{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "from sklearn import preprocessing\n",
        "import random\n",
        "import sklearn.linear_model as sklm\n",
        "from sklearn import metrics\n",
        "import math"
      ],
      "metadata": {
        "id": "9NYIlEGVdXBk"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SrS92WXzbaVm",
        "outputId": "54a20068-43de-46d2-d143-9dc4703d2b83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "file_path = '/content/drive/MyDrive/train.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "df.head(11)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "-J20CTKybs4t",
        "outputId": "c5bb5998-d955-4a3b-d06b-1745208b5de4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    labels       f_0       f_1       f_2       f_3       f_4       f_5  \\\n",
              "0        0 -2.033875  0.978446 -0.142131 -0.177117 -1.470684  1.669562   \n",
              "1        1 -0.348835  0.294815 -0.557577 -2.020773 -1.234715  1.633930   \n",
              "2        1  0.113248 -0.607726 -0.947791  0.830851  0.998291  0.498321   \n",
              "3        0  1.223321 -0.479048 -1.925789  1.680377  0.021840 -1.453307   \n",
              "4        0  0.160109  0.422684 -0.308029  0.227744  0.432854  0.608348   \n",
              "5        0 -0.526642 -0.590432  0.328210 -0.547433 -0.692556  0.175954   \n",
              "6        0 -0.199279  0.831787 -1.052687  0.491722 -0.571469 -1.449519   \n",
              "7        0 -0.906233  0.987997 -2.056229  1.078932  0.501608  0.826041   \n",
              "8        0 -0.283658  0.964051 -0.349123 -0.162445  0.238172  0.501472   \n",
              "9        0  1.382773 -2.415394  0.969006 -1.690371  1.509442  0.914959   \n",
              "10       1 -0.932571  1.366246  0.364603  2.126203  0.705695  0.066673   \n",
              "\n",
              "         f_6       f_7       f_8  ...    f_1190    f_1191    f_1192    f_1193  \\\n",
              "0  -0.196530 -0.125239 -0.452284  ... -1.111266  0.716084  0.060039  0.301279   \n",
              "1  -1.680658 -0.358146  0.166122  ...  0.735240  0.829781  1.521941  1.347946   \n",
              "2  -1.493958  0.789572 -1.311018  ...  0.104698  0.616189 -1.035953  2.111387   \n",
              "3   0.605559 -0.019024  1.065448  ...  0.360237 -1.957863 -0.123384  1.505329   \n",
              "4   0.193832  1.035091 -0.538868  ...  0.416629  1.441766  0.212572 -0.994721   \n",
              "5   0.539330  0.578212  0.547327  ...  1.131889  0.250693 -0.215257  0.236730   \n",
              "6  -0.227167  0.451431  0.090848  ...  1.081787  0.875338 -1.217201 -0.297249   \n",
              "7  -0.136533 -0.931548 -0.657145  ...  1.041859 -0.313667  1.492701 -0.425727   \n",
              "8   0.413006 -1.183602 -0.221886  ... -1.612677 -0.714356 -0.033445 -2.350722   \n",
              "9  -0.161389  0.952598 -0.044989  ...  0.875176 -0.855081  0.318588  0.252447   \n",
              "10 -0.796001 -1.204584 -0.579558  ...  0.403565 -0.092736 -0.051202  1.109147   \n",
              "\n",
              "      f_1194    f_1195    f_1196    f_1197    f_1198    f_1199  \n",
              "0  -1.174846 -1.076498 -0.069452 -0.604012 -2.179176  0.558003  \n",
              "1   0.754505  1.330642 -0.754453  0.582956  0.252671  1.495870  \n",
              "2  -0.984415  1.148076 -1.433554  0.243372  0.170083  1.274795  \n",
              "3   0.660290 -1.769443 -0.547756 -0.568122  0.244645  0.982116  \n",
              "4   1.143999 -2.166923 -1.199248 -1.028636  0.752791  0.317169  \n",
              "5   0.905414 -0.102015 -2.453250 -1.562715 -0.324501  1.590111  \n",
              "6  -0.133911 -0.865070 -0.128914  1.153154  0.363864  0.670339  \n",
              "7  -0.425587 -0.408214  2.041689  0.814182  0.211569  0.343013  \n",
              "8  -1.373337 -1.521727  0.015327  0.114279  1.320421  0.979955  \n",
              "9   0.400645  1.732217 -0.390191  0.628386 -1.518295 -0.218986  \n",
              "10  0.028089 -0.467010 -0.072701  0.181085  1.065936 -1.294234  \n",
              "\n",
              "[11 rows x 1201 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-920c852f-1dcd-482e-abf5-2a1aeb91c0aa\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>labels</th>\n",
              "      <th>f_0</th>\n",
              "      <th>f_1</th>\n",
              "      <th>f_2</th>\n",
              "      <th>f_3</th>\n",
              "      <th>f_4</th>\n",
              "      <th>f_5</th>\n",
              "      <th>f_6</th>\n",
              "      <th>f_7</th>\n",
              "      <th>f_8</th>\n",
              "      <th>...</th>\n",
              "      <th>f_1190</th>\n",
              "      <th>f_1191</th>\n",
              "      <th>f_1192</th>\n",
              "      <th>f_1193</th>\n",
              "      <th>f_1194</th>\n",
              "      <th>f_1195</th>\n",
              "      <th>f_1196</th>\n",
              "      <th>f_1197</th>\n",
              "      <th>f_1198</th>\n",
              "      <th>f_1199</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>-2.033875</td>\n",
              "      <td>0.978446</td>\n",
              "      <td>-0.142131</td>\n",
              "      <td>-0.177117</td>\n",
              "      <td>-1.470684</td>\n",
              "      <td>1.669562</td>\n",
              "      <td>-0.196530</td>\n",
              "      <td>-0.125239</td>\n",
              "      <td>-0.452284</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.111266</td>\n",
              "      <td>0.716084</td>\n",
              "      <td>0.060039</td>\n",
              "      <td>0.301279</td>\n",
              "      <td>-1.174846</td>\n",
              "      <td>-1.076498</td>\n",
              "      <td>-0.069452</td>\n",
              "      <td>-0.604012</td>\n",
              "      <td>-2.179176</td>\n",
              "      <td>0.558003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.348835</td>\n",
              "      <td>0.294815</td>\n",
              "      <td>-0.557577</td>\n",
              "      <td>-2.020773</td>\n",
              "      <td>-1.234715</td>\n",
              "      <td>1.633930</td>\n",
              "      <td>-1.680658</td>\n",
              "      <td>-0.358146</td>\n",
              "      <td>0.166122</td>\n",
              "      <td>...</td>\n",
              "      <td>0.735240</td>\n",
              "      <td>0.829781</td>\n",
              "      <td>1.521941</td>\n",
              "      <td>1.347946</td>\n",
              "      <td>0.754505</td>\n",
              "      <td>1.330642</td>\n",
              "      <td>-0.754453</td>\n",
              "      <td>0.582956</td>\n",
              "      <td>0.252671</td>\n",
              "      <td>1.495870</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0.113248</td>\n",
              "      <td>-0.607726</td>\n",
              "      <td>-0.947791</td>\n",
              "      <td>0.830851</td>\n",
              "      <td>0.998291</td>\n",
              "      <td>0.498321</td>\n",
              "      <td>-1.493958</td>\n",
              "      <td>0.789572</td>\n",
              "      <td>-1.311018</td>\n",
              "      <td>...</td>\n",
              "      <td>0.104698</td>\n",
              "      <td>0.616189</td>\n",
              "      <td>-1.035953</td>\n",
              "      <td>2.111387</td>\n",
              "      <td>-0.984415</td>\n",
              "      <td>1.148076</td>\n",
              "      <td>-1.433554</td>\n",
              "      <td>0.243372</td>\n",
              "      <td>0.170083</td>\n",
              "      <td>1.274795</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1.223321</td>\n",
              "      <td>-0.479048</td>\n",
              "      <td>-1.925789</td>\n",
              "      <td>1.680377</td>\n",
              "      <td>0.021840</td>\n",
              "      <td>-1.453307</td>\n",
              "      <td>0.605559</td>\n",
              "      <td>-0.019024</td>\n",
              "      <td>1.065448</td>\n",
              "      <td>...</td>\n",
              "      <td>0.360237</td>\n",
              "      <td>-1.957863</td>\n",
              "      <td>-0.123384</td>\n",
              "      <td>1.505329</td>\n",
              "      <td>0.660290</td>\n",
              "      <td>-1.769443</td>\n",
              "      <td>-0.547756</td>\n",
              "      <td>-0.568122</td>\n",
              "      <td>0.244645</td>\n",
              "      <td>0.982116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0.160109</td>\n",
              "      <td>0.422684</td>\n",
              "      <td>-0.308029</td>\n",
              "      <td>0.227744</td>\n",
              "      <td>0.432854</td>\n",
              "      <td>0.608348</td>\n",
              "      <td>0.193832</td>\n",
              "      <td>1.035091</td>\n",
              "      <td>-0.538868</td>\n",
              "      <td>...</td>\n",
              "      <td>0.416629</td>\n",
              "      <td>1.441766</td>\n",
              "      <td>0.212572</td>\n",
              "      <td>-0.994721</td>\n",
              "      <td>1.143999</td>\n",
              "      <td>-2.166923</td>\n",
              "      <td>-1.199248</td>\n",
              "      <td>-1.028636</td>\n",
              "      <td>0.752791</td>\n",
              "      <td>0.317169</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>-0.526642</td>\n",
              "      <td>-0.590432</td>\n",
              "      <td>0.328210</td>\n",
              "      <td>-0.547433</td>\n",
              "      <td>-0.692556</td>\n",
              "      <td>0.175954</td>\n",
              "      <td>0.539330</td>\n",
              "      <td>0.578212</td>\n",
              "      <td>0.547327</td>\n",
              "      <td>...</td>\n",
              "      <td>1.131889</td>\n",
              "      <td>0.250693</td>\n",
              "      <td>-0.215257</td>\n",
              "      <td>0.236730</td>\n",
              "      <td>0.905414</td>\n",
              "      <td>-0.102015</td>\n",
              "      <td>-2.453250</td>\n",
              "      <td>-1.562715</td>\n",
              "      <td>-0.324501</td>\n",
              "      <td>1.590111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>-0.199279</td>\n",
              "      <td>0.831787</td>\n",
              "      <td>-1.052687</td>\n",
              "      <td>0.491722</td>\n",
              "      <td>-0.571469</td>\n",
              "      <td>-1.449519</td>\n",
              "      <td>-0.227167</td>\n",
              "      <td>0.451431</td>\n",
              "      <td>0.090848</td>\n",
              "      <td>...</td>\n",
              "      <td>1.081787</td>\n",
              "      <td>0.875338</td>\n",
              "      <td>-1.217201</td>\n",
              "      <td>-0.297249</td>\n",
              "      <td>-0.133911</td>\n",
              "      <td>-0.865070</td>\n",
              "      <td>-0.128914</td>\n",
              "      <td>1.153154</td>\n",
              "      <td>0.363864</td>\n",
              "      <td>0.670339</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>-0.906233</td>\n",
              "      <td>0.987997</td>\n",
              "      <td>-2.056229</td>\n",
              "      <td>1.078932</td>\n",
              "      <td>0.501608</td>\n",
              "      <td>0.826041</td>\n",
              "      <td>-0.136533</td>\n",
              "      <td>-0.931548</td>\n",
              "      <td>-0.657145</td>\n",
              "      <td>...</td>\n",
              "      <td>1.041859</td>\n",
              "      <td>-0.313667</td>\n",
              "      <td>1.492701</td>\n",
              "      <td>-0.425727</td>\n",
              "      <td>-0.425587</td>\n",
              "      <td>-0.408214</td>\n",
              "      <td>2.041689</td>\n",
              "      <td>0.814182</td>\n",
              "      <td>0.211569</td>\n",
              "      <td>0.343013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>-0.283658</td>\n",
              "      <td>0.964051</td>\n",
              "      <td>-0.349123</td>\n",
              "      <td>-0.162445</td>\n",
              "      <td>0.238172</td>\n",
              "      <td>0.501472</td>\n",
              "      <td>0.413006</td>\n",
              "      <td>-1.183602</td>\n",
              "      <td>-0.221886</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.612677</td>\n",
              "      <td>-0.714356</td>\n",
              "      <td>-0.033445</td>\n",
              "      <td>-2.350722</td>\n",
              "      <td>-1.373337</td>\n",
              "      <td>-1.521727</td>\n",
              "      <td>0.015327</td>\n",
              "      <td>0.114279</td>\n",
              "      <td>1.320421</td>\n",
              "      <td>0.979955</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0</td>\n",
              "      <td>1.382773</td>\n",
              "      <td>-2.415394</td>\n",
              "      <td>0.969006</td>\n",
              "      <td>-1.690371</td>\n",
              "      <td>1.509442</td>\n",
              "      <td>0.914959</td>\n",
              "      <td>-0.161389</td>\n",
              "      <td>0.952598</td>\n",
              "      <td>-0.044989</td>\n",
              "      <td>...</td>\n",
              "      <td>0.875176</td>\n",
              "      <td>-0.855081</td>\n",
              "      <td>0.318588</td>\n",
              "      <td>0.252447</td>\n",
              "      <td>0.400645</td>\n",
              "      <td>1.732217</td>\n",
              "      <td>-0.390191</td>\n",
              "      <td>0.628386</td>\n",
              "      <td>-1.518295</td>\n",
              "      <td>-0.218986</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.932571</td>\n",
              "      <td>1.366246</td>\n",
              "      <td>0.364603</td>\n",
              "      <td>2.126203</td>\n",
              "      <td>0.705695</td>\n",
              "      <td>0.066673</td>\n",
              "      <td>-0.796001</td>\n",
              "      <td>-1.204584</td>\n",
              "      <td>-0.579558</td>\n",
              "      <td>...</td>\n",
              "      <td>0.403565</td>\n",
              "      <td>-0.092736</td>\n",
              "      <td>-0.051202</td>\n",
              "      <td>1.109147</td>\n",
              "      <td>0.028089</td>\n",
              "      <td>-0.467010</td>\n",
              "      <td>-0.072701</td>\n",
              "      <td>0.181085</td>\n",
              "      <td>1.065936</td>\n",
              "      <td>-1.294234</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11 rows × 1201 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-920c852f-1dcd-482e-abf5-2a1aeb91c0aa')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-920c852f-1dcd-482e-abf5-2a1aeb91c0aa button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-920c852f-1dcd-482e-abf5-2a1aeb91c0aa');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_labels_fake = df[df.labels==0]\n",
        "df_labels_real = df[df.labels==1]"
      ],
      "metadata": {
        "id": "F3GXzO5jcJJ-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_labels_fake.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "f8g1wZgLcOVn",
        "outputId": "04c3f51d-cb93-44f3-ab59-eec450cabfd7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       labels          f_0          f_1          f_2          f_3  \\\n",
              "count  3850.0  3850.000000  3850.000000  3850.000000  3850.000000   \n",
              "mean      0.0     0.502053    -0.030477     0.443031     0.537757   \n",
              "std       0.0     0.938144     0.818172     0.985069     0.961128   \n",
              "min       0.0    -3.456462    -3.605773    -4.078232    -3.344323   \n",
              "25%       0.0    -0.149282    -0.506289    -0.236340    -0.140414   \n",
              "50%       0.0     0.883475    -0.015724     0.867160     0.932438   \n",
              "75%       0.0     1.165988     0.447057     1.142597     1.206613   \n",
              "max       0.0     3.439295     3.581171     3.279503     3.900672   \n",
              "\n",
              "               f_4          f_5          f_6          f_7          f_8  ...  \\\n",
              "count  3850.000000  3850.000000  3850.000000  3850.000000  3850.000000  ...   \n",
              "mean      0.205177     0.117557    -0.187478    -0.184756    -0.158397  ...   \n",
              "std       0.959540     0.833402     1.030615     0.829810     1.001650  ...   \n",
              "min      -3.613712    -3.319666    -3.627701    -3.528635    -4.503662  ...   \n",
              "25%      -0.487336    -0.385564    -1.041811    -0.721281    -0.998972  ...   \n",
              "50%       0.344353     0.216695    -0.222315    -0.239900    -0.116996  ...   \n",
              "75%       1.021624     0.656654     0.706668     0.255553     0.678515  ...   \n",
              "max       3.488667     3.193113     3.062756     3.692669     3.017000  ...   \n",
              "\n",
              "            f_1190       f_1191       f_1192       f_1193       f_1194  \\\n",
              "count  3850.000000  3850.000000  3850.000000  3850.000000  3850.000000   \n",
              "mean      0.554650    -0.417062     0.062412    -0.268750    -0.107413   \n",
              "std       0.945503     1.035183     0.918475     0.962270     1.035620   \n",
              "min      -3.684054    -3.385650    -3.162629    -3.022903    -3.357147   \n",
              "25%      -0.053651    -1.263328    -0.594758    -1.016095    -1.007004   \n",
              "50%       0.937109    -0.515049     0.174416    -0.292924    -0.067019   \n",
              "75%       1.200452     0.332425     0.729584     0.391029     0.793604   \n",
              "max       4.077517     3.550058     3.550058     3.907684     3.777545   \n",
              "\n",
              "            f_1195       f_1196       f_1197       f_1198       f_1199  \n",
              "count  3850.000000  3850.000000  3850.000000  3850.000000  3850.000000  \n",
              "mean     -0.313844    -0.188299     0.489204    -0.258141    -0.075701  \n",
              "std       0.953724     0.846435     0.961586     0.998810     0.828229  \n",
              "min      -4.791005    -3.356509    -3.933762    -4.174752    -3.618622  \n",
              "25%      -0.943706    -0.715001    -0.182125    -1.086697    -0.588205  \n",
              "50%      -0.327877    -0.226964     0.904574    -0.281546    -0.067258  \n",
              "75%       0.271970     0.257808     1.166320     0.520457     0.384528  \n",
              "max       3.269490     3.526907     3.157554     3.335078     3.161221  \n",
              "\n",
              "[8 rows x 1201 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f7281c09-1bdf-4316-8079-51df0eea18f6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>labels</th>\n",
              "      <th>f_0</th>\n",
              "      <th>f_1</th>\n",
              "      <th>f_2</th>\n",
              "      <th>f_3</th>\n",
              "      <th>f_4</th>\n",
              "      <th>f_5</th>\n",
              "      <th>f_6</th>\n",
              "      <th>f_7</th>\n",
              "      <th>f_8</th>\n",
              "      <th>...</th>\n",
              "      <th>f_1190</th>\n",
              "      <th>f_1191</th>\n",
              "      <th>f_1192</th>\n",
              "      <th>f_1193</th>\n",
              "      <th>f_1194</th>\n",
              "      <th>f_1195</th>\n",
              "      <th>f_1196</th>\n",
              "      <th>f_1197</th>\n",
              "      <th>f_1198</th>\n",
              "      <th>f_1199</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>3850.0</td>\n",
              "      <td>3850.000000</td>\n",
              "      <td>3850.000000</td>\n",
              "      <td>3850.000000</td>\n",
              "      <td>3850.000000</td>\n",
              "      <td>3850.000000</td>\n",
              "      <td>3850.000000</td>\n",
              "      <td>3850.000000</td>\n",
              "      <td>3850.000000</td>\n",
              "      <td>3850.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>3850.000000</td>\n",
              "      <td>3850.000000</td>\n",
              "      <td>3850.000000</td>\n",
              "      <td>3850.000000</td>\n",
              "      <td>3850.000000</td>\n",
              "      <td>3850.000000</td>\n",
              "      <td>3850.000000</td>\n",
              "      <td>3850.000000</td>\n",
              "      <td>3850.000000</td>\n",
              "      <td>3850.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.502053</td>\n",
              "      <td>-0.030477</td>\n",
              "      <td>0.443031</td>\n",
              "      <td>0.537757</td>\n",
              "      <td>0.205177</td>\n",
              "      <td>0.117557</td>\n",
              "      <td>-0.187478</td>\n",
              "      <td>-0.184756</td>\n",
              "      <td>-0.158397</td>\n",
              "      <td>...</td>\n",
              "      <td>0.554650</td>\n",
              "      <td>-0.417062</td>\n",
              "      <td>0.062412</td>\n",
              "      <td>-0.268750</td>\n",
              "      <td>-0.107413</td>\n",
              "      <td>-0.313844</td>\n",
              "      <td>-0.188299</td>\n",
              "      <td>0.489204</td>\n",
              "      <td>-0.258141</td>\n",
              "      <td>-0.075701</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.938144</td>\n",
              "      <td>0.818172</td>\n",
              "      <td>0.985069</td>\n",
              "      <td>0.961128</td>\n",
              "      <td>0.959540</td>\n",
              "      <td>0.833402</td>\n",
              "      <td>1.030615</td>\n",
              "      <td>0.829810</td>\n",
              "      <td>1.001650</td>\n",
              "      <td>...</td>\n",
              "      <td>0.945503</td>\n",
              "      <td>1.035183</td>\n",
              "      <td>0.918475</td>\n",
              "      <td>0.962270</td>\n",
              "      <td>1.035620</td>\n",
              "      <td>0.953724</td>\n",
              "      <td>0.846435</td>\n",
              "      <td>0.961586</td>\n",
              "      <td>0.998810</td>\n",
              "      <td>0.828229</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-3.456462</td>\n",
              "      <td>-3.605773</td>\n",
              "      <td>-4.078232</td>\n",
              "      <td>-3.344323</td>\n",
              "      <td>-3.613712</td>\n",
              "      <td>-3.319666</td>\n",
              "      <td>-3.627701</td>\n",
              "      <td>-3.528635</td>\n",
              "      <td>-4.503662</td>\n",
              "      <td>...</td>\n",
              "      <td>-3.684054</td>\n",
              "      <td>-3.385650</td>\n",
              "      <td>-3.162629</td>\n",
              "      <td>-3.022903</td>\n",
              "      <td>-3.357147</td>\n",
              "      <td>-4.791005</td>\n",
              "      <td>-3.356509</td>\n",
              "      <td>-3.933762</td>\n",
              "      <td>-4.174752</td>\n",
              "      <td>-3.618622</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.149282</td>\n",
              "      <td>-0.506289</td>\n",
              "      <td>-0.236340</td>\n",
              "      <td>-0.140414</td>\n",
              "      <td>-0.487336</td>\n",
              "      <td>-0.385564</td>\n",
              "      <td>-1.041811</td>\n",
              "      <td>-0.721281</td>\n",
              "      <td>-0.998972</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.053651</td>\n",
              "      <td>-1.263328</td>\n",
              "      <td>-0.594758</td>\n",
              "      <td>-1.016095</td>\n",
              "      <td>-1.007004</td>\n",
              "      <td>-0.943706</td>\n",
              "      <td>-0.715001</td>\n",
              "      <td>-0.182125</td>\n",
              "      <td>-1.086697</td>\n",
              "      <td>-0.588205</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.883475</td>\n",
              "      <td>-0.015724</td>\n",
              "      <td>0.867160</td>\n",
              "      <td>0.932438</td>\n",
              "      <td>0.344353</td>\n",
              "      <td>0.216695</td>\n",
              "      <td>-0.222315</td>\n",
              "      <td>-0.239900</td>\n",
              "      <td>-0.116996</td>\n",
              "      <td>...</td>\n",
              "      <td>0.937109</td>\n",
              "      <td>-0.515049</td>\n",
              "      <td>0.174416</td>\n",
              "      <td>-0.292924</td>\n",
              "      <td>-0.067019</td>\n",
              "      <td>-0.327877</td>\n",
              "      <td>-0.226964</td>\n",
              "      <td>0.904574</td>\n",
              "      <td>-0.281546</td>\n",
              "      <td>-0.067258</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.165988</td>\n",
              "      <td>0.447057</td>\n",
              "      <td>1.142597</td>\n",
              "      <td>1.206613</td>\n",
              "      <td>1.021624</td>\n",
              "      <td>0.656654</td>\n",
              "      <td>0.706668</td>\n",
              "      <td>0.255553</td>\n",
              "      <td>0.678515</td>\n",
              "      <td>...</td>\n",
              "      <td>1.200452</td>\n",
              "      <td>0.332425</td>\n",
              "      <td>0.729584</td>\n",
              "      <td>0.391029</td>\n",
              "      <td>0.793604</td>\n",
              "      <td>0.271970</td>\n",
              "      <td>0.257808</td>\n",
              "      <td>1.166320</td>\n",
              "      <td>0.520457</td>\n",
              "      <td>0.384528</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.0</td>\n",
              "      <td>3.439295</td>\n",
              "      <td>3.581171</td>\n",
              "      <td>3.279503</td>\n",
              "      <td>3.900672</td>\n",
              "      <td>3.488667</td>\n",
              "      <td>3.193113</td>\n",
              "      <td>3.062756</td>\n",
              "      <td>3.692669</td>\n",
              "      <td>3.017000</td>\n",
              "      <td>...</td>\n",
              "      <td>4.077517</td>\n",
              "      <td>3.550058</td>\n",
              "      <td>3.550058</td>\n",
              "      <td>3.907684</td>\n",
              "      <td>3.777545</td>\n",
              "      <td>3.269490</td>\n",
              "      <td>3.526907</td>\n",
              "      <td>3.157554</td>\n",
              "      <td>3.335078</td>\n",
              "      <td>3.161221</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 1201 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f7281c09-1bdf-4316-8079-51df0eea18f6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f7281c09-1bdf-4316-8079-51df0eea18f6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f7281c09-1bdf-4316-8079-51df0eea18f6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_labels_fake.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "7akAZ4BccbT1",
        "outputId": "ea6bd476-2331-4ef8-cecd-16760cd3baa8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    labels       f_0       f_1       f_2       f_3       f_4       f_5  \\\n",
              "0        0 -2.033875  0.978446 -0.142131 -0.177117 -1.470684  1.669562   \n",
              "3        0  1.223321 -0.479048 -1.925789  1.680377  0.021840 -1.453307   \n",
              "4        0  0.160109  0.422684 -0.308029  0.227744  0.432854  0.608348   \n",
              "5        0 -0.526642 -0.590432  0.328210 -0.547433 -0.692556  0.175954   \n",
              "6        0 -0.199279  0.831787 -1.052687  0.491722 -0.571469 -1.449519   \n",
              "7        0 -0.906233  0.987997 -2.056229  1.078932  0.501608  0.826041   \n",
              "8        0 -0.283658  0.964051 -0.349123 -0.162445  0.238172  0.501472   \n",
              "9        0  1.382773 -2.415394  0.969006 -1.690371  1.509442  0.914959   \n",
              "11       0  0.365353  0.470598  1.752336  0.505644 -1.261461  1.758168   \n",
              "12       0  0.235247 -0.091385 -0.759469  0.113210 -0.433791  0.300723   \n",
              "\n",
              "         f_6       f_7       f_8  ...    f_1190    f_1191    f_1192    f_1193  \\\n",
              "0  -0.196530 -0.125239 -0.452284  ... -1.111266  0.716084  0.060039  0.301279   \n",
              "3   0.605559 -0.019024  1.065448  ...  0.360237 -1.957863 -0.123384  1.505329   \n",
              "4   0.193832  1.035091 -0.538868  ...  0.416629  1.441766  0.212572 -0.994721   \n",
              "5   0.539330  0.578212  0.547327  ...  1.131889  0.250693 -0.215257  0.236730   \n",
              "6  -0.227167  0.451431  0.090848  ...  1.081787  0.875338 -1.217201 -0.297249   \n",
              "7  -0.136533 -0.931548 -0.657145  ...  1.041859 -0.313667  1.492701 -0.425727   \n",
              "8   0.413006 -1.183602 -0.221886  ... -1.612677 -0.714356 -0.033445 -2.350722   \n",
              "9  -0.161389  0.952598 -0.044989  ...  0.875176 -0.855081  0.318588  0.252447   \n",
              "11 -1.017149 -0.055868 -0.535391  ... -0.129481  1.155167 -1.204498  1.321770   \n",
              "12 -0.267967  0.162265  0.556682  ... -1.967113  0.945310  0.417037  0.640227   \n",
              "\n",
              "      f_1194    f_1195    f_1196    f_1197    f_1198    f_1199  \n",
              "0  -1.174846 -1.076498 -0.069452 -0.604012 -2.179176  0.558003  \n",
              "3   0.660290 -1.769443 -0.547756 -0.568122  0.244645  0.982116  \n",
              "4   1.143999 -2.166923 -1.199248 -1.028636  0.752791  0.317169  \n",
              "5   0.905414 -0.102015 -2.453250 -1.562715 -0.324501  1.590111  \n",
              "6  -0.133911 -0.865070 -0.128914  1.153154  0.363864  0.670339  \n",
              "7  -0.425587 -0.408214  2.041689  0.814182  0.211569  0.343013  \n",
              "8  -1.373337 -1.521727  0.015327  0.114279  1.320421  0.979955  \n",
              "9   0.400645  1.732217 -0.390191  0.628386 -1.518295 -0.218986  \n",
              "11 -0.112178  0.851505 -1.089377 -1.842042 -0.832785 -2.380189  \n",
              "12 -0.835910 -0.657269 -1.671775 -0.491912  0.371470  0.295782  \n",
              "\n",
              "[10 rows x 1201 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d68b6065-dde5-4575-b670-fb58cee8cf7b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>labels</th>\n",
              "      <th>f_0</th>\n",
              "      <th>f_1</th>\n",
              "      <th>f_2</th>\n",
              "      <th>f_3</th>\n",
              "      <th>f_4</th>\n",
              "      <th>f_5</th>\n",
              "      <th>f_6</th>\n",
              "      <th>f_7</th>\n",
              "      <th>f_8</th>\n",
              "      <th>...</th>\n",
              "      <th>f_1190</th>\n",
              "      <th>f_1191</th>\n",
              "      <th>f_1192</th>\n",
              "      <th>f_1193</th>\n",
              "      <th>f_1194</th>\n",
              "      <th>f_1195</th>\n",
              "      <th>f_1196</th>\n",
              "      <th>f_1197</th>\n",
              "      <th>f_1198</th>\n",
              "      <th>f_1199</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>-2.033875</td>\n",
              "      <td>0.978446</td>\n",
              "      <td>-0.142131</td>\n",
              "      <td>-0.177117</td>\n",
              "      <td>-1.470684</td>\n",
              "      <td>1.669562</td>\n",
              "      <td>-0.196530</td>\n",
              "      <td>-0.125239</td>\n",
              "      <td>-0.452284</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.111266</td>\n",
              "      <td>0.716084</td>\n",
              "      <td>0.060039</td>\n",
              "      <td>0.301279</td>\n",
              "      <td>-1.174846</td>\n",
              "      <td>-1.076498</td>\n",
              "      <td>-0.069452</td>\n",
              "      <td>-0.604012</td>\n",
              "      <td>-2.179176</td>\n",
              "      <td>0.558003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1.223321</td>\n",
              "      <td>-0.479048</td>\n",
              "      <td>-1.925789</td>\n",
              "      <td>1.680377</td>\n",
              "      <td>0.021840</td>\n",
              "      <td>-1.453307</td>\n",
              "      <td>0.605559</td>\n",
              "      <td>-0.019024</td>\n",
              "      <td>1.065448</td>\n",
              "      <td>...</td>\n",
              "      <td>0.360237</td>\n",
              "      <td>-1.957863</td>\n",
              "      <td>-0.123384</td>\n",
              "      <td>1.505329</td>\n",
              "      <td>0.660290</td>\n",
              "      <td>-1.769443</td>\n",
              "      <td>-0.547756</td>\n",
              "      <td>-0.568122</td>\n",
              "      <td>0.244645</td>\n",
              "      <td>0.982116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0.160109</td>\n",
              "      <td>0.422684</td>\n",
              "      <td>-0.308029</td>\n",
              "      <td>0.227744</td>\n",
              "      <td>0.432854</td>\n",
              "      <td>0.608348</td>\n",
              "      <td>0.193832</td>\n",
              "      <td>1.035091</td>\n",
              "      <td>-0.538868</td>\n",
              "      <td>...</td>\n",
              "      <td>0.416629</td>\n",
              "      <td>1.441766</td>\n",
              "      <td>0.212572</td>\n",
              "      <td>-0.994721</td>\n",
              "      <td>1.143999</td>\n",
              "      <td>-2.166923</td>\n",
              "      <td>-1.199248</td>\n",
              "      <td>-1.028636</td>\n",
              "      <td>0.752791</td>\n",
              "      <td>0.317169</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>-0.526642</td>\n",
              "      <td>-0.590432</td>\n",
              "      <td>0.328210</td>\n",
              "      <td>-0.547433</td>\n",
              "      <td>-0.692556</td>\n",
              "      <td>0.175954</td>\n",
              "      <td>0.539330</td>\n",
              "      <td>0.578212</td>\n",
              "      <td>0.547327</td>\n",
              "      <td>...</td>\n",
              "      <td>1.131889</td>\n",
              "      <td>0.250693</td>\n",
              "      <td>-0.215257</td>\n",
              "      <td>0.236730</td>\n",
              "      <td>0.905414</td>\n",
              "      <td>-0.102015</td>\n",
              "      <td>-2.453250</td>\n",
              "      <td>-1.562715</td>\n",
              "      <td>-0.324501</td>\n",
              "      <td>1.590111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>-0.199279</td>\n",
              "      <td>0.831787</td>\n",
              "      <td>-1.052687</td>\n",
              "      <td>0.491722</td>\n",
              "      <td>-0.571469</td>\n",
              "      <td>-1.449519</td>\n",
              "      <td>-0.227167</td>\n",
              "      <td>0.451431</td>\n",
              "      <td>0.090848</td>\n",
              "      <td>...</td>\n",
              "      <td>1.081787</td>\n",
              "      <td>0.875338</td>\n",
              "      <td>-1.217201</td>\n",
              "      <td>-0.297249</td>\n",
              "      <td>-0.133911</td>\n",
              "      <td>-0.865070</td>\n",
              "      <td>-0.128914</td>\n",
              "      <td>1.153154</td>\n",
              "      <td>0.363864</td>\n",
              "      <td>0.670339</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>-0.906233</td>\n",
              "      <td>0.987997</td>\n",
              "      <td>-2.056229</td>\n",
              "      <td>1.078932</td>\n",
              "      <td>0.501608</td>\n",
              "      <td>0.826041</td>\n",
              "      <td>-0.136533</td>\n",
              "      <td>-0.931548</td>\n",
              "      <td>-0.657145</td>\n",
              "      <td>...</td>\n",
              "      <td>1.041859</td>\n",
              "      <td>-0.313667</td>\n",
              "      <td>1.492701</td>\n",
              "      <td>-0.425727</td>\n",
              "      <td>-0.425587</td>\n",
              "      <td>-0.408214</td>\n",
              "      <td>2.041689</td>\n",
              "      <td>0.814182</td>\n",
              "      <td>0.211569</td>\n",
              "      <td>0.343013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>-0.283658</td>\n",
              "      <td>0.964051</td>\n",
              "      <td>-0.349123</td>\n",
              "      <td>-0.162445</td>\n",
              "      <td>0.238172</td>\n",
              "      <td>0.501472</td>\n",
              "      <td>0.413006</td>\n",
              "      <td>-1.183602</td>\n",
              "      <td>-0.221886</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.612677</td>\n",
              "      <td>-0.714356</td>\n",
              "      <td>-0.033445</td>\n",
              "      <td>-2.350722</td>\n",
              "      <td>-1.373337</td>\n",
              "      <td>-1.521727</td>\n",
              "      <td>0.015327</td>\n",
              "      <td>0.114279</td>\n",
              "      <td>1.320421</td>\n",
              "      <td>0.979955</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0</td>\n",
              "      <td>1.382773</td>\n",
              "      <td>-2.415394</td>\n",
              "      <td>0.969006</td>\n",
              "      <td>-1.690371</td>\n",
              "      <td>1.509442</td>\n",
              "      <td>0.914959</td>\n",
              "      <td>-0.161389</td>\n",
              "      <td>0.952598</td>\n",
              "      <td>-0.044989</td>\n",
              "      <td>...</td>\n",
              "      <td>0.875176</td>\n",
              "      <td>-0.855081</td>\n",
              "      <td>0.318588</td>\n",
              "      <td>0.252447</td>\n",
              "      <td>0.400645</td>\n",
              "      <td>1.732217</td>\n",
              "      <td>-0.390191</td>\n",
              "      <td>0.628386</td>\n",
              "      <td>-1.518295</td>\n",
              "      <td>-0.218986</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0</td>\n",
              "      <td>0.365353</td>\n",
              "      <td>0.470598</td>\n",
              "      <td>1.752336</td>\n",
              "      <td>0.505644</td>\n",
              "      <td>-1.261461</td>\n",
              "      <td>1.758168</td>\n",
              "      <td>-1.017149</td>\n",
              "      <td>-0.055868</td>\n",
              "      <td>-0.535391</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.129481</td>\n",
              "      <td>1.155167</td>\n",
              "      <td>-1.204498</td>\n",
              "      <td>1.321770</td>\n",
              "      <td>-0.112178</td>\n",
              "      <td>0.851505</td>\n",
              "      <td>-1.089377</td>\n",
              "      <td>-1.842042</td>\n",
              "      <td>-0.832785</td>\n",
              "      <td>-2.380189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0</td>\n",
              "      <td>0.235247</td>\n",
              "      <td>-0.091385</td>\n",
              "      <td>-0.759469</td>\n",
              "      <td>0.113210</td>\n",
              "      <td>-0.433791</td>\n",
              "      <td>0.300723</td>\n",
              "      <td>-0.267967</td>\n",
              "      <td>0.162265</td>\n",
              "      <td>0.556682</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.967113</td>\n",
              "      <td>0.945310</td>\n",
              "      <td>0.417037</td>\n",
              "      <td>0.640227</td>\n",
              "      <td>-0.835910</td>\n",
              "      <td>-0.657269</td>\n",
              "      <td>-1.671775</td>\n",
              "      <td>-0.491912</td>\n",
              "      <td>0.371470</td>\n",
              "      <td>0.295782</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 1201 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d68b6065-dde5-4575-b670-fb58cee8cf7b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d68b6065-dde5-4575-b670-fb58cee8cf7b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d68b6065-dde5-4575-b670-fb58cee8cf7b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_labels_real.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "aEejugRlce6v",
        "outputId": "5d76415d-1adc-4ce7-fc8a-d7664d607148"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       labels          f_0          f_1          f_2          f_3  \\\n",
              "count  1400.0  1400.000000  1400.000000  1400.000000  1400.000000   \n",
              "mean      1.0     0.064802     0.409193    -0.029270     0.022719   \n",
              "std       0.0     0.822742     1.024029     0.832047     0.825924   \n",
              "min       1.0    -3.462941    -3.061072    -3.060476    -3.324739   \n",
              "25%       1.0    -0.436428    -0.319716    -0.546558    -0.494289   \n",
              "50%       1.0     0.070270     0.427571    -0.029743     0.031760   \n",
              "75%       1.0     0.598975     1.198388     0.517935     0.570023   \n",
              "max       1.0     3.177726     3.208203     3.991985     3.020774   \n",
              "\n",
              "               f_4          f_5          f_6          f_7          f_8  ...  \\\n",
              "count  1400.000000  1400.000000  1400.000000  1400.000000  1400.000000  ...   \n",
              "mean     -0.215248     0.327466    -0.137206     0.228108    -0.074246  ...   \n",
              "std       0.925952     1.031763     0.916289     1.030208     0.883430  ...   \n",
              "min      -2.970385    -2.855506    -3.608427    -2.995866    -2.796173  ...   \n",
              "25%      -0.897283    -0.401509    -0.743596    -0.471056    -0.686638  ...   \n",
              "50%      -0.272647     0.337853    -0.115410     0.240151    -0.095068  ...   \n",
              "75%       0.432904     1.116948     0.497908     1.006404     0.541666  ...   \n",
              "max       3.281725     2.936176     3.022501     3.877255     2.747384  ...   \n",
              "\n",
              "            f_1190       f_1191       f_1192       f_1193       f_1194  \\\n",
              "count  1400.000000  1400.000000  1400.000000  1400.000000  1400.000000   \n",
              "mean      0.041741    -0.372058     0.171480    -0.296434    -0.203826   \n",
              "std       0.819869     1.104632     1.058639     1.061999     1.056633   \n",
              "min      -3.219559    -2.969118    -2.762414    -2.841162    -3.698249   \n",
              "25%      -0.476058    -1.281886    -0.588261    -1.145848    -1.012140   \n",
              "50%       0.049110    -0.400176     0.248998    -0.318497    -0.298879   \n",
              "75%       0.601029     0.457508     0.981958     0.457717     0.551920   \n",
              "max       2.745427     2.798844     3.790435     3.140983     3.264250   \n",
              "\n",
              "            f_1195       f_1196       f_1197       f_1198       f_1199  \n",
              "count  1400.000000  1400.000000  1400.000000  1400.000000  1400.000000  \n",
              "mean      0.276291     0.157727     0.050665    -0.124678     0.232671  \n",
              "std       1.068060     1.036113     0.813314     0.893863     1.030468  \n",
              "min      -3.114715    -3.127319    -3.140881    -3.237633    -3.624981  \n",
              "25%      -0.455473    -0.564852    -0.471020    -0.729350    -0.484317  \n",
              "50%       0.315481     0.174871     0.079494    -0.123543     0.306693  \n",
              "75%       1.055877     0.942090     0.618689     0.486917     0.975435  \n",
              "max       3.050249     2.926616     3.542401     3.642856     3.718869  \n",
              "\n",
              "[8 rows x 1201 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-46933d2c-da64-4cdc-80c7-9f16d745d3e0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>labels</th>\n",
              "      <th>f_0</th>\n",
              "      <th>f_1</th>\n",
              "      <th>f_2</th>\n",
              "      <th>f_3</th>\n",
              "      <th>f_4</th>\n",
              "      <th>f_5</th>\n",
              "      <th>f_6</th>\n",
              "      <th>f_7</th>\n",
              "      <th>f_8</th>\n",
              "      <th>...</th>\n",
              "      <th>f_1190</th>\n",
              "      <th>f_1191</th>\n",
              "      <th>f_1192</th>\n",
              "      <th>f_1193</th>\n",
              "      <th>f_1194</th>\n",
              "      <th>f_1195</th>\n",
              "      <th>f_1196</th>\n",
              "      <th>f_1197</th>\n",
              "      <th>f_1198</th>\n",
              "      <th>f_1199</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1400.0</td>\n",
              "      <td>1400.000000</td>\n",
              "      <td>1400.000000</td>\n",
              "      <td>1400.000000</td>\n",
              "      <td>1400.000000</td>\n",
              "      <td>1400.000000</td>\n",
              "      <td>1400.000000</td>\n",
              "      <td>1400.000000</td>\n",
              "      <td>1400.000000</td>\n",
              "      <td>1400.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1400.000000</td>\n",
              "      <td>1400.000000</td>\n",
              "      <td>1400.000000</td>\n",
              "      <td>1400.000000</td>\n",
              "      <td>1400.000000</td>\n",
              "      <td>1400.000000</td>\n",
              "      <td>1400.000000</td>\n",
              "      <td>1400.000000</td>\n",
              "      <td>1400.000000</td>\n",
              "      <td>1400.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.064802</td>\n",
              "      <td>0.409193</td>\n",
              "      <td>-0.029270</td>\n",
              "      <td>0.022719</td>\n",
              "      <td>-0.215248</td>\n",
              "      <td>0.327466</td>\n",
              "      <td>-0.137206</td>\n",
              "      <td>0.228108</td>\n",
              "      <td>-0.074246</td>\n",
              "      <td>...</td>\n",
              "      <td>0.041741</td>\n",
              "      <td>-0.372058</td>\n",
              "      <td>0.171480</td>\n",
              "      <td>-0.296434</td>\n",
              "      <td>-0.203826</td>\n",
              "      <td>0.276291</td>\n",
              "      <td>0.157727</td>\n",
              "      <td>0.050665</td>\n",
              "      <td>-0.124678</td>\n",
              "      <td>0.232671</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.822742</td>\n",
              "      <td>1.024029</td>\n",
              "      <td>0.832047</td>\n",
              "      <td>0.825924</td>\n",
              "      <td>0.925952</td>\n",
              "      <td>1.031763</td>\n",
              "      <td>0.916289</td>\n",
              "      <td>1.030208</td>\n",
              "      <td>0.883430</td>\n",
              "      <td>...</td>\n",
              "      <td>0.819869</td>\n",
              "      <td>1.104632</td>\n",
              "      <td>1.058639</td>\n",
              "      <td>1.061999</td>\n",
              "      <td>1.056633</td>\n",
              "      <td>1.068060</td>\n",
              "      <td>1.036113</td>\n",
              "      <td>0.813314</td>\n",
              "      <td>0.893863</td>\n",
              "      <td>1.030468</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-3.462941</td>\n",
              "      <td>-3.061072</td>\n",
              "      <td>-3.060476</td>\n",
              "      <td>-3.324739</td>\n",
              "      <td>-2.970385</td>\n",
              "      <td>-2.855506</td>\n",
              "      <td>-3.608427</td>\n",
              "      <td>-2.995866</td>\n",
              "      <td>-2.796173</td>\n",
              "      <td>...</td>\n",
              "      <td>-3.219559</td>\n",
              "      <td>-2.969118</td>\n",
              "      <td>-2.762414</td>\n",
              "      <td>-2.841162</td>\n",
              "      <td>-3.698249</td>\n",
              "      <td>-3.114715</td>\n",
              "      <td>-3.127319</td>\n",
              "      <td>-3.140881</td>\n",
              "      <td>-3.237633</td>\n",
              "      <td>-3.624981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.436428</td>\n",
              "      <td>-0.319716</td>\n",
              "      <td>-0.546558</td>\n",
              "      <td>-0.494289</td>\n",
              "      <td>-0.897283</td>\n",
              "      <td>-0.401509</td>\n",
              "      <td>-0.743596</td>\n",
              "      <td>-0.471056</td>\n",
              "      <td>-0.686638</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.476058</td>\n",
              "      <td>-1.281886</td>\n",
              "      <td>-0.588261</td>\n",
              "      <td>-1.145848</td>\n",
              "      <td>-1.012140</td>\n",
              "      <td>-0.455473</td>\n",
              "      <td>-0.564852</td>\n",
              "      <td>-0.471020</td>\n",
              "      <td>-0.729350</td>\n",
              "      <td>-0.484317</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.070270</td>\n",
              "      <td>0.427571</td>\n",
              "      <td>-0.029743</td>\n",
              "      <td>0.031760</td>\n",
              "      <td>-0.272647</td>\n",
              "      <td>0.337853</td>\n",
              "      <td>-0.115410</td>\n",
              "      <td>0.240151</td>\n",
              "      <td>-0.095068</td>\n",
              "      <td>...</td>\n",
              "      <td>0.049110</td>\n",
              "      <td>-0.400176</td>\n",
              "      <td>0.248998</td>\n",
              "      <td>-0.318497</td>\n",
              "      <td>-0.298879</td>\n",
              "      <td>0.315481</td>\n",
              "      <td>0.174871</td>\n",
              "      <td>0.079494</td>\n",
              "      <td>-0.123543</td>\n",
              "      <td>0.306693</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.598975</td>\n",
              "      <td>1.198388</td>\n",
              "      <td>0.517935</td>\n",
              "      <td>0.570023</td>\n",
              "      <td>0.432904</td>\n",
              "      <td>1.116948</td>\n",
              "      <td>0.497908</td>\n",
              "      <td>1.006404</td>\n",
              "      <td>0.541666</td>\n",
              "      <td>...</td>\n",
              "      <td>0.601029</td>\n",
              "      <td>0.457508</td>\n",
              "      <td>0.981958</td>\n",
              "      <td>0.457717</td>\n",
              "      <td>0.551920</td>\n",
              "      <td>1.055877</td>\n",
              "      <td>0.942090</td>\n",
              "      <td>0.618689</td>\n",
              "      <td>0.486917</td>\n",
              "      <td>0.975435</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.0</td>\n",
              "      <td>3.177726</td>\n",
              "      <td>3.208203</td>\n",
              "      <td>3.991985</td>\n",
              "      <td>3.020774</td>\n",
              "      <td>3.281725</td>\n",
              "      <td>2.936176</td>\n",
              "      <td>3.022501</td>\n",
              "      <td>3.877255</td>\n",
              "      <td>2.747384</td>\n",
              "      <td>...</td>\n",
              "      <td>2.745427</td>\n",
              "      <td>2.798844</td>\n",
              "      <td>3.790435</td>\n",
              "      <td>3.140983</td>\n",
              "      <td>3.264250</td>\n",
              "      <td>3.050249</td>\n",
              "      <td>2.926616</td>\n",
              "      <td>3.542401</td>\n",
              "      <td>3.642856</td>\n",
              "      <td>3.718869</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 1201 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-46933d2c-da64-4cdc-80c7-9f16d745d3e0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-46933d2c-da64-4cdc-80c7-9f16d745d3e0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-46933d2c-da64-4cdc-80c7-9f16d745d3e0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_labels_real.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "0frmJTT2cizu",
        "outputId": "986faef7-8e48-41e7-a866-3fdcae3630e9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    labels       f_0       f_1       f_2       f_3       f_4       f_5  \\\n",
              "1        1 -0.348835  0.294815 -0.557577 -2.020773 -1.234715  1.633930   \n",
              "2        1  0.113248 -0.607726 -0.947791  0.830851  0.998291  0.498321   \n",
              "10       1 -0.932571  1.366246  0.364603  2.126203  0.705695  0.066673   \n",
              "16       1 -1.593680 -0.731218 -0.052828 -0.458814 -0.476738  0.887608   \n",
              "20       1 -0.490307 -1.185301  0.156087 -0.416752  0.498768 -0.392604   \n",
              "23       1  0.699435 -0.409208 -0.733523  1.063904  1.402882  0.121692   \n",
              "26       1  1.977668  0.078103 -0.337783 -1.474893  0.672837  0.592674   \n",
              "30       1  0.008912  0.501167  0.833886 -0.433362 -0.649726  0.537057   \n",
              "32       1  0.512031  0.822484 -0.448323 -0.278851 -1.135995 -0.586103   \n",
              "36       1  1.275421 -1.374833  0.146325  0.261692  0.400923  0.457052   \n",
              "\n",
              "         f_6       f_7       f_8  ...    f_1190    f_1191    f_1192    f_1193  \\\n",
              "1  -1.680658 -0.358146  0.166122  ...  0.735240  0.829781  1.521941  1.347946   \n",
              "2  -1.493958  0.789572 -1.311018  ...  0.104698  0.616189 -1.035953  2.111387   \n",
              "10 -0.796001 -1.204584 -0.579558  ...  0.403565 -0.092736 -0.051202  1.109147   \n",
              "16 -0.460991 -0.059051  1.114105  ...  0.547734 -0.512943 -0.023156 -0.021865   \n",
              "20  1.190598  1.749591  0.000897  ... -2.164895  1.039613  1.532804 -1.713240   \n",
              "23  0.693201 -0.246482 -2.796173  ... -1.600347  0.533398  0.811930 -0.950390   \n",
              "26  0.519973 -0.570367 -1.213920  ... -0.156197 -0.002251 -0.822713  1.091787   \n",
              "30  0.317005  0.159265  2.437977  ... -0.465914 -1.942418  0.062264  0.208436   \n",
              "32  1.547900 -1.577255  0.284239  ... -0.794239  0.307278 -0.518308 -0.304720   \n",
              "36 -1.296557  3.877255  0.439320  ... -0.365889  0.408901  1.264185 -0.200257   \n",
              "\n",
              "      f_1194    f_1195    f_1196    f_1197    f_1198    f_1199  \n",
              "1   0.754505  1.330642 -0.754453  0.582956  0.252671  1.495870  \n",
              "2  -0.984415  1.148076 -1.433554  0.243372  0.170083  1.274795  \n",
              "10  0.028089 -0.467010 -0.072701  0.181085  1.065936 -1.294234  \n",
              "16  0.298182 -0.575766 -0.102218  0.731609 -0.248299  1.397388  \n",
              "20  1.544514 -0.233746  0.902512  1.131872 -0.936994  0.126443  \n",
              "23  0.283361  0.166180  1.550970  0.392693  0.735159  0.244586  \n",
              "26  0.761468 -0.238339  0.157990  0.267915 -0.602962 -2.379913  \n",
              "30  1.213639 -0.467115 -1.256437 -1.163842 -0.411401 -0.029953  \n",
              "32  0.368168 -0.772607 -1.797486 -0.253851 -0.859979 -0.981040  \n",
              "36  0.827967 -3.114715 -2.880945  0.336202 -0.633886  0.595661  \n",
              "\n",
              "[10 rows x 1201 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-444a67cd-4743-4cf1-ace2-a4c10acae272\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>labels</th>\n",
              "      <th>f_0</th>\n",
              "      <th>f_1</th>\n",
              "      <th>f_2</th>\n",
              "      <th>f_3</th>\n",
              "      <th>f_4</th>\n",
              "      <th>f_5</th>\n",
              "      <th>f_6</th>\n",
              "      <th>f_7</th>\n",
              "      <th>f_8</th>\n",
              "      <th>...</th>\n",
              "      <th>f_1190</th>\n",
              "      <th>f_1191</th>\n",
              "      <th>f_1192</th>\n",
              "      <th>f_1193</th>\n",
              "      <th>f_1194</th>\n",
              "      <th>f_1195</th>\n",
              "      <th>f_1196</th>\n",
              "      <th>f_1197</th>\n",
              "      <th>f_1198</th>\n",
              "      <th>f_1199</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.348835</td>\n",
              "      <td>0.294815</td>\n",
              "      <td>-0.557577</td>\n",
              "      <td>-2.020773</td>\n",
              "      <td>-1.234715</td>\n",
              "      <td>1.633930</td>\n",
              "      <td>-1.680658</td>\n",
              "      <td>-0.358146</td>\n",
              "      <td>0.166122</td>\n",
              "      <td>...</td>\n",
              "      <td>0.735240</td>\n",
              "      <td>0.829781</td>\n",
              "      <td>1.521941</td>\n",
              "      <td>1.347946</td>\n",
              "      <td>0.754505</td>\n",
              "      <td>1.330642</td>\n",
              "      <td>-0.754453</td>\n",
              "      <td>0.582956</td>\n",
              "      <td>0.252671</td>\n",
              "      <td>1.495870</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0.113248</td>\n",
              "      <td>-0.607726</td>\n",
              "      <td>-0.947791</td>\n",
              "      <td>0.830851</td>\n",
              "      <td>0.998291</td>\n",
              "      <td>0.498321</td>\n",
              "      <td>-1.493958</td>\n",
              "      <td>0.789572</td>\n",
              "      <td>-1.311018</td>\n",
              "      <td>...</td>\n",
              "      <td>0.104698</td>\n",
              "      <td>0.616189</td>\n",
              "      <td>-1.035953</td>\n",
              "      <td>2.111387</td>\n",
              "      <td>-0.984415</td>\n",
              "      <td>1.148076</td>\n",
              "      <td>-1.433554</td>\n",
              "      <td>0.243372</td>\n",
              "      <td>0.170083</td>\n",
              "      <td>1.274795</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.932571</td>\n",
              "      <td>1.366246</td>\n",
              "      <td>0.364603</td>\n",
              "      <td>2.126203</td>\n",
              "      <td>0.705695</td>\n",
              "      <td>0.066673</td>\n",
              "      <td>-0.796001</td>\n",
              "      <td>-1.204584</td>\n",
              "      <td>-0.579558</td>\n",
              "      <td>...</td>\n",
              "      <td>0.403565</td>\n",
              "      <td>-0.092736</td>\n",
              "      <td>-0.051202</td>\n",
              "      <td>1.109147</td>\n",
              "      <td>0.028089</td>\n",
              "      <td>-0.467010</td>\n",
              "      <td>-0.072701</td>\n",
              "      <td>0.181085</td>\n",
              "      <td>1.065936</td>\n",
              "      <td>-1.294234</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1</td>\n",
              "      <td>-1.593680</td>\n",
              "      <td>-0.731218</td>\n",
              "      <td>-0.052828</td>\n",
              "      <td>-0.458814</td>\n",
              "      <td>-0.476738</td>\n",
              "      <td>0.887608</td>\n",
              "      <td>-0.460991</td>\n",
              "      <td>-0.059051</td>\n",
              "      <td>1.114105</td>\n",
              "      <td>...</td>\n",
              "      <td>0.547734</td>\n",
              "      <td>-0.512943</td>\n",
              "      <td>-0.023156</td>\n",
              "      <td>-0.021865</td>\n",
              "      <td>0.298182</td>\n",
              "      <td>-0.575766</td>\n",
              "      <td>-0.102218</td>\n",
              "      <td>0.731609</td>\n",
              "      <td>-0.248299</td>\n",
              "      <td>1.397388</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.490307</td>\n",
              "      <td>-1.185301</td>\n",
              "      <td>0.156087</td>\n",
              "      <td>-0.416752</td>\n",
              "      <td>0.498768</td>\n",
              "      <td>-0.392604</td>\n",
              "      <td>1.190598</td>\n",
              "      <td>1.749591</td>\n",
              "      <td>0.000897</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.164895</td>\n",
              "      <td>1.039613</td>\n",
              "      <td>1.532804</td>\n",
              "      <td>-1.713240</td>\n",
              "      <td>1.544514</td>\n",
              "      <td>-0.233746</td>\n",
              "      <td>0.902512</td>\n",
              "      <td>1.131872</td>\n",
              "      <td>-0.936994</td>\n",
              "      <td>0.126443</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>1</td>\n",
              "      <td>0.699435</td>\n",
              "      <td>-0.409208</td>\n",
              "      <td>-0.733523</td>\n",
              "      <td>1.063904</td>\n",
              "      <td>1.402882</td>\n",
              "      <td>0.121692</td>\n",
              "      <td>0.693201</td>\n",
              "      <td>-0.246482</td>\n",
              "      <td>-2.796173</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.600347</td>\n",
              "      <td>0.533398</td>\n",
              "      <td>0.811930</td>\n",
              "      <td>-0.950390</td>\n",
              "      <td>0.283361</td>\n",
              "      <td>0.166180</td>\n",
              "      <td>1.550970</td>\n",
              "      <td>0.392693</td>\n",
              "      <td>0.735159</td>\n",
              "      <td>0.244586</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>1</td>\n",
              "      <td>1.977668</td>\n",
              "      <td>0.078103</td>\n",
              "      <td>-0.337783</td>\n",
              "      <td>-1.474893</td>\n",
              "      <td>0.672837</td>\n",
              "      <td>0.592674</td>\n",
              "      <td>0.519973</td>\n",
              "      <td>-0.570367</td>\n",
              "      <td>-1.213920</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.156197</td>\n",
              "      <td>-0.002251</td>\n",
              "      <td>-0.822713</td>\n",
              "      <td>1.091787</td>\n",
              "      <td>0.761468</td>\n",
              "      <td>-0.238339</td>\n",
              "      <td>0.157990</td>\n",
              "      <td>0.267915</td>\n",
              "      <td>-0.602962</td>\n",
              "      <td>-2.379913</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>1</td>\n",
              "      <td>0.008912</td>\n",
              "      <td>0.501167</td>\n",
              "      <td>0.833886</td>\n",
              "      <td>-0.433362</td>\n",
              "      <td>-0.649726</td>\n",
              "      <td>0.537057</td>\n",
              "      <td>0.317005</td>\n",
              "      <td>0.159265</td>\n",
              "      <td>2.437977</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.465914</td>\n",
              "      <td>-1.942418</td>\n",
              "      <td>0.062264</td>\n",
              "      <td>0.208436</td>\n",
              "      <td>1.213639</td>\n",
              "      <td>-0.467115</td>\n",
              "      <td>-1.256437</td>\n",
              "      <td>-1.163842</td>\n",
              "      <td>-0.411401</td>\n",
              "      <td>-0.029953</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>1</td>\n",
              "      <td>0.512031</td>\n",
              "      <td>0.822484</td>\n",
              "      <td>-0.448323</td>\n",
              "      <td>-0.278851</td>\n",
              "      <td>-1.135995</td>\n",
              "      <td>-0.586103</td>\n",
              "      <td>1.547900</td>\n",
              "      <td>-1.577255</td>\n",
              "      <td>0.284239</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.794239</td>\n",
              "      <td>0.307278</td>\n",
              "      <td>-0.518308</td>\n",
              "      <td>-0.304720</td>\n",
              "      <td>0.368168</td>\n",
              "      <td>-0.772607</td>\n",
              "      <td>-1.797486</td>\n",
              "      <td>-0.253851</td>\n",
              "      <td>-0.859979</td>\n",
              "      <td>-0.981040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>1</td>\n",
              "      <td>1.275421</td>\n",
              "      <td>-1.374833</td>\n",
              "      <td>0.146325</td>\n",
              "      <td>0.261692</td>\n",
              "      <td>0.400923</td>\n",
              "      <td>0.457052</td>\n",
              "      <td>-1.296557</td>\n",
              "      <td>3.877255</td>\n",
              "      <td>0.439320</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.365889</td>\n",
              "      <td>0.408901</td>\n",
              "      <td>1.264185</td>\n",
              "      <td>-0.200257</td>\n",
              "      <td>0.827967</td>\n",
              "      <td>-3.114715</td>\n",
              "      <td>-2.880945</td>\n",
              "      <td>0.336202</td>\n",
              "      <td>-0.633886</td>\n",
              "      <td>0.595661</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 1201 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-444a67cd-4743-4cf1-ace2-a4c10acae272')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-444a67cd-4743-4cf1-ace2-a4c10acae272 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-444a67cd-4743-4cf1-ace2-a4c10acae272');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "8S_nH1BXcmJn",
        "outputId": "f116430b-5152-4058-a168-8eb2a80272e3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            labels          f_0          f_1          f_2          f_3  \\\n",
              "count  5250.000000  5250.000000  5250.000000  5250.000000  5250.000000   \n",
              "mean      0.266667     0.385453     0.086769     0.317084     0.400414   \n",
              "std       0.442259     0.929075     0.898979     0.969380     0.954504   \n",
              "min       0.000000    -3.462941    -3.605773    -4.078232    -3.344323   \n",
              "25%       0.000000    -0.286854    -0.470281    -0.379984    -0.290078   \n",
              "50%       0.000000     0.598422     0.071867     0.518698     0.653512   \n",
              "75%       1.000000     1.108212     0.609769     1.085552     1.135854   \n",
              "max       1.000000     3.439295     3.581171     3.991985     3.900672   \n",
              "\n",
              "               f_4          f_5          f_6          f_7          f_8  ...  \\\n",
              "count  5250.000000  5250.000000  5250.000000  5250.000000  5250.000000  ...   \n",
              "mean      0.093063     0.173532    -0.174072    -0.074659    -0.135957  ...   \n",
              "std       0.968625     0.895351     1.001566     0.906168     0.972163  ...   \n",
              "min      -3.613712    -3.319666    -3.627701    -3.528635    -4.503662  ...   \n",
              "25%      -0.644337    -0.392807    -0.980593    -0.677763    -0.914803  ...   \n",
              "50%       0.141549     0.237502    -0.180645    -0.159631    -0.108885  ...   \n",
              "75%       0.950304     0.747622     0.621790     0.450741     0.627055  ...   \n",
              "max       3.488667     3.193113     3.062756     3.877255     3.017000  ...   \n",
              "\n",
              "            f_1190       f_1191       f_1192       f_1193       f_1194  \\\n",
              "count  5250.000000  5250.000000  5250.000000  5250.000000  5250.000000   \n",
              "mean      0.417874    -0.405061     0.091497    -0.276132    -0.133123   \n",
              "std       0.941354     1.054231     0.958970     0.989820     1.042036   \n",
              "min      -3.684054    -3.385650    -3.162629    -3.022903    -3.698249   \n",
              "25%      -0.254776    -1.265848    -0.594289    -1.054700    -1.009256   \n",
              "50%       0.648944    -0.489479     0.192821    -0.301887    -0.139792   \n",
              "75%       1.131876     0.366639     0.779280     0.409370     0.740059   \n",
              "max       4.077517     3.550058     3.790435     3.907684     3.777545   \n",
              "\n",
              "            f_1195       f_1196       f_1197       f_1198       f_1199  \n",
              "count  5250.000000  5250.000000  5250.000000  5250.000000  5250.000000  \n",
              "mean     -0.156475    -0.096026     0.372260    -0.222551     0.006532  \n",
              "std       1.019384     0.913732     0.944429     0.973640     0.897006  \n",
              "min      -4.791005    -3.356509    -3.933762    -4.174752    -3.624981  \n",
              "25%      -0.833164    -0.684567    -0.301254    -1.010557    -0.564394  \n",
              "50%      -0.197277    -0.156927     0.612440    -0.241763    -0.008017  \n",
              "75%       0.493094     0.434146     1.109200     0.508097     0.552090  \n",
              "max       3.269490     3.526907     3.542401     3.642856     3.718869  \n",
              "\n",
              "[8 rows x 1201 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ed09833e-41fb-453d-a50e-03773dbb3734\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>labels</th>\n",
              "      <th>f_0</th>\n",
              "      <th>f_1</th>\n",
              "      <th>f_2</th>\n",
              "      <th>f_3</th>\n",
              "      <th>f_4</th>\n",
              "      <th>f_5</th>\n",
              "      <th>f_6</th>\n",
              "      <th>f_7</th>\n",
              "      <th>f_8</th>\n",
              "      <th>...</th>\n",
              "      <th>f_1190</th>\n",
              "      <th>f_1191</th>\n",
              "      <th>f_1192</th>\n",
              "      <th>f_1193</th>\n",
              "      <th>f_1194</th>\n",
              "      <th>f_1195</th>\n",
              "      <th>f_1196</th>\n",
              "      <th>f_1197</th>\n",
              "      <th>f_1198</th>\n",
              "      <th>f_1199</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>5250.000000</td>\n",
              "      <td>5250.000000</td>\n",
              "      <td>5250.000000</td>\n",
              "      <td>5250.000000</td>\n",
              "      <td>5250.000000</td>\n",
              "      <td>5250.000000</td>\n",
              "      <td>5250.000000</td>\n",
              "      <td>5250.000000</td>\n",
              "      <td>5250.000000</td>\n",
              "      <td>5250.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>5250.000000</td>\n",
              "      <td>5250.000000</td>\n",
              "      <td>5250.000000</td>\n",
              "      <td>5250.000000</td>\n",
              "      <td>5250.000000</td>\n",
              "      <td>5250.000000</td>\n",
              "      <td>5250.000000</td>\n",
              "      <td>5250.000000</td>\n",
              "      <td>5250.000000</td>\n",
              "      <td>5250.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.266667</td>\n",
              "      <td>0.385453</td>\n",
              "      <td>0.086769</td>\n",
              "      <td>0.317084</td>\n",
              "      <td>0.400414</td>\n",
              "      <td>0.093063</td>\n",
              "      <td>0.173532</td>\n",
              "      <td>-0.174072</td>\n",
              "      <td>-0.074659</td>\n",
              "      <td>-0.135957</td>\n",
              "      <td>...</td>\n",
              "      <td>0.417874</td>\n",
              "      <td>-0.405061</td>\n",
              "      <td>0.091497</td>\n",
              "      <td>-0.276132</td>\n",
              "      <td>-0.133123</td>\n",
              "      <td>-0.156475</td>\n",
              "      <td>-0.096026</td>\n",
              "      <td>0.372260</td>\n",
              "      <td>-0.222551</td>\n",
              "      <td>0.006532</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.442259</td>\n",
              "      <td>0.929075</td>\n",
              "      <td>0.898979</td>\n",
              "      <td>0.969380</td>\n",
              "      <td>0.954504</td>\n",
              "      <td>0.968625</td>\n",
              "      <td>0.895351</td>\n",
              "      <td>1.001566</td>\n",
              "      <td>0.906168</td>\n",
              "      <td>0.972163</td>\n",
              "      <td>...</td>\n",
              "      <td>0.941354</td>\n",
              "      <td>1.054231</td>\n",
              "      <td>0.958970</td>\n",
              "      <td>0.989820</td>\n",
              "      <td>1.042036</td>\n",
              "      <td>1.019384</td>\n",
              "      <td>0.913732</td>\n",
              "      <td>0.944429</td>\n",
              "      <td>0.973640</td>\n",
              "      <td>0.897006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>-3.462941</td>\n",
              "      <td>-3.605773</td>\n",
              "      <td>-4.078232</td>\n",
              "      <td>-3.344323</td>\n",
              "      <td>-3.613712</td>\n",
              "      <td>-3.319666</td>\n",
              "      <td>-3.627701</td>\n",
              "      <td>-3.528635</td>\n",
              "      <td>-4.503662</td>\n",
              "      <td>...</td>\n",
              "      <td>-3.684054</td>\n",
              "      <td>-3.385650</td>\n",
              "      <td>-3.162629</td>\n",
              "      <td>-3.022903</td>\n",
              "      <td>-3.698249</td>\n",
              "      <td>-4.791005</td>\n",
              "      <td>-3.356509</td>\n",
              "      <td>-3.933762</td>\n",
              "      <td>-4.174752</td>\n",
              "      <td>-3.624981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.286854</td>\n",
              "      <td>-0.470281</td>\n",
              "      <td>-0.379984</td>\n",
              "      <td>-0.290078</td>\n",
              "      <td>-0.644337</td>\n",
              "      <td>-0.392807</td>\n",
              "      <td>-0.980593</td>\n",
              "      <td>-0.677763</td>\n",
              "      <td>-0.914803</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.254776</td>\n",
              "      <td>-1.265848</td>\n",
              "      <td>-0.594289</td>\n",
              "      <td>-1.054700</td>\n",
              "      <td>-1.009256</td>\n",
              "      <td>-0.833164</td>\n",
              "      <td>-0.684567</td>\n",
              "      <td>-0.301254</td>\n",
              "      <td>-1.010557</td>\n",
              "      <td>-0.564394</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.598422</td>\n",
              "      <td>0.071867</td>\n",
              "      <td>0.518698</td>\n",
              "      <td>0.653512</td>\n",
              "      <td>0.141549</td>\n",
              "      <td>0.237502</td>\n",
              "      <td>-0.180645</td>\n",
              "      <td>-0.159631</td>\n",
              "      <td>-0.108885</td>\n",
              "      <td>...</td>\n",
              "      <td>0.648944</td>\n",
              "      <td>-0.489479</td>\n",
              "      <td>0.192821</td>\n",
              "      <td>-0.301887</td>\n",
              "      <td>-0.139792</td>\n",
              "      <td>-0.197277</td>\n",
              "      <td>-0.156927</td>\n",
              "      <td>0.612440</td>\n",
              "      <td>-0.241763</td>\n",
              "      <td>-0.008017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.108212</td>\n",
              "      <td>0.609769</td>\n",
              "      <td>1.085552</td>\n",
              "      <td>1.135854</td>\n",
              "      <td>0.950304</td>\n",
              "      <td>0.747622</td>\n",
              "      <td>0.621790</td>\n",
              "      <td>0.450741</td>\n",
              "      <td>0.627055</td>\n",
              "      <td>...</td>\n",
              "      <td>1.131876</td>\n",
              "      <td>0.366639</td>\n",
              "      <td>0.779280</td>\n",
              "      <td>0.409370</td>\n",
              "      <td>0.740059</td>\n",
              "      <td>0.493094</td>\n",
              "      <td>0.434146</td>\n",
              "      <td>1.109200</td>\n",
              "      <td>0.508097</td>\n",
              "      <td>0.552090</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.439295</td>\n",
              "      <td>3.581171</td>\n",
              "      <td>3.991985</td>\n",
              "      <td>3.900672</td>\n",
              "      <td>3.488667</td>\n",
              "      <td>3.193113</td>\n",
              "      <td>3.062756</td>\n",
              "      <td>3.877255</td>\n",
              "      <td>3.017000</td>\n",
              "      <td>...</td>\n",
              "      <td>4.077517</td>\n",
              "      <td>3.550058</td>\n",
              "      <td>3.790435</td>\n",
              "      <td>3.907684</td>\n",
              "      <td>3.777545</td>\n",
              "      <td>3.269490</td>\n",
              "      <td>3.526907</td>\n",
              "      <td>3.542401</td>\n",
              "      <td>3.642856</td>\n",
              "      <td>3.718869</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 1201 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ed09833e-41fb-453d-a50e-03773dbb3734')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ed09833e-41fb-453d-a50e-03773dbb3734 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ed09833e-41fb-453d-a50e-03773dbb3734');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X = df.drop(['labels'],axis=1)\n",
        "y = df['labels']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)"
      ],
      "metadata": {
        "id": "YXeaqRxmcv4B"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_try = df.iloc[:,1:1201]\n",
        "y_try = df.iloc[:,0]"
      ],
      "metadata": {
        "id": "nsG6gXrSc89W"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_try.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxHj0WnGc_k4",
        "outputId": "4efe1949-e01f-4ed9-b422-b01ce4b8d990"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5250, 1200)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_try"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U78CQDo3dCp1",
        "outputId": "b4b140da-2956-4e16-99c3-c90690ca1c35"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       0\n",
              "1       1\n",
              "2       1\n",
              "3       0\n",
              "4       0\n",
              "       ..\n",
              "5245    0\n",
              "5246    0\n",
              "5247    1\n",
              "5248    1\n",
              "5249    1\n",
              "Name: labels, Length: 5250, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_try, X_test_try, y_train_try, y_test_try = train_test_split(X_try, y_try, train_size=0.7, shuffle=True)"
      ],
      "metadata": {
        "id": "BhxLaHJVdKR9"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_try.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dq9F3DI9dNvb",
        "outputId": "d7f0192e-7aa2-419d-9738-5f9e091a13de"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5250,)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "X_try = torch.tensor(X_try.values, dtype=torch.float32)\n",
        "y_try = torch.tensor(y_try, dtype=torch.float32).reshape(-1, 1)"
      ],
      "metadata": {
        "id": "LuoJv16kdkue"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "gRlDF-WZdpmU",
        "outputId": "27ca6be4-2043-4b88-a1a0-b6ac6f1db10b"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           f_0       f_1       f_2       f_3       f_4       f_5       f_6  \\\n",
              "0    -2.033875  0.978446 -0.142131 -0.177117 -1.470684  1.669562 -0.196530   \n",
              "1    -0.348835  0.294815 -0.557577 -2.020773 -1.234715  1.633930 -1.680658   \n",
              "2     0.113248 -0.607726 -0.947791  0.830851  0.998291  0.498321 -1.493958   \n",
              "3     1.223321 -0.479048 -1.925789  1.680377  0.021840 -1.453307  0.605559   \n",
              "4     0.160109  0.422684 -0.308029  0.227744  0.432854  0.608348  0.193832   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "5245  1.157565 -0.142219  1.043992  1.144946  1.195423  0.248978 -1.505100   \n",
              "5246  1.424709  0.235910  1.356778  1.368099 -0.318862  1.039765 -0.986854   \n",
              "5247 -0.375687  1.524455  0.012514 -0.007917  0.073809 -0.906909 -1.254247   \n",
              "5248 -0.478238  1.666142  0.049609 -0.428752 -0.362771  1.798104 -0.214314   \n",
              "5249 -0.750874  0.267008 -0.155041 -0.179867 -0.155041 -0.303999 -0.279173   \n",
              "\n",
              "           f_7       f_8       f_9  ...    f_1190    f_1191    f_1192  \\\n",
              "0    -0.125239 -0.452284 -0.128052  ... -1.111266  0.716084  0.060039   \n",
              "1    -0.358146  0.166122 -1.656990  ...  0.735240  0.829781  1.521941   \n",
              "2     0.789572 -1.311018  0.848524  ...  0.104698  0.616189 -1.035953   \n",
              "3    -0.019024  1.065448  0.717341  ...  0.360237 -1.957863 -0.123384   \n",
              "4     1.035091 -0.538868  0.778445  ...  0.416629  1.441766  0.212572   \n",
              "...        ...       ...       ...  ...       ...       ...       ...   \n",
              "5245 -0.874137 -1.782724  0.261597  ...  1.195423 -0.255793 -0.154838   \n",
              "5246 -0.330184 -1.383120  1.243559  ...  1.424709 -1.066107  0.881258   \n",
              "5247  1.606182  0.298557  0.053378  ... -0.028349 -0.968204 -1.233815   \n",
              "5248  0.775400 -0.379267  0.725914  ... -0.428752 -1.121552 -0.379267   \n",
              "5249  1.731765  0.564925  1.508328  ... -0.303999 -0.850180  0.937321   \n",
              "\n",
              "        f_1193    f_1194    f_1195    f_1196    f_1197    f_1198    f_1199  \n",
              "0     0.301279 -1.174846 -1.076498 -0.069452 -0.604012 -2.179176  0.558003  \n",
              "1     1.347946  0.754505  1.330642 -0.754453  0.582956  0.252671  1.495870  \n",
              "2     2.111387 -0.984415  1.148076 -1.433554  0.243372  0.170083  1.274795  \n",
              "3     1.505329  0.660290 -1.769443 -0.547756 -0.568122  0.244645  0.982116  \n",
              "4    -0.994721  1.143999 -2.166923 -1.199248 -1.028636  0.752791  0.317169  \n",
              "...        ...       ...       ...       ...       ...       ...       ...  \n",
              "5245  0.413029 -0.482939 -1.277953 -0.445082  1.195423 -0.924614 -0.432462  \n",
              "5246 -0.488691 -1.281223 -1.213291  0.122692  1.175627 -1.145360  0.451026  \n",
              "5247  1.626613 -0.191802  1.115823  0.380284 -0.293960  0.135104  1.381434  \n",
              "5248 -0.593705  0.049609  1.765114  0.313533 -0.329781 -1.220524  0.033114  \n",
              "5249 -1.594972  1.036626  1.582807  1.036626 -0.254346  0.664230  1.831071  \n",
              "\n",
              "[5250 rows x 1200 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-46402721-4499-4a6e-803e-083e53e5ebf1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>f_0</th>\n",
              "      <th>f_1</th>\n",
              "      <th>f_2</th>\n",
              "      <th>f_3</th>\n",
              "      <th>f_4</th>\n",
              "      <th>f_5</th>\n",
              "      <th>f_6</th>\n",
              "      <th>f_7</th>\n",
              "      <th>f_8</th>\n",
              "      <th>f_9</th>\n",
              "      <th>...</th>\n",
              "      <th>f_1190</th>\n",
              "      <th>f_1191</th>\n",
              "      <th>f_1192</th>\n",
              "      <th>f_1193</th>\n",
              "      <th>f_1194</th>\n",
              "      <th>f_1195</th>\n",
              "      <th>f_1196</th>\n",
              "      <th>f_1197</th>\n",
              "      <th>f_1198</th>\n",
              "      <th>f_1199</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-2.033875</td>\n",
              "      <td>0.978446</td>\n",
              "      <td>-0.142131</td>\n",
              "      <td>-0.177117</td>\n",
              "      <td>-1.470684</td>\n",
              "      <td>1.669562</td>\n",
              "      <td>-0.196530</td>\n",
              "      <td>-0.125239</td>\n",
              "      <td>-0.452284</td>\n",
              "      <td>-0.128052</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.111266</td>\n",
              "      <td>0.716084</td>\n",
              "      <td>0.060039</td>\n",
              "      <td>0.301279</td>\n",
              "      <td>-1.174846</td>\n",
              "      <td>-1.076498</td>\n",
              "      <td>-0.069452</td>\n",
              "      <td>-0.604012</td>\n",
              "      <td>-2.179176</td>\n",
              "      <td>0.558003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.348835</td>\n",
              "      <td>0.294815</td>\n",
              "      <td>-0.557577</td>\n",
              "      <td>-2.020773</td>\n",
              "      <td>-1.234715</td>\n",
              "      <td>1.633930</td>\n",
              "      <td>-1.680658</td>\n",
              "      <td>-0.358146</td>\n",
              "      <td>0.166122</td>\n",
              "      <td>-1.656990</td>\n",
              "      <td>...</td>\n",
              "      <td>0.735240</td>\n",
              "      <td>0.829781</td>\n",
              "      <td>1.521941</td>\n",
              "      <td>1.347946</td>\n",
              "      <td>0.754505</td>\n",
              "      <td>1.330642</td>\n",
              "      <td>-0.754453</td>\n",
              "      <td>0.582956</td>\n",
              "      <td>0.252671</td>\n",
              "      <td>1.495870</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.113248</td>\n",
              "      <td>-0.607726</td>\n",
              "      <td>-0.947791</td>\n",
              "      <td>0.830851</td>\n",
              "      <td>0.998291</td>\n",
              "      <td>0.498321</td>\n",
              "      <td>-1.493958</td>\n",
              "      <td>0.789572</td>\n",
              "      <td>-1.311018</td>\n",
              "      <td>0.848524</td>\n",
              "      <td>...</td>\n",
              "      <td>0.104698</td>\n",
              "      <td>0.616189</td>\n",
              "      <td>-1.035953</td>\n",
              "      <td>2.111387</td>\n",
              "      <td>-0.984415</td>\n",
              "      <td>1.148076</td>\n",
              "      <td>-1.433554</td>\n",
              "      <td>0.243372</td>\n",
              "      <td>0.170083</td>\n",
              "      <td>1.274795</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.223321</td>\n",
              "      <td>-0.479048</td>\n",
              "      <td>-1.925789</td>\n",
              "      <td>1.680377</td>\n",
              "      <td>0.021840</td>\n",
              "      <td>-1.453307</td>\n",
              "      <td>0.605559</td>\n",
              "      <td>-0.019024</td>\n",
              "      <td>1.065448</td>\n",
              "      <td>0.717341</td>\n",
              "      <td>...</td>\n",
              "      <td>0.360237</td>\n",
              "      <td>-1.957863</td>\n",
              "      <td>-0.123384</td>\n",
              "      <td>1.505329</td>\n",
              "      <td>0.660290</td>\n",
              "      <td>-1.769443</td>\n",
              "      <td>-0.547756</td>\n",
              "      <td>-0.568122</td>\n",
              "      <td>0.244645</td>\n",
              "      <td>0.982116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.160109</td>\n",
              "      <td>0.422684</td>\n",
              "      <td>-0.308029</td>\n",
              "      <td>0.227744</td>\n",
              "      <td>0.432854</td>\n",
              "      <td>0.608348</td>\n",
              "      <td>0.193832</td>\n",
              "      <td>1.035091</td>\n",
              "      <td>-0.538868</td>\n",
              "      <td>0.778445</td>\n",
              "      <td>...</td>\n",
              "      <td>0.416629</td>\n",
              "      <td>1.441766</td>\n",
              "      <td>0.212572</td>\n",
              "      <td>-0.994721</td>\n",
              "      <td>1.143999</td>\n",
              "      <td>-2.166923</td>\n",
              "      <td>-1.199248</td>\n",
              "      <td>-1.028636</td>\n",
              "      <td>0.752791</td>\n",
              "      <td>0.317169</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5245</th>\n",
              "      <td>1.157565</td>\n",
              "      <td>-0.142219</td>\n",
              "      <td>1.043992</td>\n",
              "      <td>1.144946</td>\n",
              "      <td>1.195423</td>\n",
              "      <td>0.248978</td>\n",
              "      <td>-1.505100</td>\n",
              "      <td>-0.874137</td>\n",
              "      <td>-1.782724</td>\n",
              "      <td>0.261597</td>\n",
              "      <td>...</td>\n",
              "      <td>1.195423</td>\n",
              "      <td>-0.255793</td>\n",
              "      <td>-0.154838</td>\n",
              "      <td>0.413029</td>\n",
              "      <td>-0.482939</td>\n",
              "      <td>-1.277953</td>\n",
              "      <td>-0.445082</td>\n",
              "      <td>1.195423</td>\n",
              "      <td>-0.924614</td>\n",
              "      <td>-0.432462</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5246</th>\n",
              "      <td>1.424709</td>\n",
              "      <td>0.235910</td>\n",
              "      <td>1.356778</td>\n",
              "      <td>1.368099</td>\n",
              "      <td>-0.318862</td>\n",
              "      <td>1.039765</td>\n",
              "      <td>-0.986854</td>\n",
              "      <td>-0.330184</td>\n",
              "      <td>-1.383120</td>\n",
              "      <td>1.243559</td>\n",
              "      <td>...</td>\n",
              "      <td>1.424709</td>\n",
              "      <td>-1.066107</td>\n",
              "      <td>0.881258</td>\n",
              "      <td>-0.488691</td>\n",
              "      <td>-1.281223</td>\n",
              "      <td>-1.213291</td>\n",
              "      <td>0.122692</td>\n",
              "      <td>1.175627</td>\n",
              "      <td>-1.145360</td>\n",
              "      <td>0.451026</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5247</th>\n",
              "      <td>-0.375687</td>\n",
              "      <td>1.524455</td>\n",
              "      <td>0.012514</td>\n",
              "      <td>-0.007917</td>\n",
              "      <td>0.073809</td>\n",
              "      <td>-0.906909</td>\n",
              "      <td>-1.254247</td>\n",
              "      <td>1.606182</td>\n",
              "      <td>0.298557</td>\n",
              "      <td>0.053378</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.028349</td>\n",
              "      <td>-0.968204</td>\n",
              "      <td>-1.233815</td>\n",
              "      <td>1.626613</td>\n",
              "      <td>-0.191802</td>\n",
              "      <td>1.115823</td>\n",
              "      <td>0.380284</td>\n",
              "      <td>-0.293960</td>\n",
              "      <td>0.135104</td>\n",
              "      <td>1.381434</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5248</th>\n",
              "      <td>-0.478238</td>\n",
              "      <td>1.666142</td>\n",
              "      <td>0.049609</td>\n",
              "      <td>-0.428752</td>\n",
              "      <td>-0.362771</td>\n",
              "      <td>1.798104</td>\n",
              "      <td>-0.214314</td>\n",
              "      <td>0.775400</td>\n",
              "      <td>-0.379267</td>\n",
              "      <td>0.725914</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.428752</td>\n",
              "      <td>-1.121552</td>\n",
              "      <td>-0.379267</td>\n",
              "      <td>-0.593705</td>\n",
              "      <td>0.049609</td>\n",
              "      <td>1.765114</td>\n",
              "      <td>0.313533</td>\n",
              "      <td>-0.329781</td>\n",
              "      <td>-1.220524</td>\n",
              "      <td>0.033114</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5249</th>\n",
              "      <td>-0.750874</td>\n",
              "      <td>0.267008</td>\n",
              "      <td>-0.155041</td>\n",
              "      <td>-0.179867</td>\n",
              "      <td>-0.155041</td>\n",
              "      <td>-0.303999</td>\n",
              "      <td>-0.279173</td>\n",
              "      <td>1.731765</td>\n",
              "      <td>0.564925</td>\n",
              "      <td>1.508328</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.303999</td>\n",
              "      <td>-0.850180</td>\n",
              "      <td>0.937321</td>\n",
              "      <td>-1.594972</td>\n",
              "      <td>1.036626</td>\n",
              "      <td>1.582807</td>\n",
              "      <td>1.036626</td>\n",
              "      <td>-0.254346</td>\n",
              "      <td>0.664230</td>\n",
              "      <td>1.831071</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5250 rows × 1200 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-46402721-4499-4a6e-803e-083e53e5ebf1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-46402721-4499-4a6e-803e-083e53e5ebf1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-46402721-4499-4a6e-803e-083e53e5ebf1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "xF9ixEexduG9",
        "outputId": "21d7a558-a3c9-49bc-c42c-d6f107b82c90"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           f_0       f_1       f_2       f_3       f_4       f_5       f_6  \\\n",
              "4609  1.166039  0.410565  0.831472  0.939397  0.183922  0.960982 -1.488915   \n",
              "4767  1.463656  0.251083  1.318147  1.366650 -0.476460  0.275335 -1.313135   \n",
              "3481  1.272077  0.707197  1.232436  1.272077  0.023396  1.083783 -1.175733   \n",
              "3480  1.130936  0.258055  1.058196  1.821966 -0.578455  1.058196 -0.833045   \n",
              "1795 -0.840447 -0.472406  0.516034  1.109274  0.582020  0.591840  0.238144   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "3335  0.474419 -0.113313  0.488412  1.733844  0.572374 -0.379192 -1.596637   \n",
              "1099 -0.421378  1.462126 -1.275895  1.158129  1.327889 -0.358845 -1.410703   \n",
              "2514  0.072249 -1.201610  0.790880  0.218083 -0.422327  0.145970  0.901358   \n",
              "3606  1.352592  0.331141  1.190654  1.190654  0.007266  1.066087 -0.976814   \n",
              "2575  0.220324 -0.109989  0.918214 -0.413464 -0.806526 -0.123946 -0.194320   \n",
              "\n",
              "           f_7       f_8       f_9  ...    f_1190    f_1191    f_1192  \\\n",
              "4609 -0.161438 -1.467330  0.982567  ...  1.004152 -1.273065  0.615622   \n",
              "4767 -0.355203 -1.143375  0.978627  ...  1.354524 -0.803855  1.075632   \n",
              "3481  0.409893 -1.205464  0.806299  ...  1.252256 -0.987440  1.133334   \n",
              "3480  0.124699 -1.148252  0.718742  ...  1.821966 -0.663318 -0.032905   \n",
              "1795 -0.422780  0.613405  0.637375  ... -1.252584 -2.301808 -0.442274   \n",
              "...        ...       ...       ...  ...       ...       ...       ...   \n",
              "3335 -0.868969  0.530393 -0.183281  ...  1.789819  0.166559  1.188093   \n",
              "1099  0.303408 -0.398474  0.507667  ...  1.076916  0.351943  0.819817   \n",
              "2514 -0.466246  0.487091  1.264977  ...  0.970406 -0.451735  0.985949   \n",
              "3606 -0.017647 -1.126295  1.003804  ...  1.277851 -1.475083 -0.117301   \n",
              "2575 -0.617532 -1.329466 -0.438792  ... -1.127819 -0.011199 -0.411279   \n",
              "\n",
              "        f_1193    f_1194    f_1195    f_1196    f_1197    f_1198    f_1199  \n",
              "4609 -0.808988  0.766717  0.108375 -0.042720  0.950189 -1.586047  0.173130  \n",
              "4767 -0.270323  1.318147 -0.100563 -0.039934  1.257518 -1.422266  0.578478  \n",
              "3481  0.409893 -1.165823 -0.373010  0.618006  1.272077 -1.215374  0.479264  \n",
              "3480 -1.002772 -0.978525 -0.784552  0.173192  1.143059 -1.039142  0.306549  \n",
              "1795  0.861663 -0.560699  0.540608  0.142927  1.275490  1.071340  0.876267  \n",
              "...        ...       ...       ...       ...       ...       ...       ...  \n",
              "3335  0.782278  0.698316 -1.750567 -0.924943  0.530393 -0.799001 -0.561109  \n",
              "1099  0.718917  1.136913  0.337254 -0.586579  1.510014 -1.026841  0.395185  \n",
              "2514  1.541963 -0.225305 -2.385345  0.196546  0.335510 -1.832958  0.166655  \n",
              "3606 -0.914530  0.106920  0.206574 -0.030104  1.115914 -1.176121  0.380968  \n",
              "2575 -0.506249 -0.837173 -0.742393 -0.291009 -0.410843 -1.572290  0.167870  \n",
              "\n",
              "[4200 rows x 1200 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8fca8e28-6e4e-4e4c-9542-ab0ebc9e4dcd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>f_0</th>\n",
              "      <th>f_1</th>\n",
              "      <th>f_2</th>\n",
              "      <th>f_3</th>\n",
              "      <th>f_4</th>\n",
              "      <th>f_5</th>\n",
              "      <th>f_6</th>\n",
              "      <th>f_7</th>\n",
              "      <th>f_8</th>\n",
              "      <th>f_9</th>\n",
              "      <th>...</th>\n",
              "      <th>f_1190</th>\n",
              "      <th>f_1191</th>\n",
              "      <th>f_1192</th>\n",
              "      <th>f_1193</th>\n",
              "      <th>f_1194</th>\n",
              "      <th>f_1195</th>\n",
              "      <th>f_1196</th>\n",
              "      <th>f_1197</th>\n",
              "      <th>f_1198</th>\n",
              "      <th>f_1199</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4609</th>\n",
              "      <td>1.166039</td>\n",
              "      <td>0.410565</td>\n",
              "      <td>0.831472</td>\n",
              "      <td>0.939397</td>\n",
              "      <td>0.183922</td>\n",
              "      <td>0.960982</td>\n",
              "      <td>-1.488915</td>\n",
              "      <td>-0.161438</td>\n",
              "      <td>-1.467330</td>\n",
              "      <td>0.982567</td>\n",
              "      <td>...</td>\n",
              "      <td>1.004152</td>\n",
              "      <td>-1.273065</td>\n",
              "      <td>0.615622</td>\n",
              "      <td>-0.808988</td>\n",
              "      <td>0.766717</td>\n",
              "      <td>0.108375</td>\n",
              "      <td>-0.042720</td>\n",
              "      <td>0.950189</td>\n",
              "      <td>-1.586047</td>\n",
              "      <td>0.173130</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4767</th>\n",
              "      <td>1.463656</td>\n",
              "      <td>0.251083</td>\n",
              "      <td>1.318147</td>\n",
              "      <td>1.366650</td>\n",
              "      <td>-0.476460</td>\n",
              "      <td>0.275335</td>\n",
              "      <td>-1.313135</td>\n",
              "      <td>-0.355203</td>\n",
              "      <td>-1.143375</td>\n",
              "      <td>0.978627</td>\n",
              "      <td>...</td>\n",
              "      <td>1.354524</td>\n",
              "      <td>-0.803855</td>\n",
              "      <td>1.075632</td>\n",
              "      <td>-0.270323</td>\n",
              "      <td>1.318147</td>\n",
              "      <td>-0.100563</td>\n",
              "      <td>-0.039934</td>\n",
              "      <td>1.257518</td>\n",
              "      <td>-1.422266</td>\n",
              "      <td>0.578478</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3481</th>\n",
              "      <td>1.272077</td>\n",
              "      <td>0.707197</td>\n",
              "      <td>1.232436</td>\n",
              "      <td>1.272077</td>\n",
              "      <td>0.023396</td>\n",
              "      <td>1.083783</td>\n",
              "      <td>-1.175733</td>\n",
              "      <td>0.409893</td>\n",
              "      <td>-1.205464</td>\n",
              "      <td>0.806299</td>\n",
              "      <td>...</td>\n",
              "      <td>1.252256</td>\n",
              "      <td>-0.987440</td>\n",
              "      <td>1.133334</td>\n",
              "      <td>0.409893</td>\n",
              "      <td>-1.165823</td>\n",
              "      <td>-0.373010</td>\n",
              "      <td>0.618006</td>\n",
              "      <td>1.272077</td>\n",
              "      <td>-1.215374</td>\n",
              "      <td>0.479264</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3480</th>\n",
              "      <td>1.130936</td>\n",
              "      <td>0.258055</td>\n",
              "      <td>1.058196</td>\n",
              "      <td>1.821966</td>\n",
              "      <td>-0.578455</td>\n",
              "      <td>1.058196</td>\n",
              "      <td>-0.833045</td>\n",
              "      <td>0.124699</td>\n",
              "      <td>-1.148252</td>\n",
              "      <td>0.718742</td>\n",
              "      <td>...</td>\n",
              "      <td>1.821966</td>\n",
              "      <td>-0.663318</td>\n",
              "      <td>-0.032905</td>\n",
              "      <td>-1.002772</td>\n",
              "      <td>-0.978525</td>\n",
              "      <td>-0.784552</td>\n",
              "      <td>0.173192</td>\n",
              "      <td>1.143059</td>\n",
              "      <td>-1.039142</td>\n",
              "      <td>0.306549</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1795</th>\n",
              "      <td>-0.840447</td>\n",
              "      <td>-0.472406</td>\n",
              "      <td>0.516034</td>\n",
              "      <td>1.109274</td>\n",
              "      <td>0.582020</td>\n",
              "      <td>0.591840</td>\n",
              "      <td>0.238144</td>\n",
              "      <td>-0.422780</td>\n",
              "      <td>0.613405</td>\n",
              "      <td>0.637375</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.252584</td>\n",
              "      <td>-2.301808</td>\n",
              "      <td>-0.442274</td>\n",
              "      <td>0.861663</td>\n",
              "      <td>-0.560699</td>\n",
              "      <td>0.540608</td>\n",
              "      <td>0.142927</td>\n",
              "      <td>1.275490</td>\n",
              "      <td>1.071340</td>\n",
              "      <td>0.876267</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3335</th>\n",
              "      <td>0.474419</td>\n",
              "      <td>-0.113313</td>\n",
              "      <td>0.488412</td>\n",
              "      <td>1.733844</td>\n",
              "      <td>0.572374</td>\n",
              "      <td>-0.379192</td>\n",
              "      <td>-1.596637</td>\n",
              "      <td>-0.868969</td>\n",
              "      <td>0.530393</td>\n",
              "      <td>-0.183281</td>\n",
              "      <td>...</td>\n",
              "      <td>1.789819</td>\n",
              "      <td>0.166559</td>\n",
              "      <td>1.188093</td>\n",
              "      <td>0.782278</td>\n",
              "      <td>0.698316</td>\n",
              "      <td>-1.750567</td>\n",
              "      <td>-0.924943</td>\n",
              "      <td>0.530393</td>\n",
              "      <td>-0.799001</td>\n",
              "      <td>-0.561109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1099</th>\n",
              "      <td>-0.421378</td>\n",
              "      <td>1.462126</td>\n",
              "      <td>-1.275895</td>\n",
              "      <td>1.158129</td>\n",
              "      <td>1.327889</td>\n",
              "      <td>-0.358845</td>\n",
              "      <td>-1.410703</td>\n",
              "      <td>0.303408</td>\n",
              "      <td>-0.398474</td>\n",
              "      <td>0.507667</td>\n",
              "      <td>...</td>\n",
              "      <td>1.076916</td>\n",
              "      <td>0.351943</td>\n",
              "      <td>0.819817</td>\n",
              "      <td>0.718917</td>\n",
              "      <td>1.136913</td>\n",
              "      <td>0.337254</td>\n",
              "      <td>-0.586579</td>\n",
              "      <td>1.510014</td>\n",
              "      <td>-1.026841</td>\n",
              "      <td>0.395185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2514</th>\n",
              "      <td>0.072249</td>\n",
              "      <td>-1.201610</td>\n",
              "      <td>0.790880</td>\n",
              "      <td>0.218083</td>\n",
              "      <td>-0.422327</td>\n",
              "      <td>0.145970</td>\n",
              "      <td>0.901358</td>\n",
              "      <td>-0.466246</td>\n",
              "      <td>0.487091</td>\n",
              "      <td>1.264977</td>\n",
              "      <td>...</td>\n",
              "      <td>0.970406</td>\n",
              "      <td>-0.451735</td>\n",
              "      <td>0.985949</td>\n",
              "      <td>1.541963</td>\n",
              "      <td>-0.225305</td>\n",
              "      <td>-2.385345</td>\n",
              "      <td>0.196546</td>\n",
              "      <td>0.335510</td>\n",
              "      <td>-1.832958</td>\n",
              "      <td>0.166655</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3606</th>\n",
              "      <td>1.352592</td>\n",
              "      <td>0.331141</td>\n",
              "      <td>1.190654</td>\n",
              "      <td>1.190654</td>\n",
              "      <td>0.007266</td>\n",
              "      <td>1.066087</td>\n",
              "      <td>-0.976814</td>\n",
              "      <td>-0.017647</td>\n",
              "      <td>-1.126295</td>\n",
              "      <td>1.003804</td>\n",
              "      <td>...</td>\n",
              "      <td>1.277851</td>\n",
              "      <td>-1.475083</td>\n",
              "      <td>-0.117301</td>\n",
              "      <td>-0.914530</td>\n",
              "      <td>0.106920</td>\n",
              "      <td>0.206574</td>\n",
              "      <td>-0.030104</td>\n",
              "      <td>1.115914</td>\n",
              "      <td>-1.176121</td>\n",
              "      <td>0.380968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2575</th>\n",
              "      <td>0.220324</td>\n",
              "      <td>-0.109989</td>\n",
              "      <td>0.918214</td>\n",
              "      <td>-0.413464</td>\n",
              "      <td>-0.806526</td>\n",
              "      <td>-0.123946</td>\n",
              "      <td>-0.194320</td>\n",
              "      <td>-0.617532</td>\n",
              "      <td>-1.329466</td>\n",
              "      <td>-0.438792</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.127819</td>\n",
              "      <td>-0.011199</td>\n",
              "      <td>-0.411279</td>\n",
              "      <td>-0.506249</td>\n",
              "      <td>-0.837173</td>\n",
              "      <td>-0.742393</td>\n",
              "      <td>-0.291009</td>\n",
              "      <td>-0.410843</td>\n",
              "      <td>-1.572290</td>\n",
              "      <td>0.167870</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4200 rows × 1200 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8fca8e28-6e4e-4e4c-9542-ab0ebc9e4dcd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8fca8e28-6e4e-4e4c-9542-ab0ebc9e4dcd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8fca8e28-6e4e-4e4c-9542-ab0ebc9e4dcd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "kl203bjIdxEm",
        "outputId": "8f574b50-0333-40a3-a5af-066e27f14cf2"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           f_0       f_1       f_2       f_3       f_4       f_5       f_6  \\\n",
              "622   0.414507 -0.084732  0.817176  1.699438 -0.177796  2.197731 -0.946666   \n",
              "4709  0.846881 -0.038140  1.127840  1.085696  0.846881  0.299011 -0.473627   \n",
              "1471  0.603621 -0.854295 -0.790347 -0.576797  1.137031 -0.621563 -0.836415   \n",
              "4030  0.948981  0.537924  0.948981  0.948981  0.927901 -0.747949  0.885742   \n",
              "4100  0.342467  1.771953 -0.023621  0.481929 -0.075920  1.841684 -0.651201   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "1614 -0.477779 -2.327928 -0.173024  0.914004  0.698379  0.318776 -2.158623   \n",
              "1239  0.997471  0.229178 -0.140462  0.977226  1.013152  0.259783 -0.277012   \n",
              "5234  0.379699  0.630899  0.572930  0.263760  0.495637  0.708191  0.572930   \n",
              "1298 -0.800257 -0.680145  2.461833 -1.628303  0.460057 -0.123933 -1.444007   \n",
              "5204  0.371371  1.580607 -0.003321  0.388403 -1.587249  1.836079  0.166994   \n",
              "\n",
              "           f_7       f_8       f_9  ...    f_1190    f_1191    f_1192  \\\n",
              "622  -0.272134  0.220641  0.706877  ...  1.480261 -1.049922  0.140801   \n",
              "4709 -0.712442 -0.305051  0.945216  ...  1.071648 -1.780086  0.523778   \n",
              "1471 -0.664562  2.069877 -1.605179  ... -0.086227 -1.323784  0.511916   \n",
              "4030  0.169026  0.084706  0.948981  ...  0.917361 -1.232787 -0.252572   \n",
              "4100  0.063542  0.551660  0.970046  ...  0.516794  0.150706 -0.145651   \n",
              "...        ...       ...       ...  ...       ...       ...       ...   \n",
              "1614 -0.768339  2.310280 -0.988883  ... -0.282483 -0.540868  0.184609   \n",
              "1239  2.619211 -0.861281  0.218731  ...  1.179650  0.283766 -1.275039   \n",
              "5234 -1.475318  0.321730 -0.760364  ...  0.283083 -2.248242 -0.663748   \n",
              "1298  1.486262  1.302783 -0.234174  ... -0.418349  0.326167  0.574420   \n",
              "5204  0.422466 -1.365840  1.631701  ...  0.388403  1.086694  1.546544   \n",
              "\n",
              "        f_1193    f_1194    f_1195    f_1196    f_1197    f_1198    f_1199  \n",
              "622   0.806468  0.618929 -0.921879 -0.496920  1.165440  3.335078  1.348169  \n",
              "4709 -1.639607 -0.473627 -0.656250 -0.024092  1.127840 -0.656250  0.327107  \n",
              "1471  1.455155  0.518500 -0.299079  0.206391  1.487134 -1.037806 -0.833084  \n",
              "4030 -1.211707 -1.380346  0.485224  0.390364  0.906822 -1.454126  0.126866  \n",
              "4100 -0.999856 -0.197949  1.859117  0.603958  0.464496  0.080975  0.429630  \n",
              "...        ...       ...       ...       ...       ...       ...       ...  \n",
              "1614  0.353144  0.785386 -1.272865 -1.166833  1.807885 -0.993463  0.623806  \n",
              "1239  0.051749 -0.025880  2.117535  1.554742  0.547960  0.188821  0.070420  \n",
              "5234 -2.383504 -0.799010  1.287884  0.070529  0.418345  0.592253 -0.876302  \n",
              "1298  0.487766  0.725005 -1.273332 -0.844419  0.409891 -0.590461  0.465109  \n",
              "5204 -0.292856 -0.309888  1.257009 -0.207699  0.422466  0.201057  1.103725  \n",
              "\n",
              "[1050 rows x 1200 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a4b73862-625e-4fd1-bd53-e7f940e320bb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>f_0</th>\n",
              "      <th>f_1</th>\n",
              "      <th>f_2</th>\n",
              "      <th>f_3</th>\n",
              "      <th>f_4</th>\n",
              "      <th>f_5</th>\n",
              "      <th>f_6</th>\n",
              "      <th>f_7</th>\n",
              "      <th>f_8</th>\n",
              "      <th>f_9</th>\n",
              "      <th>...</th>\n",
              "      <th>f_1190</th>\n",
              "      <th>f_1191</th>\n",
              "      <th>f_1192</th>\n",
              "      <th>f_1193</th>\n",
              "      <th>f_1194</th>\n",
              "      <th>f_1195</th>\n",
              "      <th>f_1196</th>\n",
              "      <th>f_1197</th>\n",
              "      <th>f_1198</th>\n",
              "      <th>f_1199</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>622</th>\n",
              "      <td>0.414507</td>\n",
              "      <td>-0.084732</td>\n",
              "      <td>0.817176</td>\n",
              "      <td>1.699438</td>\n",
              "      <td>-0.177796</td>\n",
              "      <td>2.197731</td>\n",
              "      <td>-0.946666</td>\n",
              "      <td>-0.272134</td>\n",
              "      <td>0.220641</td>\n",
              "      <td>0.706877</td>\n",
              "      <td>...</td>\n",
              "      <td>1.480261</td>\n",
              "      <td>-1.049922</td>\n",
              "      <td>0.140801</td>\n",
              "      <td>0.806468</td>\n",
              "      <td>0.618929</td>\n",
              "      <td>-0.921879</td>\n",
              "      <td>-0.496920</td>\n",
              "      <td>1.165440</td>\n",
              "      <td>3.335078</td>\n",
              "      <td>1.348169</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4709</th>\n",
              "      <td>0.846881</td>\n",
              "      <td>-0.038140</td>\n",
              "      <td>1.127840</td>\n",
              "      <td>1.085696</td>\n",
              "      <td>0.846881</td>\n",
              "      <td>0.299011</td>\n",
              "      <td>-0.473627</td>\n",
              "      <td>-0.712442</td>\n",
              "      <td>-0.305051</td>\n",
              "      <td>0.945216</td>\n",
              "      <td>...</td>\n",
              "      <td>1.071648</td>\n",
              "      <td>-1.780086</td>\n",
              "      <td>0.523778</td>\n",
              "      <td>-1.639607</td>\n",
              "      <td>-0.473627</td>\n",
              "      <td>-0.656250</td>\n",
              "      <td>-0.024092</td>\n",
              "      <td>1.127840</td>\n",
              "      <td>-0.656250</td>\n",
              "      <td>0.327107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1471</th>\n",
              "      <td>0.603621</td>\n",
              "      <td>-0.854295</td>\n",
              "      <td>-0.790347</td>\n",
              "      <td>-0.576797</td>\n",
              "      <td>1.137031</td>\n",
              "      <td>-0.621563</td>\n",
              "      <td>-0.836415</td>\n",
              "      <td>-0.664562</td>\n",
              "      <td>2.069877</td>\n",
              "      <td>-1.605179</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.086227</td>\n",
              "      <td>-1.323784</td>\n",
              "      <td>0.511916</td>\n",
              "      <td>1.455155</td>\n",
              "      <td>0.518500</td>\n",
              "      <td>-0.299079</td>\n",
              "      <td>0.206391</td>\n",
              "      <td>1.487134</td>\n",
              "      <td>-1.037806</td>\n",
              "      <td>-0.833084</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4030</th>\n",
              "      <td>0.948981</td>\n",
              "      <td>0.537924</td>\n",
              "      <td>0.948981</td>\n",
              "      <td>0.948981</td>\n",
              "      <td>0.927901</td>\n",
              "      <td>-0.747949</td>\n",
              "      <td>0.885742</td>\n",
              "      <td>0.169026</td>\n",
              "      <td>0.084706</td>\n",
              "      <td>0.948981</td>\n",
              "      <td>...</td>\n",
              "      <td>0.917361</td>\n",
              "      <td>-1.232787</td>\n",
              "      <td>-0.252572</td>\n",
              "      <td>-1.211707</td>\n",
              "      <td>-1.380346</td>\n",
              "      <td>0.485224</td>\n",
              "      <td>0.390364</td>\n",
              "      <td>0.906822</td>\n",
              "      <td>-1.454126</td>\n",
              "      <td>0.126866</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4100</th>\n",
              "      <td>0.342467</td>\n",
              "      <td>1.771953</td>\n",
              "      <td>-0.023621</td>\n",
              "      <td>0.481929</td>\n",
              "      <td>-0.075920</td>\n",
              "      <td>1.841684</td>\n",
              "      <td>-0.651201</td>\n",
              "      <td>0.063542</td>\n",
              "      <td>0.551660</td>\n",
              "      <td>0.970046</td>\n",
              "      <td>...</td>\n",
              "      <td>0.516794</td>\n",
              "      <td>0.150706</td>\n",
              "      <td>-0.145651</td>\n",
              "      <td>-0.999856</td>\n",
              "      <td>-0.197949</td>\n",
              "      <td>1.859117</td>\n",
              "      <td>0.603958</td>\n",
              "      <td>0.464496</td>\n",
              "      <td>0.080975</td>\n",
              "      <td>0.429630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1614</th>\n",
              "      <td>-0.477779</td>\n",
              "      <td>-2.327928</td>\n",
              "      <td>-0.173024</td>\n",
              "      <td>0.914004</td>\n",
              "      <td>0.698379</td>\n",
              "      <td>0.318776</td>\n",
              "      <td>-2.158623</td>\n",
              "      <td>-0.768339</td>\n",
              "      <td>2.310280</td>\n",
              "      <td>-0.988883</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.282483</td>\n",
              "      <td>-0.540868</td>\n",
              "      <td>0.184609</td>\n",
              "      <td>0.353144</td>\n",
              "      <td>0.785386</td>\n",
              "      <td>-1.272865</td>\n",
              "      <td>-1.166833</td>\n",
              "      <td>1.807885</td>\n",
              "      <td>-0.993463</td>\n",
              "      <td>0.623806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1239</th>\n",
              "      <td>0.997471</td>\n",
              "      <td>0.229178</td>\n",
              "      <td>-0.140462</td>\n",
              "      <td>0.977226</td>\n",
              "      <td>1.013152</td>\n",
              "      <td>0.259783</td>\n",
              "      <td>-0.277012</td>\n",
              "      <td>2.619211</td>\n",
              "      <td>-0.861281</td>\n",
              "      <td>0.218731</td>\n",
              "      <td>...</td>\n",
              "      <td>1.179650</td>\n",
              "      <td>0.283766</td>\n",
              "      <td>-1.275039</td>\n",
              "      <td>0.051749</td>\n",
              "      <td>-0.025880</td>\n",
              "      <td>2.117535</td>\n",
              "      <td>1.554742</td>\n",
              "      <td>0.547960</td>\n",
              "      <td>0.188821</td>\n",
              "      <td>0.070420</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5234</th>\n",
              "      <td>0.379699</td>\n",
              "      <td>0.630899</td>\n",
              "      <td>0.572930</td>\n",
              "      <td>0.263760</td>\n",
              "      <td>0.495637</td>\n",
              "      <td>0.708191</td>\n",
              "      <td>0.572930</td>\n",
              "      <td>-1.475318</td>\n",
              "      <td>0.321730</td>\n",
              "      <td>-0.760364</td>\n",
              "      <td>...</td>\n",
              "      <td>0.283083</td>\n",
              "      <td>-2.248242</td>\n",
              "      <td>-0.663748</td>\n",
              "      <td>-2.383504</td>\n",
              "      <td>-0.799010</td>\n",
              "      <td>1.287884</td>\n",
              "      <td>0.070529</td>\n",
              "      <td>0.418345</td>\n",
              "      <td>0.592253</td>\n",
              "      <td>-0.876302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1298</th>\n",
              "      <td>-0.800257</td>\n",
              "      <td>-0.680145</td>\n",
              "      <td>2.461833</td>\n",
              "      <td>-1.628303</td>\n",
              "      <td>0.460057</td>\n",
              "      <td>-0.123933</td>\n",
              "      <td>-1.444007</td>\n",
              "      <td>1.486262</td>\n",
              "      <td>1.302783</td>\n",
              "      <td>-0.234174</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.418349</td>\n",
              "      <td>0.326167</td>\n",
              "      <td>0.574420</td>\n",
              "      <td>0.487766</td>\n",
              "      <td>0.725005</td>\n",
              "      <td>-1.273332</td>\n",
              "      <td>-0.844419</td>\n",
              "      <td>0.409891</td>\n",
              "      <td>-0.590461</td>\n",
              "      <td>0.465109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5204</th>\n",
              "      <td>0.371371</td>\n",
              "      <td>1.580607</td>\n",
              "      <td>-0.003321</td>\n",
              "      <td>0.388403</td>\n",
              "      <td>-1.587249</td>\n",
              "      <td>1.836079</td>\n",
              "      <td>0.166994</td>\n",
              "      <td>0.422466</td>\n",
              "      <td>-1.365840</td>\n",
              "      <td>1.631701</td>\n",
              "      <td>...</td>\n",
              "      <td>0.388403</td>\n",
              "      <td>1.086694</td>\n",
              "      <td>1.546544</td>\n",
              "      <td>-0.292856</td>\n",
              "      <td>-0.309888</td>\n",
              "      <td>1.257009</td>\n",
              "      <td>-0.207699</td>\n",
              "      <td>0.422466</td>\n",
              "      <td>0.201057</td>\n",
              "      <td>1.103725</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1050 rows × 1200 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a4b73862-625e-4fd1-bd53-e7f940e320bb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a4b73862-625e-4fd1-bd53-e7f940e320bb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a4b73862-625e-4fd1-bd53-e7f940e320bb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-MNvY3cd0K-",
        "outputId": "ec834cce-943b-4042-b8df-e97070b1513a"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       0\n",
              "1       1\n",
              "2       1\n",
              "3       0\n",
              "4       0\n",
              "       ..\n",
              "5245    0\n",
              "5246    0\n",
              "5247    1\n",
              "5248    1\n",
              "5249    1\n",
              "Name: labels, Length: 5250, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training Using Logistic Regression"
      ],
      "metadata": {
        "id": "9mLsqftUybZU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# training using regression\n",
        "model_LG = LinearRegression()\n",
        "model_LG.fit(X_train, y_train)\n",
        "y_predlinear = model_LG.predict(X_test)\n",
        "# print(y_predlinear)\n",
        "y_predlinear_new = []\n",
        "for target in y_predlinear:\n",
        "  y_predlinear_new.append(round(target))\n",
        "# print(y_predlinear_new)\n",
        "# y_predlinear = round(y_predlinear)\n",
        "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_predlinear_new))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aA0oFh-ad2bm",
        "outputId": "eef80693-64a0-4d4f-a789-b8bc63f7638a"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7628571428571429\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training using Gradient Boosting"
      ],
      "metadata": {
        "id": "XJRD3ludzBFc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "clf = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1,\n",
        "    max_depth=3, random_state=20)\n",
        "clf.fit(X_train, y_train)\n",
        "y_predgboost = clf.predict(X_test)\n",
        "y_predgboost_new = []\n",
        "for target in y_predgboost:\n",
        "  y_predgboost_new.append(round(target))\n",
        "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_predgboost_new))\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-AOfdy6ylAv",
        "outputId": "15ab9095-ae0b-4e4e-f35e-01fdb9897163"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8542857142857143\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training using Deep Neural Network"
      ],
      "metadata": {
        "id": "L5hO7kGNz4sD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.iloc[:, 1:].values\n",
        "y = df.iloc[:, 0].values\n",
        "\n",
        "# Reshape the features to image-like format (assuming each neural layer is an image)\n",
        "X = X.reshape(X.shape[0], 20, 20, 3)\n",
        "y = to_categorical(y)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syXbR2nO0DPC",
        "outputId": "6126d348-e28e-4452-f49b-0b334740d7fa"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4200, 20, 20, 3)\n",
            "(4200, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Activation, Dropout\n",
        "from keras.utils import to_categorical, np_utils\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import load_model\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'valid',\n",
        "                 activation ='relu', input_shape = (20,20,3)))\n",
        "print(\"Input: \", model.input_shape)\n",
        "print(\"Output: \", model.output_shape)\n",
        "\n",
        "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'valid',\n",
        "                 activation ='relu'))\n",
        "print(\"Input: \", model.input_shape)\n",
        "print(\"Output: \", model.output_shape)\n",
        "\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Dropout(0.25))\n",
        "print(\"Input: \", model.input_shape)\n",
        "print(\"Output: \", model.output_shape)\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation = \"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(2, activation = \"softmax\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxhP5bDkuP2k",
        "outputId": "4f6ac90d-b8b5-47e3-abd2-581b46ce4136"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:  (None, 20, 20, 3)\n",
            "Output:  (None, 16, 16, 32)\n",
            "Input:  (None, 20, 20, 3)\n",
            "Output:  (None, 12, 12, 32)\n",
            "Input:  (None, 20, 20, 3)\n",
            "Output:  (None, 6, 6, 32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = RMSprop(lr=0.0005, rho=0.9, epsilon=1e-08, decay=0.0)\n",
        "model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "sTHCR23Nu0Ri"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = EarlyStopping(monitor='val_acc',\n",
        "                              min_delta=0,\n",
        "                              patience=2,\n",
        "                              verbose=0, mode='auto')"
      ],
      "metadata": {
        "id": "cF6TAZ0xu3bp"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, batch_size = 100, epochs = 30,\n",
        "          validation_data = (X_test, y_test), verbose = 2, callbacks=[early_stopping])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9JMW5EXu7xa",
        "outputId": "04b4154f-3a0d-4f09-d6ca-a1574a4bb055"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42/42 - 1s - loss: 0.4910 - accuracy: 0.7633 - val_loss: 0.3698 - val_accuracy: 0.8486 - 1s/epoch - 27ms/step\n",
            "Epoch 2/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42/42 - 0s - loss: 0.3744 - accuracy: 0.8188 - val_loss: 0.3429 - val_accuracy: 0.8619 - 218ms/epoch - 5ms/step\n",
            "Epoch 3/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42/42 - 0s - loss: 0.3287 - accuracy: 0.8474 - val_loss: 0.3328 - val_accuracy: 0.8552 - 210ms/epoch - 5ms/step\n",
            "Epoch 4/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42/42 - 0s - loss: 0.2888 - accuracy: 0.8710 - val_loss: 0.3238 - val_accuracy: 0.8629 - 205ms/epoch - 5ms/step\n",
            "Epoch 5/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42/42 - 0s - loss: 0.2390 - accuracy: 0.8948 - val_loss: 0.3317 - val_accuracy: 0.8619 - 192ms/epoch - 5ms/step\n",
            "Epoch 6/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42/42 - 0s - loss: 0.2027 - accuracy: 0.9126 - val_loss: 0.3430 - val_accuracy: 0.8619 - 219ms/epoch - 5ms/step\n",
            "Epoch 7/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42/42 - 0s - loss: 0.1685 - accuracy: 0.9360 - val_loss: 0.3836 - val_accuracy: 0.8600 - 180ms/epoch - 4ms/step\n",
            "Epoch 8/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42/42 - 0s - loss: 0.1391 - accuracy: 0.9510 - val_loss: 0.3494 - val_accuracy: 0.8505 - 196ms/epoch - 5ms/step\n",
            "Epoch 9/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42/42 - 0s - loss: 0.1062 - accuracy: 0.9652 - val_loss: 0.3912 - val_accuracy: 0.8533 - 211ms/epoch - 5ms/step\n",
            "Epoch 10/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42/42 - 0s - loss: 0.0755 - accuracy: 0.9764 - val_loss: 0.4346 - val_accuracy: 0.8505 - 183ms/epoch - 4ms/step\n",
            "Epoch 11/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42/42 - 0s - loss: 0.0735 - accuracy: 0.9767 - val_loss: 0.4310 - val_accuracy: 0.8419 - 218ms/epoch - 5ms/step\n",
            "Epoch 12/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42/42 - 0s - loss: 0.0598 - accuracy: 0.9798 - val_loss: 0.4601 - val_accuracy: 0.8448 - 178ms/epoch - 4ms/step\n",
            "Epoch 13/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42/42 - 0s - loss: 0.0429 - accuracy: 0.9871 - val_loss: 0.4705 - val_accuracy: 0.8238 - 212ms/epoch - 5ms/step\n",
            "Epoch 14/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42/42 - 0s - loss: 0.0437 - accuracy: 0.9852 - val_loss: 0.5102 - val_accuracy: 0.8486 - 186ms/epoch - 4ms/step\n",
            "Epoch 15/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42/42 - 0s - loss: 0.0354 - accuracy: 0.9886 - val_loss: 0.5141 - val_accuracy: 0.8505 - 211ms/epoch - 5ms/step\n",
            "Epoch 16/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42/42 - 0s - loss: 0.0390 - accuracy: 0.9848 - val_loss: 0.5248 - val_accuracy: 0.8457 - 190ms/epoch - 5ms/step\n",
            "Epoch 17/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42/42 - 0s - loss: 0.0321 - accuracy: 0.9900 - val_loss: 0.5889 - val_accuracy: 0.8495 - 217ms/epoch - 5ms/step\n",
            "Epoch 18/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42/42 - 0s - loss: 0.0268 - accuracy: 0.9905 - val_loss: 0.6303 - val_accuracy: 0.8505 - 182ms/epoch - 4ms/step\n",
            "Epoch 19/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42/42 - 0s - loss: 0.0279 - accuracy: 0.9893 - val_loss: 0.5853 - val_accuracy: 0.8486 - 192ms/epoch - 5ms/step\n",
            "Epoch 20/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42/42 - 0s - loss: 0.0208 - accuracy: 0.9929 - val_loss: 0.6524 - val_accuracy: 0.8438 - 191ms/epoch - 5ms/step\n",
            "Epoch 21/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42/42 - 0s - loss: 0.0214 - accuracy: 0.9926 - val_loss: 0.6548 - val_accuracy: 0.8495 - 188ms/epoch - 4ms/step\n",
            "Epoch 22/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42/42 - 0s - loss: 0.0187 - accuracy: 0.9921 - val_loss: 0.7131 - val_accuracy: 0.8371 - 192ms/epoch - 5ms/step\n",
            "Epoch 23/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42/42 - 0s - loss: 0.0211 - accuracy: 0.9929 - val_loss: 0.6716 - val_accuracy: 0.8457 - 197ms/epoch - 5ms/step\n",
            "Epoch 24/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42/42 - 0s - loss: 0.0203 - accuracy: 0.9924 - val_loss: 0.7667 - val_accuracy: 0.8419 - 201ms/epoch - 5ms/step\n",
            "Epoch 25/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42/42 - 0s - loss: 0.0157 - accuracy: 0.9943 - val_loss: 0.7648 - val_accuracy: 0.8476 - 192ms/epoch - 5ms/step\n",
            "Epoch 26/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42/42 - 0s - loss: 0.0194 - accuracy: 0.9929 - val_loss: 0.8123 - val_accuracy: 0.8486 - 218ms/epoch - 5ms/step\n",
            "Epoch 27/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42/42 - 0s - loss: 0.0121 - accuracy: 0.9964 - val_loss: 0.7861 - val_accuracy: 0.8410 - 185ms/epoch - 4ms/step\n",
            "Epoch 28/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42/42 - 0s - loss: 0.0173 - accuracy: 0.9938 - val_loss: 0.9313 - val_accuracy: 0.8514 - 191ms/epoch - 5ms/step\n",
            "Epoch 29/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42/42 - 0s - loss: 0.0135 - accuracy: 0.9945 - val_loss: 0.8141 - val_accuracy: 0.8381 - 223ms/epoch - 5ms/step\n",
            "Epoch 30/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42/42 - 0s - loss: 0.0166 - accuracy: 0.9938 - val_loss: 0.7633 - val_accuracy: 0.8429 - 192ms/epoch - 5ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "y_test = np.argmax(y_test, axis=1)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "print(\"F1 Score:\", f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvHNFW4nw9_i",
        "outputId": "c4450757-53c3-4ac8-945d-12e87f43de84"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7633 - accuracy: 0.8429\n",
            "Test Loss: 0.763306736946106\n",
            "Test Accuracy: 0.8428571224212646\n",
            "33/33 [==============================] - 0s 2ms/step\n",
            "F1 Score: 0.6680080482897384\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing with test data"
      ],
      "metadata": {
        "id": "CdIiHqXP4S94"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data=pd.read_csv('/content/drive/MyDrive/train.csv')\n",
        "X = train_data.iloc[:, 1:].values\n",
        "y = train_data.iloc[:, 0].values\n",
        "X = X.reshape(X.shape[0], 20, 20, 3)\n",
        "\n",
        "\n",
        "# Convert the target variable to categorical format\n",
        "y = to_categorical(y)\n",
        "# print(X_train.shape)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "snbnf2vC1w6K"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'valid',\n",
        "                 activation ='relu', input_shape = (20,20,3)))\n",
        "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'valid',\n",
        "                 activation ='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation = \"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(2, activation = \"softmax\"))\n",
        "optimizer = RMSprop(lr=0.0005, rho=0.9, epsilon=1e-08, decay=0.0)\n",
        "model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "early_stopping = EarlyStopping(monitor='val_acc', min_delta=0, patience=2, verbose=0, mode='auto')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0L_UuPej118O",
        "outputId": "70866f94-2595-40e4-b137-996f9410f558"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/optimizers/legacy/rmsprop.py:143: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X, y, batch_size = 100, epochs = 30,\n",
        "          validation_data = (X_test, y_test), verbose = 2, callbacks=[early_stopping])\n",
        "\n",
        "#Load test data\n",
        "test_data = pd.read_csv('/content/drive/MyDrive/test.csv')\n",
        "\n",
        "# Seperating useful features and excluding heading of the test data\n",
        "X_test = test_data.iloc[:, 1:].values\n",
        "X_test = X_test.reshape(X_test.shape[0], 20, 20, 3)\n",
        "\n",
        "\n",
        "predictions = model.predict(X_test)\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "#Creating a solution file which predicts from the test file\n",
        "result_df = pd.DataFrame({'id': test_data['id'], 'Prediction': predicted_labels})\n",
        "\n",
        "# Save results into a file in drive\n",
        "result_df.to_csv('/content/drive/MyDrive/predictions.csv', index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cf2ra-H_16Uv",
        "outputId": "3e4b2554-79a2-48ce-f3ea-0538aad0e9e8"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53/53 - 1s - loss: 0.5074 - accuracy: 0.7590 - val_loss: 0.3666 - val_accuracy: 0.8276 - 1s/epoch - 20ms/step\n",
            "Epoch 2/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53/53 - 0s - loss: 0.3726 - accuracy: 0.8251 - val_loss: 0.2948 - val_accuracy: 0.8790 - 258ms/epoch - 5ms/step\n",
            "Epoch 3/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53/53 - 0s - loss: 0.3255 - accuracy: 0.8543 - val_loss: 0.2866 - val_accuracy: 0.8571 - 283ms/epoch - 5ms/step\n",
            "Epoch 4/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53/53 - 0s - loss: 0.2880 - accuracy: 0.8672 - val_loss: 0.2146 - val_accuracy: 0.9390 - 297ms/epoch - 6ms/step\n",
            "Epoch 5/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53/53 - 0s - loss: 0.2399 - accuracy: 0.8924 - val_loss: 0.1651 - val_accuracy: 0.9181 - 350ms/epoch - 7ms/step\n",
            "Epoch 6/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53/53 - 0s - loss: 0.1995 - accuracy: 0.9154 - val_loss: 0.1302 - val_accuracy: 0.9781 - 389ms/epoch - 7ms/step\n",
            "Epoch 7/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53/53 - 0s - loss: 0.1743 - accuracy: 0.9307 - val_loss: 0.0939 - val_accuracy: 0.9829 - 317ms/epoch - 6ms/step\n",
            "Epoch 8/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53/53 - 0s - loss: 0.1439 - accuracy: 0.9415 - val_loss: 0.0617 - val_accuracy: 0.9914 - 343ms/epoch - 6ms/step\n",
            "Epoch 9/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53/53 - 0s - loss: 0.1145 - accuracy: 0.9585 - val_loss: 0.0510 - val_accuracy: 0.9971 - 330ms/epoch - 6ms/step\n",
            "Epoch 10/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53/53 - 0s - loss: 0.0852 - accuracy: 0.9710 - val_loss: 0.0315 - val_accuracy: 0.9990 - 332ms/epoch - 6ms/step\n",
            "Epoch 11/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53/53 - 0s - loss: 0.0819 - accuracy: 0.9697 - val_loss: 0.0291 - val_accuracy: 0.9971 - 340ms/epoch - 6ms/step\n",
            "Epoch 12/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53/53 - 0s - loss: 0.0664 - accuracy: 0.9775 - val_loss: 0.0152 - val_accuracy: 1.0000 - 326ms/epoch - 6ms/step\n",
            "Epoch 13/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53/53 - 0s - loss: 0.0503 - accuracy: 0.9819 - val_loss: 0.0119 - val_accuracy: 1.0000 - 338ms/epoch - 6ms/step\n",
            "Epoch 14/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53/53 - 0s - loss: 0.0449 - accuracy: 0.9855 - val_loss: 0.0107 - val_accuracy: 1.0000 - 362ms/epoch - 7ms/step\n",
            "Epoch 15/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53/53 - 0s - loss: 0.0435 - accuracy: 0.9865 - val_loss: 0.0079 - val_accuracy: 1.0000 - 255ms/epoch - 5ms/step\n",
            "Epoch 16/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53/53 - 0s - loss: 0.0425 - accuracy: 0.9840 - val_loss: 0.0169 - val_accuracy: 0.9990 - 269ms/epoch - 5ms/step\n",
            "Epoch 17/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53/53 - 0s - loss: 0.0346 - accuracy: 0.9870 - val_loss: 0.0049 - val_accuracy: 1.0000 - 269ms/epoch - 5ms/step\n",
            "Epoch 18/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53/53 - 0s - loss: 0.0326 - accuracy: 0.9895 - val_loss: 0.0051 - val_accuracy: 0.9990 - 236ms/epoch - 4ms/step\n",
            "Epoch 19/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53/53 - 0s - loss: 0.0264 - accuracy: 0.9907 - val_loss: 0.0021 - val_accuracy: 1.0000 - 234ms/epoch - 4ms/step\n",
            "Epoch 20/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53/53 - 0s - loss: 0.0277 - accuracy: 0.9905 - val_loss: 0.0027 - val_accuracy: 1.0000 - 292ms/epoch - 6ms/step\n",
            "Epoch 21/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53/53 - 0s - loss: 0.0311 - accuracy: 0.9882 - val_loss: 0.0029 - val_accuracy: 1.0000 - 224ms/epoch - 4ms/step\n",
            "Epoch 22/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53/53 - 0s - loss: 0.0232 - accuracy: 0.9914 - val_loss: 0.0019 - val_accuracy: 1.0000 - 230ms/epoch - 4ms/step\n",
            "Epoch 23/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53/53 - 0s - loss: 0.0262 - accuracy: 0.9905 - val_loss: 0.0021 - val_accuracy: 1.0000 - 235ms/epoch - 4ms/step\n",
            "Epoch 24/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53/53 - 0s - loss: 0.0212 - accuracy: 0.9924 - val_loss: 0.0030 - val_accuracy: 1.0000 - 275ms/epoch - 5ms/step\n",
            "Epoch 25/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53/53 - 0s - loss: 0.0209 - accuracy: 0.9916 - val_loss: 0.0011 - val_accuracy: 1.0000 - 240ms/epoch - 5ms/step\n",
            "Epoch 26/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53/53 - 0s - loss: 0.0197 - accuracy: 0.9926 - val_loss: 8.0794e-04 - val_accuracy: 1.0000 - 227ms/epoch - 4ms/step\n",
            "Epoch 27/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53/53 - 0s - loss: 0.0206 - accuracy: 0.9924 - val_loss: 0.0026 - val_accuracy: 1.0000 - 235ms/epoch - 4ms/step\n",
            "Epoch 28/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53/53 - 0s - loss: 0.0187 - accuracy: 0.9933 - val_loss: 0.0011 - val_accuracy: 1.0000 - 223ms/epoch - 4ms/step\n",
            "Epoch 29/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53/53 - 0s - loss: 0.0233 - accuracy: 0.9922 - val_loss: 9.8690e-04 - val_accuracy: 1.0000 - 231ms/epoch - 4ms/step\n",
            "Epoch 30/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53/53 - 0s - loss: 0.0217 - accuracy: 0.9924 - val_loss: 7.6253e-04 - val_accuracy: 1.0000 - 264ms/epoch - 5ms/step\n",
            "71/71 [==============================] - 0s 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using Vision Transformer"
      ],
      "metadata": {
        "id": "TE2lw1cs47Sk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inp = torch.from_numpy(X.values.reshape(len(X),3,20,20).astype(float))\n",
        "inp = torch.clamp(inp,0,1)\n",
        "inp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKk25tf3GX6W",
        "outputId": "59e182d4-eb17-428b-a8c7-d22df0c849fe"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[0.0000e+00, 9.7845e-01, 0.0000e+00,  ..., 4.5184e-02,\n",
              "           0.0000e+00, 7.0296e-01],\n",
              "          [0.0000e+00, 5.5401e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           1.0000e+00, 0.0000e+00],\n",
              "          [0.0000e+00, 1.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           8.3506e-01, 0.0000e+00],\n",
              "          ...,\n",
              "          [3.5884e-01, 0.0000e+00, 2.1953e-01,  ..., 2.9834e-01,\n",
              "           3.8864e-01, 1.7029e-01],\n",
              "          [8.2437e-01, 0.0000e+00, 5.4134e-01,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 7.8418e-01],\n",
              "          [4.8284e-01, 1.0000e+00, 3.8534e-01,  ..., 5.2226e-01,\n",
              "           0.0000e+00, 3.5099e-02]],\n",
              "\n",
              "         [[0.0000e+00, 1.0000e+00, 0.0000e+00,  ..., 7.4908e-01,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [9.6579e-01, 2.5935e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           1.0000e+00, 0.0000e+00],\n",
              "          [1.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
              "           1.0825e-01, 1.0000e+00],\n",
              "          ...,\n",
              "          [1.3879e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           1.0000e+00, 0.0000e+00],\n",
              "          [3.6090e-01, 9.8250e-01, 0.0000e+00,  ..., 1.0000e+00,\n",
              "           1.0000e+00, 0.0000e+00],\n",
              "          [0.0000e+00, 5.2106e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           1.0000e+00, 0.0000e+00]],\n",
              "\n",
              "         [[6.4230e-01, 0.0000e+00, 0.0000e+00,  ..., 7.2454e-01,\n",
              "           0.0000e+00, 2.6545e-01],\n",
              "          [9.2356e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           1.0000e+00, 0.0000e+00],\n",
              "          [4.5812e-01, 3.0362e-01, 0.0000e+00,  ..., 1.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          ...,\n",
              "          [0.0000e+00, 0.0000e+00, 1.4858e-01,  ..., 3.7191e-01,\n",
              "           0.0000e+00, 1.0000e+00],\n",
              "          [0.0000e+00, 1.0000e+00, 4.9966e-01,  ..., 7.4401e-01,\n",
              "           9.0800e-01, 0.0000e+00],\n",
              "          [0.0000e+00, 5.5010e-01, 4.6254e-01,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 5.5800e-01]]],\n",
              "\n",
              "\n",
              "        [[[0.0000e+00, 2.9481e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           1.8365e-01, 2.1598e-01],\n",
              "          [1.2473e-01, 8.8043e-01, 6.3155e-01,  ..., 1.0000e+00,\n",
              "           9.7884e-01, 3.3160e-01],\n",
              "          [0.0000e+00, 4.4263e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           1.0000e+00, 0.0000e+00],\n",
              "          ...,\n",
              "          [0.0000e+00, 1.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 4.7644e-01],\n",
              "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 4.3395e-01,\n",
              "           7.1138e-03, 1.0000e+00],\n",
              "          [1.5474e-01, 0.0000e+00, 0.0000e+00,  ..., 7.9551e-01,\n",
              "           0.0000e+00, 0.0000e+00]],\n",
              "\n",
              "         [[0.0000e+00, 9.2972e-01, 2.6606e-01,  ..., 5.2380e-01,\n",
              "           0.0000e+00, 2.1264e-01],\n",
              "          [1.0000e+00, 8.9600e-01, 0.0000e+00,  ..., 6.7959e-02,\n",
              "           3.5122e-01, 6.6440e-02],\n",
              "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           4.9262e-02, 1.0000e+00],\n",
              "          ...,\n",
              "          [0.0000e+00, 8.0660e-01, 0.0000e+00,  ..., 1.0000e+00,\n",
              "           4.6245e-02, 7.1387e-01],\n",
              "          [0.0000e+00, 9.4436e-02, 0.0000e+00,  ..., 1.0835e-01,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [2.0439e-01, 0.0000e+00, 6.7677e-01,  ..., 2.0627e-01,\n",
              "           0.0000e+00, 6.9124e-01]],\n",
              "\n",
              "         [[0.0000e+00, 1.0000e+00, 7.9855e-01,  ..., 3.8507e-01,\n",
              "           1.0000e+00, 1.0000e+00],\n",
              "          [0.0000e+00, 0.0000e+00, 6.2148e-01,  ..., 9.1671e-01,\n",
              "           2.8743e-01, 0.0000e+00],\n",
              "          [1.2162e-01, 0.0000e+00, 7.9450e-01,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 1.0000e+00],\n",
              "          ...,\n",
              "          [6.8690e-02, 3.6873e-01, 0.0000e+00,  ..., 4.5124e-01,\n",
              "           0.0000e+00, 4.8044e-01],\n",
              "          [0.0000e+00, 7.3034e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [0.0000e+00, 3.2274e-03, 4.5534e-01,  ..., 5.8296e-01,\n",
              "           2.5267e-01, 1.0000e+00]]],\n",
              "\n",
              "\n",
              "        [[[1.1325e-01, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
              "           3.7042e-01, 0.0000e+00],\n",
              "          [1.1470e-01, 0.0000e+00, 8.1075e-01,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 1.0000e+00],\n",
              "          [0.0000e+00, 0.0000e+00, 3.2358e-01,  ..., 3.1542e-01,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          ...,\n",
              "          [0.0000e+00, 1.2400e-01, 2.3621e-01,  ..., 1.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [1.0000e+00, 0.0000e+00, 1.0000e+00,  ..., 0.0000e+00,\n",
              "           8.1140e-01, 0.0000e+00],\n",
              "          [6.8745e-01, 0.0000e+00, 3.6316e-01,  ..., 1.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00]],\n",
              "\n",
              "         [[3.3343e-01, 1.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
              "           1.0000e+00, 1.5485e-01],\n",
              "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 4.9716e-01,\n",
              "           0.0000e+00, 1.0000e+00],\n",
              "          [0.0000e+00, 5.2011e-01, 1.0000e+00,  ..., 0.0000e+00,\n",
              "           1.0000e+00, 3.9723e-01],\n",
              "          ...,\n",
              "          [7.5814e-01, 1.0000e+00, 9.2188e-01,  ..., 6.5955e-01,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [0.0000e+00, 3.3720e-01, 3.1387e-01,  ..., 7.9011e-01,\n",
              "           9.5849e-01, 3.6410e-01],\n",
              "          [0.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00]],\n",
              "\n",
              "         [[1.0000e+00, 0.0000e+00, 2.3062e-01,  ..., 6.1762e-01,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [1.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [4.2382e-01, 6.9925e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          ...,\n",
              "          [2.3811e-01, 0.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
              "           7.4144e-03, 1.0000e+00],\n",
              "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
              "           4.2771e-01, 0.0000e+00],\n",
              "          [0.0000e+00, 4.6707e-01, 1.0000e+00,  ..., 2.4337e-01,\n",
              "           1.7008e-01, 1.0000e+00]]],\n",
              "\n",
              "\n",
              "        ...,\n",
              "\n",
              "\n",
              "        [[[0.0000e+00, 1.0000e+00, 1.2514e-02,  ..., 1.0000e+00,\n",
              "           5.2331e-01, 1.0000e+00],\n",
              "          [0.0000e+00, 0.0000e+00, 1.9640e-01,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [1.0000e+00, 1.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
              "           1.0000e+00, 0.0000e+00],\n",
              "          ...,\n",
              "          [0.0000e+00, 1.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [0.0000e+00, 1.0000e+00, 3.2946e-02,  ..., 0.0000e+00,\n",
              "           5.3378e-02, 9.3194e-01],\n",
              "          [0.0000e+00, 1.0000e+00, 7.8892e-01,  ..., 0.0000e+00,\n",
              "           2.3726e-01, 0.0000e+00]],\n",
              "\n",
              "         [[0.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 2.3726e-01,\n",
              "           9.5237e-01, 1.0000e+00],\n",
              "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [0.0000e+00, 1.9640e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           1.0000e+00, 1.1467e-01],\n",
              "          ...,\n",
              "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           9.5237e-01, 0.0000e+00],\n",
              "          [1.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           1.3510e-01, 0.0000e+00],\n",
              "          [5.3378e-02, 1.1467e-01, 0.0000e+00,  ..., 7.2762e-01,\n",
              "           0.0000e+00, 5.3378e-02]],\n",
              "\n",
              "         [[0.0000e+00, 6.8676e-01, 1.7597e-01,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 1.0000e+00],\n",
              "          [0.0000e+00, 3.8028e-01, 0.0000e+00,  ..., 6.8676e-01,\n",
              "           0.0000e+00, 1.0000e+00],\n",
              "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           9.4241e-02, 0.0000e+00],\n",
              "          ...,\n",
              "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 6.6633e-01,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
              "           1.0000e+00, 0.0000e+00],\n",
              "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           1.3510e-01, 1.0000e+00]]],\n",
              "\n",
              "\n",
              "        [[[0.0000e+00, 1.0000e+00, 4.9609e-02,  ..., 1.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [0.0000e+00, 1.6619e-02, 0.0000e+00,  ..., 1.4858e-01,\n",
              "           4.9609e-02, 0.0000e+00],\n",
              "          [0.0000e+00, 1.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
              "           1.0000e+00, 1.1559e-01],\n",
              "          ...,\n",
              "          [0.0000e+00, 9.9095e-02, 0.0000e+00,  ..., 1.6619e-02,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [1.9807e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           8.9087e-01, 1.0000e+00],\n",
              "          [0.0000e+00, 0.0000e+00, 1.0000e+00,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00]],\n",
              "\n",
              "         [[0.0000e+00, 8.7437e-01, 1.0000e+00,  ..., 0.0000e+00,\n",
              "           1.0000e+00, 1.0000e+00],\n",
              "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 8.2600e-02,\n",
              "           1.0000e+00, 9.9095e-02],\n",
              "          [1.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
              "           4.2900e-01, 0.0000e+00],\n",
              "          ...,\n",
              "          [0.0000e+00, 1.2371e-04, 0.0000e+00,  ..., 1.0000e+00,\n",
              "           1.0000e+00, 0.0000e+00],\n",
              "          [5.2797e-01, 0.0000e+00, 1.1559e-01,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00]],\n",
              "\n",
              "         [[0.0000e+00, 6.9292e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [1.0000e+00, 1.0000e+00, 5.4447e-01,  ..., 6.9292e-01,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 3.3114e-02,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          ...,\n",
              "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 7.9189e-01,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [0.0000e+00, 0.0000e+00, 1.9807e-01,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 3.3114e-02]]],\n",
              "\n",
              "\n",
              "        [[[0.0000e+00, 2.6701e-01, 0.0000e+00,  ..., 1.0000e+00,\n",
              "           9.8697e-01, 2.4218e-01],\n",
              "          [0.0000e+00, 0.0000e+00, 2.6701e-01,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [9.1249e-01, 1.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
              "           0.0000e+00, 9.3223e-02],\n",
              "          ...,\n",
              "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [6.8397e-02, 9.1249e-01, 4.1597e-01,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 1.0000e+00],\n",
              "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
              "           1.0000e+00, 0.0000e+00]],\n",
              "\n",
              "         [[0.0000e+00, 6.1458e-01, 1.0000e+00,  ..., 1.6770e-01,\n",
              "           0.0000e+00, 1.0000e+00],\n",
              "          [7.1388e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [0.0000e+00, 6.6423e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          ...,\n",
              "          [1.1805e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [1.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
              "           4.9045e-01, 8.6284e-01],\n",
              "          [1.6770e-01, 1.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
              "           0.0000e+00, 1.6770e-01]],\n",
              "\n",
              "         [[0.0000e+00, 1.0000e+00, 0.0000e+00,  ..., 1.9253e-01,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [0.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 5.1527e-01],\n",
              "          ...,\n",
              "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 7.8836e-01],\n",
              "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 9.3732e-01,\n",
              "           1.0000e+00, 0.0000e+00],\n",
              "          [1.0000e+00, 0.0000e+00, 6.8397e-02,  ..., 0.0000e+00,\n",
              "           6.6423e-01, 1.0000e+00]]]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from torch import nn\n",
        "from torch.nn import Module\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import TensorDataset ,DataLoader\n",
        "from tqdm import tqdm\n",
        "class VisionTransformer(nn.Module):\n",
        "    def __init__(self, classes, img_size, patch_size, dim):\n",
        "        super(VisionTransformer, self).__init__()\n",
        "        self.patch_size = patch_size\n",
        "        patches = (img_size / patch_size) ** 2\n",
        "        patch_dim = 3 * (patch_size ** 2)\n",
        "        self.patch_embedding = nn.Conv2d(3, dim, kernel_size=patch_size, stride=patch_size)\n",
        "        self.pos_encoding = nn.Parameter(torch.zeros(1, int(patches), dim))\n",
        "        self.transformer = nn.TransformerEncoder(nn.TransformerEncoderLayer(d_model=dim, nhead=8), num_layers=6)\n",
        "        self.fc = nn.Linear(dim, classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, channels, height, width = x.shape\n",
        "        x = self.patch_embedding(x)\n",
        "        x = x.flatten(2).permute(0, 2, 1)\n",
        "        seq_len = x.shape[1]\n",
        "        pos_encoding = self.pos_encoding.expand(batch_size, -1, -1)\n",
        "        x = torch.cat([pos_encoding, x], dim=1)\n",
        "        x = self.transformer(x)\n",
        "        x = x.mean(dim=1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "classes = 2\n",
        "img_size = 20\n",
        "patch_size = 5\n",
        "dim = 128\n",
        "batch_size = 64\n",
        "num_epochs=2\n",
        "\n",
        "train_dataset = TensorDataset(inp, torch.from_numpy(np.array(y)))\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "vit = VisionTransformer(classes, img_size, patch_size, dim)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(vit.parameters(), lr=0.0001 )\n",
        "\n",
        "loss_df = []\n",
        "def train(model, train_loader, criterion, optimizer, num_epochs):\n",
        "    model.train()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        epoch_loss = 0.0\n",
        "        progress_bar = tqdm(train_loader, desc=f'epoch {epoch + 1}', unit='batch', ncols=80)\n",
        "\n",
        "        for images, labels in progress_bar:\n",
        "            outputs = model(images.float())\n",
        "            loss = criterion(outputs, labels)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            progress_bar.set_postfix({'Loss': loss.item()})\n",
        "\n",
        "        epoch_loss /= len(train_loader)\n",
        "        loss_df.append(epoch_loss)\n",
        "        print(f'average_loss: {epoch_loss}')\n",
        "\n",
        "    print('Training finished.')\n",
        "\n",
        "\n",
        "train(vit, train_loader, criterion, optimizer,num_epochs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbGCjapBEAdO",
        "outputId": "c5b2bdd2-8bb5-4200-e953-5c0673ca62ef"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 1: 100%|███████████████████| 83/83 [01:40<00:00,  1.21s/batch, Loss=0.768]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average_loss: 0.5408171253750124\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 2: 100%|███████████████████| 83/83 [01:36<00:00,  1.16s/batch, Loss=0.722]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average_loss: 0.4069327686924532\n",
            "Training finished.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot( np.arange(len(loss_df)),np.array(loss_df))"
      ],
      "metadata": {
        "id": "22MbhzzJSXE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mp3y7uNWJ7sq",
        "outputId": "3cad9fef-999c-44f3-c437-d5bfdc80a892"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VisionTransformer(\n",
              "  (patch_embedding): Conv2d(3, 128, kernel_size=(5, 5), stride=(5, 5))\n",
              "  (transformer): TransformerEncoder(\n",
              "    (layers): ModuleList(\n",
              "      (0-5): 6 x TransformerEncoderLayer(\n",
              "        (self_attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
              "        )\n",
              "        (linear1): Linear(in_features=128, out_features=2048, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (linear2): Linear(in_features=2048, out_features=128, bias=True)\n",
              "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout1): Dropout(p=0.1, inplace=False)\n",
              "        (dropout2): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (fc): Linear(in_features=128, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_inp = torch.from_numpy(X_test.values.reshape(len(X_test),3,20,20).astype(float))\n",
        "test_inp = torch.clamp(inp,0,1)\n",
        "test_inp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YU9b4e--J_WS",
        "outputId": "4a77b717-93d0-454c-ff55-df41a8338e33"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[0.0000e+00, 9.7845e-01, 0.0000e+00,  ..., 4.5184e-02,\n",
              "           0.0000e+00, 7.0296e-01],\n",
              "          [0.0000e+00, 5.5401e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           1.0000e+00, 0.0000e+00],\n",
              "          [0.0000e+00, 1.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           8.3506e-01, 0.0000e+00],\n",
              "          ...,\n",
              "          [3.5884e-01, 0.0000e+00, 2.1953e-01,  ..., 2.9834e-01,\n",
              "           3.8864e-01, 1.7029e-01],\n",
              "          [8.2437e-01, 0.0000e+00, 5.4134e-01,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 7.8418e-01],\n",
              "          [4.8284e-01, 1.0000e+00, 3.8534e-01,  ..., 5.2226e-01,\n",
              "           0.0000e+00, 3.5099e-02]],\n",
              "\n",
              "         [[0.0000e+00, 1.0000e+00, 0.0000e+00,  ..., 7.4908e-01,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [9.6579e-01, 2.5935e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           1.0000e+00, 0.0000e+00],\n",
              "          [1.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
              "           1.0825e-01, 1.0000e+00],\n",
              "          ...,\n",
              "          [1.3879e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           1.0000e+00, 0.0000e+00],\n",
              "          [3.6090e-01, 9.8250e-01, 0.0000e+00,  ..., 1.0000e+00,\n",
              "           1.0000e+00, 0.0000e+00],\n",
              "          [0.0000e+00, 5.2106e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           1.0000e+00, 0.0000e+00]],\n",
              "\n",
              "         [[6.4230e-01, 0.0000e+00, 0.0000e+00,  ..., 7.2454e-01,\n",
              "           0.0000e+00, 2.6545e-01],\n",
              "          [9.2356e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           1.0000e+00, 0.0000e+00],\n",
              "          [4.5812e-01, 3.0362e-01, 0.0000e+00,  ..., 1.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          ...,\n",
              "          [0.0000e+00, 0.0000e+00, 1.4858e-01,  ..., 3.7191e-01,\n",
              "           0.0000e+00, 1.0000e+00],\n",
              "          [0.0000e+00, 1.0000e+00, 4.9966e-01,  ..., 7.4401e-01,\n",
              "           9.0800e-01, 0.0000e+00],\n",
              "          [0.0000e+00, 5.5010e-01, 4.6254e-01,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 5.5800e-01]]],\n",
              "\n",
              "\n",
              "        [[[0.0000e+00, 2.9481e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           1.8365e-01, 2.1598e-01],\n",
              "          [1.2473e-01, 8.8043e-01, 6.3155e-01,  ..., 1.0000e+00,\n",
              "           9.7884e-01, 3.3160e-01],\n",
              "          [0.0000e+00, 4.4263e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           1.0000e+00, 0.0000e+00],\n",
              "          ...,\n",
              "          [0.0000e+00, 1.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 4.7644e-01],\n",
              "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 4.3395e-01,\n",
              "           7.1138e-03, 1.0000e+00],\n",
              "          [1.5474e-01, 0.0000e+00, 0.0000e+00,  ..., 7.9551e-01,\n",
              "           0.0000e+00, 0.0000e+00]],\n",
              "\n",
              "         [[0.0000e+00, 9.2972e-01, 2.6606e-01,  ..., 5.2380e-01,\n",
              "           0.0000e+00, 2.1264e-01],\n",
              "          [1.0000e+00, 8.9600e-01, 0.0000e+00,  ..., 6.7959e-02,\n",
              "           3.5122e-01, 6.6440e-02],\n",
              "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           4.9262e-02, 1.0000e+00],\n",
              "          ...,\n",
              "          [0.0000e+00, 8.0660e-01, 0.0000e+00,  ..., 1.0000e+00,\n",
              "           4.6245e-02, 7.1387e-01],\n",
              "          [0.0000e+00, 9.4436e-02, 0.0000e+00,  ..., 1.0835e-01,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [2.0439e-01, 0.0000e+00, 6.7677e-01,  ..., 2.0627e-01,\n",
              "           0.0000e+00, 6.9124e-01]],\n",
              "\n",
              "         [[0.0000e+00, 1.0000e+00, 7.9855e-01,  ..., 3.8507e-01,\n",
              "           1.0000e+00, 1.0000e+00],\n",
              "          [0.0000e+00, 0.0000e+00, 6.2148e-01,  ..., 9.1671e-01,\n",
              "           2.8743e-01, 0.0000e+00],\n",
              "          [1.2162e-01, 0.0000e+00, 7.9450e-01,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 1.0000e+00],\n",
              "          ...,\n",
              "          [6.8690e-02, 3.6873e-01, 0.0000e+00,  ..., 4.5124e-01,\n",
              "           0.0000e+00, 4.8044e-01],\n",
              "          [0.0000e+00, 7.3034e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [0.0000e+00, 3.2274e-03, 4.5534e-01,  ..., 5.8296e-01,\n",
              "           2.5267e-01, 1.0000e+00]]],\n",
              "\n",
              "\n",
              "        [[[1.1325e-01, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
              "           3.7042e-01, 0.0000e+00],\n",
              "          [1.1470e-01, 0.0000e+00, 8.1075e-01,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 1.0000e+00],\n",
              "          [0.0000e+00, 0.0000e+00, 3.2358e-01,  ..., 3.1542e-01,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          ...,\n",
              "          [0.0000e+00, 1.2400e-01, 2.3621e-01,  ..., 1.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [1.0000e+00, 0.0000e+00, 1.0000e+00,  ..., 0.0000e+00,\n",
              "           8.1140e-01, 0.0000e+00],\n",
              "          [6.8745e-01, 0.0000e+00, 3.6316e-01,  ..., 1.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00]],\n",
              "\n",
              "         [[3.3343e-01, 1.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
              "           1.0000e+00, 1.5485e-01],\n",
              "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 4.9716e-01,\n",
              "           0.0000e+00, 1.0000e+00],\n",
              "          [0.0000e+00, 5.2011e-01, 1.0000e+00,  ..., 0.0000e+00,\n",
              "           1.0000e+00, 3.9723e-01],\n",
              "          ...,\n",
              "          [7.5814e-01, 1.0000e+00, 9.2188e-01,  ..., 6.5955e-01,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [0.0000e+00, 3.3720e-01, 3.1387e-01,  ..., 7.9011e-01,\n",
              "           9.5849e-01, 3.6410e-01],\n",
              "          [0.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00]],\n",
              "\n",
              "         [[1.0000e+00, 0.0000e+00, 2.3062e-01,  ..., 6.1762e-01,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [1.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [4.2382e-01, 6.9925e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          ...,\n",
              "          [2.3811e-01, 0.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
              "           7.4144e-03, 1.0000e+00],\n",
              "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
              "           4.2771e-01, 0.0000e+00],\n",
              "          [0.0000e+00, 4.6707e-01, 1.0000e+00,  ..., 2.4337e-01,\n",
              "           1.7008e-01, 1.0000e+00]]],\n",
              "\n",
              "\n",
              "        ...,\n",
              "\n",
              "\n",
              "        [[[0.0000e+00, 1.0000e+00, 1.2514e-02,  ..., 1.0000e+00,\n",
              "           5.2331e-01, 1.0000e+00],\n",
              "          [0.0000e+00, 0.0000e+00, 1.9640e-01,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [1.0000e+00, 1.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
              "           1.0000e+00, 0.0000e+00],\n",
              "          ...,\n",
              "          [0.0000e+00, 1.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [0.0000e+00, 1.0000e+00, 3.2946e-02,  ..., 0.0000e+00,\n",
              "           5.3378e-02, 9.3194e-01],\n",
              "          [0.0000e+00, 1.0000e+00, 7.8892e-01,  ..., 0.0000e+00,\n",
              "           2.3726e-01, 0.0000e+00]],\n",
              "\n",
              "         [[0.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 2.3726e-01,\n",
              "           9.5237e-01, 1.0000e+00],\n",
              "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [0.0000e+00, 1.9640e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           1.0000e+00, 1.1467e-01],\n",
              "          ...,\n",
              "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           9.5237e-01, 0.0000e+00],\n",
              "          [1.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           1.3510e-01, 0.0000e+00],\n",
              "          [5.3378e-02, 1.1467e-01, 0.0000e+00,  ..., 7.2762e-01,\n",
              "           0.0000e+00, 5.3378e-02]],\n",
              "\n",
              "         [[0.0000e+00, 6.8676e-01, 1.7597e-01,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 1.0000e+00],\n",
              "          [0.0000e+00, 3.8028e-01, 0.0000e+00,  ..., 6.8676e-01,\n",
              "           0.0000e+00, 1.0000e+00],\n",
              "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           9.4241e-02, 0.0000e+00],\n",
              "          ...,\n",
              "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 6.6633e-01,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
              "           1.0000e+00, 0.0000e+00],\n",
              "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           1.3510e-01, 1.0000e+00]]],\n",
              "\n",
              "\n",
              "        [[[0.0000e+00, 1.0000e+00, 4.9609e-02,  ..., 1.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [0.0000e+00, 1.6619e-02, 0.0000e+00,  ..., 1.4858e-01,\n",
              "           4.9609e-02, 0.0000e+00],\n",
              "          [0.0000e+00, 1.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
              "           1.0000e+00, 1.1559e-01],\n",
              "          ...,\n",
              "          [0.0000e+00, 9.9095e-02, 0.0000e+00,  ..., 1.6619e-02,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [1.9807e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           8.9087e-01, 1.0000e+00],\n",
              "          [0.0000e+00, 0.0000e+00, 1.0000e+00,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00]],\n",
              "\n",
              "         [[0.0000e+00, 8.7437e-01, 1.0000e+00,  ..., 0.0000e+00,\n",
              "           1.0000e+00, 1.0000e+00],\n",
              "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 8.2600e-02,\n",
              "           1.0000e+00, 9.9095e-02],\n",
              "          [1.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
              "           4.2900e-01, 0.0000e+00],\n",
              "          ...,\n",
              "          [0.0000e+00, 1.2371e-04, 0.0000e+00,  ..., 1.0000e+00,\n",
              "           1.0000e+00, 0.0000e+00],\n",
              "          [5.2797e-01, 0.0000e+00, 1.1559e-01,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00]],\n",
              "\n",
              "         [[0.0000e+00, 6.9292e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [1.0000e+00, 1.0000e+00, 5.4447e-01,  ..., 6.9292e-01,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 3.3114e-02,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          ...,\n",
              "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 7.9189e-01,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [0.0000e+00, 0.0000e+00, 1.9807e-01,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 3.3114e-02]]],\n",
              "\n",
              "\n",
              "        [[[0.0000e+00, 2.6701e-01, 0.0000e+00,  ..., 1.0000e+00,\n",
              "           9.8697e-01, 2.4218e-01],\n",
              "          [0.0000e+00, 0.0000e+00, 2.6701e-01,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [9.1249e-01, 1.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
              "           0.0000e+00, 9.3223e-02],\n",
              "          ...,\n",
              "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [6.8397e-02, 9.1249e-01, 4.1597e-01,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 1.0000e+00],\n",
              "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
              "           1.0000e+00, 0.0000e+00]],\n",
              "\n",
              "         [[0.0000e+00, 6.1458e-01, 1.0000e+00,  ..., 1.6770e-01,\n",
              "           0.0000e+00, 1.0000e+00],\n",
              "          [7.1388e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [0.0000e+00, 6.6423e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          ...,\n",
              "          [1.1805e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [1.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
              "           4.9045e-01, 8.6284e-01],\n",
              "          [1.6770e-01, 1.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
              "           0.0000e+00, 1.6770e-01]],\n",
              "\n",
              "         [[0.0000e+00, 1.0000e+00, 0.0000e+00,  ..., 1.9253e-01,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [0.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 5.1527e-01],\n",
              "          ...,\n",
              "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 7.8836e-01],\n",
              "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 9.3732e-01,\n",
              "           1.0000e+00, 0.0000e+00],\n",
              "          [1.0000e+00, 0.0000e+00, 6.8397e-02,  ..., 0.0000e+00,\n",
              "           6.6423e-01, 1.0000e+00]]]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = torch.argmax(vit(torch.from_numpy(X_test.values.reshape(len(X_test),3,20,20)).float()),axis=1)"
      ],
      "metadata": {
        "id": "bpjg9hWMKKsu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('accuracy score : ' , accuracy_score(y_pred,y_test))\n",
        "print('f1 score : ', f1_score(y_pred,y_test))"
      ],
      "metadata": {
        "id": "6gLLf5m3KP-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I kind of stuck here. Not able to calculate the accuracy for the transformer model"
      ],
      "metadata": {
        "id": "ffMpwF6e5J7q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import tensorflow as tf\n",
        "# from tensorflow import keras\n",
        "# from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "O6vtpsKXpG0r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Assuming x_train, y_train, x_test, y_test are already preprocessed and tokenized\n",
        "# # Create tf.data.Dataset objects for training and testing data\n",
        "# train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
        "# test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
        "# batch_size = 32\n",
        "# # Shuffle and batch the training data\n",
        "# train_dataset = train_dataset.shuffle(len(X_train)).batch(batch_size)\n",
        "\n",
        "# # Batch the testing data\n",
        "# test_dataset = test_dataset.batch(batch_size)"
      ],
      "metadata": {
        "id": "Gb0cePPBqEUO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Calculate max sequence length for input data\n",
        "# max_sequence_length_input = max(len(sequence) for sequence in X_train)\n",
        "\n",
        "# # Determine the overall max sequence length\n",
        "# max_sequence_length = max_sequence_length_input\n",
        "\n",
        "# # Calculate input vocabulary size\n",
        "# input_vocab = set(token for sequence in X_train for token in sequence)\n",
        "# input_vocab_size = len(input_vocab)\n",
        "\n",
        "# # Calculate target vocabulary size\n",
        "# target_vocab = set(token for sequence in X_train for token in sequence)\n",
        "# target_vocab_size = len(target_vocab)\n",
        "\n",
        "# def transformer_model():\n",
        "#     # Input layers\n",
        "#     inputs = layers.Input(shape=(max_sequence_length,))\n",
        "#     targets = layers.Input(shape=(max_sequence_length,))\n",
        "\n",
        "#     # Embedding layers\n",
        "#     input_embedding = layers.Embedding(input_vocab_size, d_model)(inputs)\n",
        "#     target_embedding = layers.Embedding(target_vocab_size, d_model)(targets)\n",
        "\n",
        "#     # Transformer layers\n",
        "#     encoder_output = encoder_layer(input_embedding)\n",
        "#     decoder_output = decoder_layer(target_embedding, encoder_output)\n",
        "\n",
        "#     # Output layer\n",
        "#     outputs = layers.Dense(target_vocab_size, activation='softmax')(decoder_output)\n",
        "\n",
        "#     # Build the model\n",
        "#     model = keras.Model(inputs=[inputs, targets], outputs=outputs)\n",
        "#     return model"
      ],
      "metadata": {
        "id": "HQAunI8QeLKJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Define hyperparameters\n",
        "# d_model = 128  # Dimensionality of the model\n",
        "# num_heads = 4  # Number of attention heads\n",
        "# ff_dim = 256  # Dimension\n",
        "# def encoder_layer(embedding):\n",
        "#     # Multi-head attention\n",
        "#     attention = layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model)(embedding, embedding)\n",
        "#     attention = layers.Dropout(0.1)(attention)\n",
        "#     attention = layers.LayerNormalization(epsilon=1e-6)(embedding + attention)\n",
        "\n",
        "#     # Feed-forward network\n",
        "#     outputs = layers.Dense(units=ff_dim, activation='relu')(attention)\n",
        "#     outputs = layers.Dense(units=d_model)(outputs)\n",
        "#     outputs = layers.Dropout(0.1)(outputs)\n",
        "#     outputs = layers.LayerNormalization(epsilon=1e-6)(attention + outputs)\n",
        "\n",
        "#     return outputs\n",
        "\n",
        "# def decoder_layer(embedding, encoder_output):\n",
        "#     # Masked multi-head attention (self-attention)\n",
        "#     attention = layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model)(embedding, embedding)\n",
        "#     attention = layers.Dropout(0.1)(attention)\n",
        "#     attention = layers.LayerNormalization(epsilon=1e-6)(embedding + attention)\n",
        "\n",
        "#     # Multi-head attention (encoder-decoder attention)\n",
        "#     attention = layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model)(attention, encoder_output)\n",
        "#     attention = layers.Dropout(0.1)(attention)\n",
        "#     attention = layers.LayerNormalization(epsilon=1e-6)(attention + embedding)\n",
        "\n",
        "#     # Feed-forward network\n",
        "#     outputs = layers.Dense(units=ff_dim, activation='relu')(attention)\n",
        "#     outputs = layers.Dense(units=d_model)(outputs)\n",
        "#     outputs = layers.Dropout(0.1)(outputs)\n",
        "#     outputs = layers.LayerNormalization(epsilon=1e-6)(attention + outputs)\n",
        "\n",
        "#     return outputs"
      ],
      "metadata": {
        "id": "cXv3KMAxrhpY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = transformer_model()\n",
        "# model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "4Yl34AVBsDJs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# epochs = 10\n",
        "# model.fit(X_train, y_train, epochs=epochs)"
      ],
      "metadata": {
        "id": "Qw5DmCsyv5ko"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}