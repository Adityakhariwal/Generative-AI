{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "from sklearn import preprocessing\n",
        "import random\n",
        "import sklearn.linear_model as sklm\n",
        "from sklearn import metrics\n",
        "import math"
      ],
      "metadata": {
        "id": "9NYIlEGVdXBk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SrS92WXzbaVm"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "file_path = '/content/drive/MyDrive/train.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "df.head(11)"
      ],
      "metadata": {
        "id": "-J20CTKybs4t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_labels_fake = df[df.labels==0]\n",
        "df_labels_real = df[df.labels==1]"
      ],
      "metadata": {
        "id": "F3GXzO5jcJJ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_labels_fake.describe()"
      ],
      "metadata": {
        "id": "f8g1wZgLcOVn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_labels_fake.head(10)"
      ],
      "metadata": {
        "id": "7akAZ4BccbT1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_labels_real.describe()"
      ],
      "metadata": {
        "id": "aEejugRlce6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_labels_real.head(10)"
      ],
      "metadata": {
        "id": "0frmJTT2cizu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "8S_nH1BXcmJn",
        "outputId": "f116430b-5152-4058-a168-8eb2a80272e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            labels          f_0          f_1          f_2          f_3  \\\n",
              "count  5250.000000  5250.000000  5250.000000  5250.000000  5250.000000   \n",
              "mean      0.266667     0.385453     0.086769     0.317084     0.400414   \n",
              "std       0.442259     0.929075     0.898979     0.969380     0.954504   \n",
              "min       0.000000    -3.462941    -3.605773    -4.078232    -3.344323   \n",
              "25%       0.000000    -0.286854    -0.470281    -0.379984    -0.290078   \n",
              "50%       0.000000     0.598422     0.071867     0.518698     0.653512   \n",
              "75%       1.000000     1.108212     0.609769     1.085552     1.135854   \n",
              "max       1.000000     3.439295     3.581171     3.991985     3.900672   \n",
              "\n",
              "               f_4          f_5          f_6          f_7          f_8  ...  \\\n",
              "count  5250.000000  5250.000000  5250.000000  5250.000000  5250.000000  ...   \n",
              "mean      0.093063     0.173532    -0.174072    -0.074659    -0.135957  ...   \n",
              "std       0.968625     0.895351     1.001566     0.906168     0.972163  ...   \n",
              "min      -3.613712    -3.319666    -3.627701    -3.528635    -4.503662  ...   \n",
              "25%      -0.644337    -0.392807    -0.980593    -0.677763    -0.914803  ...   \n",
              "50%       0.141549     0.237502    -0.180645    -0.159631    -0.108885  ...   \n",
              "75%       0.950304     0.747622     0.621790     0.450741     0.627055  ...   \n",
              "max       3.488667     3.193113     3.062756     3.877255     3.017000  ...   \n",
              "\n",
              "            f_1190       f_1191       f_1192       f_1193       f_1194  \\\n",
              "count  5250.000000  5250.000000  5250.000000  5250.000000  5250.000000   \n",
              "mean      0.417874    -0.405061     0.091497    -0.276132    -0.133123   \n",
              "std       0.941354     1.054231     0.958970     0.989820     1.042036   \n",
              "min      -3.684054    -3.385650    -3.162629    -3.022903    -3.698249   \n",
              "25%      -0.254776    -1.265848    -0.594289    -1.054700    -1.009256   \n",
              "50%       0.648944    -0.489479     0.192821    -0.301887    -0.139792   \n",
              "75%       1.131876     0.366639     0.779280     0.409370     0.740059   \n",
              "max       4.077517     3.550058     3.790435     3.907684     3.777545   \n",
              "\n",
              "            f_1195       f_1196       f_1197       f_1198       f_1199  \n",
              "count  5250.000000  5250.000000  5250.000000  5250.000000  5250.000000  \n",
              "mean     -0.156475    -0.096026     0.372260    -0.222551     0.006532  \n",
              "std       1.019384     0.913732     0.944429     0.973640     0.897006  \n",
              "min      -4.791005    -3.356509    -3.933762    -4.174752    -3.624981  \n",
              "25%      -0.833164    -0.684567    -0.301254    -1.010557    -0.564394  \n",
              "50%      -0.197277    -0.156927     0.612440    -0.241763    -0.008017  \n",
              "75%       0.493094     0.434146     1.109200     0.508097     0.552090  \n",
              "max       3.269490     3.526907     3.542401     3.642856     3.718869  \n",
              "\n",
              "[8 rows x 1201 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ed09833e-41fb-453d-a50e-03773dbb3734\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>labels</th>\n",
              "      <th>f_0</th>\n",
              "      <th>f_1</th>\n",
              "      <th>f_2</th>\n",
              "      <th>f_3</th>\n",
              "      <th>f_4</th>\n",
              "      <th>f_5</th>\n",
              "      <th>f_6</th>\n",
              "      <th>f_7</th>\n",
              "      <th>f_8</th>\n",
              "      <th>...</th>\n",
              "      <th>f_1190</th>\n",
              "      <th>f_1191</th>\n",
              "      <th>f_1192</th>\n",
              "      <th>f_1193</th>\n",
              "      <th>f_1194</th>\n",
              "      <th>f_1195</th>\n",
              "      <th>f_1196</th>\n",
              "      <th>f_1197</th>\n",
              "      <th>f_1198</th>\n",
              "      <th>f_1199</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>5250.000000</td>\n",
              "      <td>5250.000000</td>\n",
              "      <td>5250.000000</td>\n",
              "      <td>5250.000000</td>\n",
              "      <td>5250.000000</td>\n",
              "      <td>5250.000000</td>\n",
              "      <td>5250.000000</td>\n",
              "      <td>5250.000000</td>\n",
              "      <td>5250.000000</td>\n",
              "      <td>5250.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>5250.000000</td>\n",
              "      <td>5250.000000</td>\n",
              "      <td>5250.000000</td>\n",
              "      <td>5250.000000</td>\n",
              "      <td>5250.000000</td>\n",
              "      <td>5250.000000</td>\n",
              "      <td>5250.000000</td>\n",
              "      <td>5250.000000</td>\n",
              "      <td>5250.000000</td>\n",
              "      <td>5250.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.266667</td>\n",
              "      <td>0.385453</td>\n",
              "      <td>0.086769</td>\n",
              "      <td>0.317084</td>\n",
              "      <td>0.400414</td>\n",
              "      <td>0.093063</td>\n",
              "      <td>0.173532</td>\n",
              "      <td>-0.174072</td>\n",
              "      <td>-0.074659</td>\n",
              "      <td>-0.135957</td>\n",
              "      <td>...</td>\n",
              "      <td>0.417874</td>\n",
              "      <td>-0.405061</td>\n",
              "      <td>0.091497</td>\n",
              "      <td>-0.276132</td>\n",
              "      <td>-0.133123</td>\n",
              "      <td>-0.156475</td>\n",
              "      <td>-0.096026</td>\n",
              "      <td>0.372260</td>\n",
              "      <td>-0.222551</td>\n",
              "      <td>0.006532</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.442259</td>\n",
              "      <td>0.929075</td>\n",
              "      <td>0.898979</td>\n",
              "      <td>0.969380</td>\n",
              "      <td>0.954504</td>\n",
              "      <td>0.968625</td>\n",
              "      <td>0.895351</td>\n",
              "      <td>1.001566</td>\n",
              "      <td>0.906168</td>\n",
              "      <td>0.972163</td>\n",
              "      <td>...</td>\n",
              "      <td>0.941354</td>\n",
              "      <td>1.054231</td>\n",
              "      <td>0.958970</td>\n",
              "      <td>0.989820</td>\n",
              "      <td>1.042036</td>\n",
              "      <td>1.019384</td>\n",
              "      <td>0.913732</td>\n",
              "      <td>0.944429</td>\n",
              "      <td>0.973640</td>\n",
              "      <td>0.897006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>-3.462941</td>\n",
              "      <td>-3.605773</td>\n",
              "      <td>-4.078232</td>\n",
              "      <td>-3.344323</td>\n",
              "      <td>-3.613712</td>\n",
              "      <td>-3.319666</td>\n",
              "      <td>-3.627701</td>\n",
              "      <td>-3.528635</td>\n",
              "      <td>-4.503662</td>\n",
              "      <td>...</td>\n",
              "      <td>-3.684054</td>\n",
              "      <td>-3.385650</td>\n",
              "      <td>-3.162629</td>\n",
              "      <td>-3.022903</td>\n",
              "      <td>-3.698249</td>\n",
              "      <td>-4.791005</td>\n",
              "      <td>-3.356509</td>\n",
              "      <td>-3.933762</td>\n",
              "      <td>-4.174752</td>\n",
              "      <td>-3.624981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.286854</td>\n",
              "      <td>-0.470281</td>\n",
              "      <td>-0.379984</td>\n",
              "      <td>-0.290078</td>\n",
              "      <td>-0.644337</td>\n",
              "      <td>-0.392807</td>\n",
              "      <td>-0.980593</td>\n",
              "      <td>-0.677763</td>\n",
              "      <td>-0.914803</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.254776</td>\n",
              "      <td>-1.265848</td>\n",
              "      <td>-0.594289</td>\n",
              "      <td>-1.054700</td>\n",
              "      <td>-1.009256</td>\n",
              "      <td>-0.833164</td>\n",
              "      <td>-0.684567</td>\n",
              "      <td>-0.301254</td>\n",
              "      <td>-1.010557</td>\n",
              "      <td>-0.564394</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.598422</td>\n",
              "      <td>0.071867</td>\n",
              "      <td>0.518698</td>\n",
              "      <td>0.653512</td>\n",
              "      <td>0.141549</td>\n",
              "      <td>0.237502</td>\n",
              "      <td>-0.180645</td>\n",
              "      <td>-0.159631</td>\n",
              "      <td>-0.108885</td>\n",
              "      <td>...</td>\n",
              "      <td>0.648944</td>\n",
              "      <td>-0.489479</td>\n",
              "      <td>0.192821</td>\n",
              "      <td>-0.301887</td>\n",
              "      <td>-0.139792</td>\n",
              "      <td>-0.197277</td>\n",
              "      <td>-0.156927</td>\n",
              "      <td>0.612440</td>\n",
              "      <td>-0.241763</td>\n",
              "      <td>-0.008017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.108212</td>\n",
              "      <td>0.609769</td>\n",
              "      <td>1.085552</td>\n",
              "      <td>1.135854</td>\n",
              "      <td>0.950304</td>\n",
              "      <td>0.747622</td>\n",
              "      <td>0.621790</td>\n",
              "      <td>0.450741</td>\n",
              "      <td>0.627055</td>\n",
              "      <td>...</td>\n",
              "      <td>1.131876</td>\n",
              "      <td>0.366639</td>\n",
              "      <td>0.779280</td>\n",
              "      <td>0.409370</td>\n",
              "      <td>0.740059</td>\n",
              "      <td>0.493094</td>\n",
              "      <td>0.434146</td>\n",
              "      <td>1.109200</td>\n",
              "      <td>0.508097</td>\n",
              "      <td>0.552090</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.439295</td>\n",
              "      <td>3.581171</td>\n",
              "      <td>3.991985</td>\n",
              "      <td>3.900672</td>\n",
              "      <td>3.488667</td>\n",
              "      <td>3.193113</td>\n",
              "      <td>3.062756</td>\n",
              "      <td>3.877255</td>\n",
              "      <td>3.017000</td>\n",
              "      <td>...</td>\n",
              "      <td>4.077517</td>\n",
              "      <td>3.550058</td>\n",
              "      <td>3.790435</td>\n",
              "      <td>3.907684</td>\n",
              "      <td>3.777545</td>\n",
              "      <td>3.269490</td>\n",
              "      <td>3.526907</td>\n",
              "      <td>3.542401</td>\n",
              "      <td>3.642856</td>\n",
              "      <td>3.718869</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 1201 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ed09833e-41fb-453d-a50e-03773dbb3734')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ed09833e-41fb-453d-a50e-03773dbb3734 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ed09833e-41fb-453d-a50e-03773dbb3734');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X = df.drop(['labels'],axis=1)\n",
        "y = df['labels']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)"
      ],
      "metadata": {
        "id": "YXeaqRxmcv4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_try = df.iloc[:,1:1201]\n",
        "y_try = df.iloc[:,0]"
      ],
      "metadata": {
        "id": "nsG6gXrSc89W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_try.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxHj0WnGc_k4",
        "outputId": "4efe1949-e01f-4ed9-b422-b01ce4b8d990"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5250, 1200)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_try"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U78CQDo3dCp1",
        "outputId": "b4b140da-2956-4e16-99c3-c90690ca1c35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       0\n",
              "1       1\n",
              "2       1\n",
              "3       0\n",
              "4       0\n",
              "       ..\n",
              "5245    0\n",
              "5246    0\n",
              "5247    1\n",
              "5248    1\n",
              "5249    1\n",
              "Name: labels, Length: 5250, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_try, X_test_try, y_train_try, y_test_try = train_test_split(X_try, y_try, train_size=0.7, shuffle=True)"
      ],
      "metadata": {
        "id": "BhxLaHJVdKR9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_try.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dq9F3DI9dNvb",
        "outputId": "d7f0192e-7aa2-419d-9738-5f9e091a13de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5250,)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "X_try = torch.tensor(X_try.values, dtype=torch.float32)\n",
        "y_try = torch.tensor(y_try, dtype=torch.float32).reshape(-1, 1)"
      ],
      "metadata": {
        "id": "LuoJv16kdkue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "gRlDF-WZdpmU",
        "outputId": "27ca6be4-2043-4b88-a1a0-b6ac6f1db10b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           f_0       f_1       f_2       f_3       f_4       f_5       f_6  \\\n",
              "0    -2.033875  0.978446 -0.142131 -0.177117 -1.470684  1.669562 -0.196530   \n",
              "1    -0.348835  0.294815 -0.557577 -2.020773 -1.234715  1.633930 -1.680658   \n",
              "2     0.113248 -0.607726 -0.947791  0.830851  0.998291  0.498321 -1.493958   \n",
              "3     1.223321 -0.479048 -1.925789  1.680377  0.021840 -1.453307  0.605559   \n",
              "4     0.160109  0.422684 -0.308029  0.227744  0.432854  0.608348  0.193832   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "5245  1.157565 -0.142219  1.043992  1.144946  1.195423  0.248978 -1.505100   \n",
              "5246  1.424709  0.235910  1.356778  1.368099 -0.318862  1.039765 -0.986854   \n",
              "5247 -0.375687  1.524455  0.012514 -0.007917  0.073809 -0.906909 -1.254247   \n",
              "5248 -0.478238  1.666142  0.049609 -0.428752 -0.362771  1.798104 -0.214314   \n",
              "5249 -0.750874  0.267008 -0.155041 -0.179867 -0.155041 -0.303999 -0.279173   \n",
              "\n",
              "           f_7       f_8       f_9  ...    f_1190    f_1191    f_1192  \\\n",
              "0    -0.125239 -0.452284 -0.128052  ... -1.111266  0.716084  0.060039   \n",
              "1    -0.358146  0.166122 -1.656990  ...  0.735240  0.829781  1.521941   \n",
              "2     0.789572 -1.311018  0.848524  ...  0.104698  0.616189 -1.035953   \n",
              "3    -0.019024  1.065448  0.717341  ...  0.360237 -1.957863 -0.123384   \n",
              "4     1.035091 -0.538868  0.778445  ...  0.416629  1.441766  0.212572   \n",
              "...        ...       ...       ...  ...       ...       ...       ...   \n",
              "5245 -0.874137 -1.782724  0.261597  ...  1.195423 -0.255793 -0.154838   \n",
              "5246 -0.330184 -1.383120  1.243559  ...  1.424709 -1.066107  0.881258   \n",
              "5247  1.606182  0.298557  0.053378  ... -0.028349 -0.968204 -1.233815   \n",
              "5248  0.775400 -0.379267  0.725914  ... -0.428752 -1.121552 -0.379267   \n",
              "5249  1.731765  0.564925  1.508328  ... -0.303999 -0.850180  0.937321   \n",
              "\n",
              "        f_1193    f_1194    f_1195    f_1196    f_1197    f_1198    f_1199  \n",
              "0     0.301279 -1.174846 -1.076498 -0.069452 -0.604012 -2.179176  0.558003  \n",
              "1     1.347946  0.754505  1.330642 -0.754453  0.582956  0.252671  1.495870  \n",
              "2     2.111387 -0.984415  1.148076 -1.433554  0.243372  0.170083  1.274795  \n",
              "3     1.505329  0.660290 -1.769443 -0.547756 -0.568122  0.244645  0.982116  \n",
              "4    -0.994721  1.143999 -2.166923 -1.199248 -1.028636  0.752791  0.317169  \n",
              "...        ...       ...       ...       ...       ...       ...       ...  \n",
              "5245  0.413029 -0.482939 -1.277953 -0.445082  1.195423 -0.924614 -0.432462  \n",
              "5246 -0.488691 -1.281223 -1.213291  0.122692  1.175627 -1.145360  0.451026  \n",
              "5247  1.626613 -0.191802  1.115823  0.380284 -0.293960  0.135104  1.381434  \n",
              "5248 -0.593705  0.049609  1.765114  0.313533 -0.329781 -1.220524  0.033114  \n",
              "5249 -1.594972  1.036626  1.582807  1.036626 -0.254346  0.664230  1.831071  \n",
              "\n",
              "[5250 rows x 1200 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-46402721-4499-4a6e-803e-083e53e5ebf1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>f_0</th>\n",
              "      <th>f_1</th>\n",
              "      <th>f_2</th>\n",
              "      <th>f_3</th>\n",
              "      <th>f_4</th>\n",
              "      <th>f_5</th>\n",
              "      <th>f_6</th>\n",
              "      <th>f_7</th>\n",
              "      <th>f_8</th>\n",
              "      <th>f_9</th>\n",
              "      <th>...</th>\n",
              "      <th>f_1190</th>\n",
              "      <th>f_1191</th>\n",
              "      <th>f_1192</th>\n",
              "      <th>f_1193</th>\n",
              "      <th>f_1194</th>\n",
              "      <th>f_1195</th>\n",
              "      <th>f_1196</th>\n",
              "      <th>f_1197</th>\n",
              "      <th>f_1198</th>\n",
              "      <th>f_1199</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-2.033875</td>\n",
              "      <td>0.978446</td>\n",
              "      <td>-0.142131</td>\n",
              "      <td>-0.177117</td>\n",
              "      <td>-1.470684</td>\n",
              "      <td>1.669562</td>\n",
              "      <td>-0.196530</td>\n",
              "      <td>-0.125239</td>\n",
              "      <td>-0.452284</td>\n",
              "      <td>-0.128052</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.111266</td>\n",
              "      <td>0.716084</td>\n",
              "      <td>0.060039</td>\n",
              "      <td>0.301279</td>\n",
              "      <td>-1.174846</td>\n",
              "      <td>-1.076498</td>\n",
              "      <td>-0.069452</td>\n",
              "      <td>-0.604012</td>\n",
              "      <td>-2.179176</td>\n",
              "      <td>0.558003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.348835</td>\n",
              "      <td>0.294815</td>\n",
              "      <td>-0.557577</td>\n",
              "      <td>-2.020773</td>\n",
              "      <td>-1.234715</td>\n",
              "      <td>1.633930</td>\n",
              "      <td>-1.680658</td>\n",
              "      <td>-0.358146</td>\n",
              "      <td>0.166122</td>\n",
              "      <td>-1.656990</td>\n",
              "      <td>...</td>\n",
              "      <td>0.735240</td>\n",
              "      <td>0.829781</td>\n",
              "      <td>1.521941</td>\n",
              "      <td>1.347946</td>\n",
              "      <td>0.754505</td>\n",
              "      <td>1.330642</td>\n",
              "      <td>-0.754453</td>\n",
              "      <td>0.582956</td>\n",
              "      <td>0.252671</td>\n",
              "      <td>1.495870</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.113248</td>\n",
              "      <td>-0.607726</td>\n",
              "      <td>-0.947791</td>\n",
              "      <td>0.830851</td>\n",
              "      <td>0.998291</td>\n",
              "      <td>0.498321</td>\n",
              "      <td>-1.493958</td>\n",
              "      <td>0.789572</td>\n",
              "      <td>-1.311018</td>\n",
              "      <td>0.848524</td>\n",
              "      <td>...</td>\n",
              "      <td>0.104698</td>\n",
              "      <td>0.616189</td>\n",
              "      <td>-1.035953</td>\n",
              "      <td>2.111387</td>\n",
              "      <td>-0.984415</td>\n",
              "      <td>1.148076</td>\n",
              "      <td>-1.433554</td>\n",
              "      <td>0.243372</td>\n",
              "      <td>0.170083</td>\n",
              "      <td>1.274795</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.223321</td>\n",
              "      <td>-0.479048</td>\n",
              "      <td>-1.925789</td>\n",
              "      <td>1.680377</td>\n",
              "      <td>0.021840</td>\n",
              "      <td>-1.453307</td>\n",
              "      <td>0.605559</td>\n",
              "      <td>-0.019024</td>\n",
              "      <td>1.065448</td>\n",
              "      <td>0.717341</td>\n",
              "      <td>...</td>\n",
              "      <td>0.360237</td>\n",
              "      <td>-1.957863</td>\n",
              "      <td>-0.123384</td>\n",
              "      <td>1.505329</td>\n",
              "      <td>0.660290</td>\n",
              "      <td>-1.769443</td>\n",
              "      <td>-0.547756</td>\n",
              "      <td>-0.568122</td>\n",
              "      <td>0.244645</td>\n",
              "      <td>0.982116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.160109</td>\n",
              "      <td>0.422684</td>\n",
              "      <td>-0.308029</td>\n",
              "      <td>0.227744</td>\n",
              "      <td>0.432854</td>\n",
              "      <td>0.608348</td>\n",
              "      <td>0.193832</td>\n",
              "      <td>1.035091</td>\n",
              "      <td>-0.538868</td>\n",
              "      <td>0.778445</td>\n",
              "      <td>...</td>\n",
              "      <td>0.416629</td>\n",
              "      <td>1.441766</td>\n",
              "      <td>0.212572</td>\n",
              "      <td>-0.994721</td>\n",
              "      <td>1.143999</td>\n",
              "      <td>-2.166923</td>\n",
              "      <td>-1.199248</td>\n",
              "      <td>-1.028636</td>\n",
              "      <td>0.752791</td>\n",
              "      <td>0.317169</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5245</th>\n",
              "      <td>1.157565</td>\n",
              "      <td>-0.142219</td>\n",
              "      <td>1.043992</td>\n",
              "      <td>1.144946</td>\n",
              "      <td>1.195423</td>\n",
              "      <td>0.248978</td>\n",
              "      <td>-1.505100</td>\n",
              "      <td>-0.874137</td>\n",
              "      <td>-1.782724</td>\n",
              "      <td>0.261597</td>\n",
              "      <td>...</td>\n",
              "      <td>1.195423</td>\n",
              "      <td>-0.255793</td>\n",
              "      <td>-0.154838</td>\n",
              "      <td>0.413029</td>\n",
              "      <td>-0.482939</td>\n",
              "      <td>-1.277953</td>\n",
              "      <td>-0.445082</td>\n",
              "      <td>1.195423</td>\n",
              "      <td>-0.924614</td>\n",
              "      <td>-0.432462</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5246</th>\n",
              "      <td>1.424709</td>\n",
              "      <td>0.235910</td>\n",
              "      <td>1.356778</td>\n",
              "      <td>1.368099</td>\n",
              "      <td>-0.318862</td>\n",
              "      <td>1.039765</td>\n",
              "      <td>-0.986854</td>\n",
              "      <td>-0.330184</td>\n",
              "      <td>-1.383120</td>\n",
              "      <td>1.243559</td>\n",
              "      <td>...</td>\n",
              "      <td>1.424709</td>\n",
              "      <td>-1.066107</td>\n",
              "      <td>0.881258</td>\n",
              "      <td>-0.488691</td>\n",
              "      <td>-1.281223</td>\n",
              "      <td>-1.213291</td>\n",
              "      <td>0.122692</td>\n",
              "      <td>1.175627</td>\n",
              "      <td>-1.145360</td>\n",
              "      <td>0.451026</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5247</th>\n",
              "      <td>-0.375687</td>\n",
              "      <td>1.524455</td>\n",
              "      <td>0.012514</td>\n",
              "      <td>-0.007917</td>\n",
              "      <td>0.073809</td>\n",
              "      <td>-0.906909</td>\n",
              "      <td>-1.254247</td>\n",
              "      <td>1.606182</td>\n",
              "      <td>0.298557</td>\n",
              "      <td>0.053378</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.028349</td>\n",
              "      <td>-0.968204</td>\n",
              "      <td>-1.233815</td>\n",
              "      <td>1.626613</td>\n",
              "      <td>-0.191802</td>\n",
              "      <td>1.115823</td>\n",
              "      <td>0.380284</td>\n",
              "      <td>-0.293960</td>\n",
              "      <td>0.135104</td>\n",
              "      <td>1.381434</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5248</th>\n",
              "      <td>-0.478238</td>\n",
              "      <td>1.666142</td>\n",
              "      <td>0.049609</td>\n",
              "      <td>-0.428752</td>\n",
              "      <td>-0.362771</td>\n",
              "      <td>1.798104</td>\n",
              "      <td>-0.214314</td>\n",
              "      <td>0.775400</td>\n",
              "      <td>-0.379267</td>\n",
              "      <td>0.725914</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.428752</td>\n",
              "      <td>-1.121552</td>\n",
              "      <td>-0.379267</td>\n",
              "      <td>-0.593705</td>\n",
              "      <td>0.049609</td>\n",
              "      <td>1.765114</td>\n",
              "      <td>0.313533</td>\n",
              "      <td>-0.329781</td>\n",
              "      <td>-1.220524</td>\n",
              "      <td>0.033114</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5249</th>\n",
              "      <td>-0.750874</td>\n",
              "      <td>0.267008</td>\n",
              "      <td>-0.155041</td>\n",
              "      <td>-0.179867</td>\n",
              "      <td>-0.155041</td>\n",
              "      <td>-0.303999</td>\n",
              "      <td>-0.279173</td>\n",
              "      <td>1.731765</td>\n",
              "      <td>0.564925</td>\n",
              "      <td>1.508328</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.303999</td>\n",
              "      <td>-0.850180</td>\n",
              "      <td>0.937321</td>\n",
              "      <td>-1.594972</td>\n",
              "      <td>1.036626</td>\n",
              "      <td>1.582807</td>\n",
              "      <td>1.036626</td>\n",
              "      <td>-0.254346</td>\n",
              "      <td>0.664230</td>\n",
              "      <td>1.831071</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5250 rows × 1200 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-46402721-4499-4a6e-803e-083e53e5ebf1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-46402721-4499-4a6e-803e-083e53e5ebf1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-46402721-4499-4a6e-803e-083e53e5ebf1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "xF9ixEexduG9",
        "outputId": "21d7a558-a3c9-49bc-c42c-d6f107b82c90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           f_0       f_1       f_2       f_3       f_4       f_5       f_6  \\\n",
              "4609  1.166039  0.410565  0.831472  0.939397  0.183922  0.960982 -1.488915   \n",
              "4767  1.463656  0.251083  1.318147  1.366650 -0.476460  0.275335 -1.313135   \n",
              "3481  1.272077  0.707197  1.232436  1.272077  0.023396  1.083783 -1.175733   \n",
              "3480  1.130936  0.258055  1.058196  1.821966 -0.578455  1.058196 -0.833045   \n",
              "1795 -0.840447 -0.472406  0.516034  1.109274  0.582020  0.591840  0.238144   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "3335  0.474419 -0.113313  0.488412  1.733844  0.572374 -0.379192 -1.596637   \n",
              "1099 -0.421378  1.462126 -1.275895  1.158129  1.327889 -0.358845 -1.410703   \n",
              "2514  0.072249 -1.201610  0.790880  0.218083 -0.422327  0.145970  0.901358   \n",
              "3606  1.352592  0.331141  1.190654  1.190654  0.007266  1.066087 -0.976814   \n",
              "2575  0.220324 -0.109989  0.918214 -0.413464 -0.806526 -0.123946 -0.194320   \n",
              "\n",
              "           f_7       f_8       f_9  ...    f_1190    f_1191    f_1192  \\\n",
              "4609 -0.161438 -1.467330  0.982567  ...  1.004152 -1.273065  0.615622   \n",
              "4767 -0.355203 -1.143375  0.978627  ...  1.354524 -0.803855  1.075632   \n",
              "3481  0.409893 -1.205464  0.806299  ...  1.252256 -0.987440  1.133334   \n",
              "3480  0.124699 -1.148252  0.718742  ...  1.821966 -0.663318 -0.032905   \n",
              "1795 -0.422780  0.613405  0.637375  ... -1.252584 -2.301808 -0.442274   \n",
              "...        ...       ...       ...  ...       ...       ...       ...   \n",
              "3335 -0.868969  0.530393 -0.183281  ...  1.789819  0.166559  1.188093   \n",
              "1099  0.303408 -0.398474  0.507667  ...  1.076916  0.351943  0.819817   \n",
              "2514 -0.466246  0.487091  1.264977  ...  0.970406 -0.451735  0.985949   \n",
              "3606 -0.017647 -1.126295  1.003804  ...  1.277851 -1.475083 -0.117301   \n",
              "2575 -0.617532 -1.329466 -0.438792  ... -1.127819 -0.011199 -0.411279   \n",
              "\n",
              "        f_1193    f_1194    f_1195    f_1196    f_1197    f_1198    f_1199  \n",
              "4609 -0.808988  0.766717  0.108375 -0.042720  0.950189 -1.586047  0.173130  \n",
              "4767 -0.270323  1.318147 -0.100563 -0.039934  1.257518 -1.422266  0.578478  \n",
              "3481  0.409893 -1.165823 -0.373010  0.618006  1.272077 -1.215374  0.479264  \n",
              "3480 -1.002772 -0.978525 -0.784552  0.173192  1.143059 -1.039142  0.306549  \n",
              "1795  0.861663 -0.560699  0.540608  0.142927  1.275490  1.071340  0.876267  \n",
              "...        ...       ...       ...       ...       ...       ...       ...  \n",
              "3335  0.782278  0.698316 -1.750567 -0.924943  0.530393 -0.799001 -0.561109  \n",
              "1099  0.718917  1.136913  0.337254 -0.586579  1.510014 -1.026841  0.395185  \n",
              "2514  1.541963 -0.225305 -2.385345  0.196546  0.335510 -1.832958  0.166655  \n",
              "3606 -0.914530  0.106920  0.206574 -0.030104  1.115914 -1.176121  0.380968  \n",
              "2575 -0.506249 -0.837173 -0.742393 -0.291009 -0.410843 -1.572290  0.167870  \n",
              "\n",
              "[4200 rows x 1200 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8fca8e28-6e4e-4e4c-9542-ab0ebc9e4dcd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>f_0</th>\n",
              "      <th>f_1</th>\n",
              "      <th>f_2</th>\n",
              "      <th>f_3</th>\n",
              "      <th>f_4</th>\n",
              "      <th>f_5</th>\n",
              "      <th>f_6</th>\n",
              "      <th>f_7</th>\n",
              "      <th>f_8</th>\n",
              "      <th>f_9</th>\n",
              "      <th>...</th>\n",
              "      <th>f_1190</th>\n",
              "      <th>f_1191</th>\n",
              "      <th>f_1192</th>\n",
              "      <th>f_1193</th>\n",
              "      <th>f_1194</th>\n",
              "      <th>f_1195</th>\n",
              "      <th>f_1196</th>\n",
              "      <th>f_1197</th>\n",
              "      <th>f_1198</th>\n",
              "      <th>f_1199</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4609</th>\n",
              "      <td>1.166039</td>\n",
              "      <td>0.410565</td>\n",
              "      <td>0.831472</td>\n",
              "      <td>0.939397</td>\n",
              "      <td>0.183922</td>\n",
              "      <td>0.960982</td>\n",
              "      <td>-1.488915</td>\n",
              "      <td>-0.161438</td>\n",
              "      <td>-1.467330</td>\n",
              "      <td>0.982567</td>\n",
              "      <td>...</td>\n",
              "      <td>1.004152</td>\n",
              "      <td>-1.273065</td>\n",
              "      <td>0.615622</td>\n",
              "      <td>-0.808988</td>\n",
              "      <td>0.766717</td>\n",
              "      <td>0.108375</td>\n",
              "      <td>-0.042720</td>\n",
              "      <td>0.950189</td>\n",
              "      <td>-1.586047</td>\n",
              "      <td>0.173130</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4767</th>\n",
              "      <td>1.463656</td>\n",
              "      <td>0.251083</td>\n",
              "      <td>1.318147</td>\n",
              "      <td>1.366650</td>\n",
              "      <td>-0.476460</td>\n",
              "      <td>0.275335</td>\n",
              "      <td>-1.313135</td>\n",
              "      <td>-0.355203</td>\n",
              "      <td>-1.143375</td>\n",
              "      <td>0.978627</td>\n",
              "      <td>...</td>\n",
              "      <td>1.354524</td>\n",
              "      <td>-0.803855</td>\n",
              "      <td>1.075632</td>\n",
              "      <td>-0.270323</td>\n",
              "      <td>1.318147</td>\n",
              "      <td>-0.100563</td>\n",
              "      <td>-0.039934</td>\n",
              "      <td>1.257518</td>\n",
              "      <td>-1.422266</td>\n",
              "      <td>0.578478</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3481</th>\n",
              "      <td>1.272077</td>\n",
              "      <td>0.707197</td>\n",
              "      <td>1.232436</td>\n",
              "      <td>1.272077</td>\n",
              "      <td>0.023396</td>\n",
              "      <td>1.083783</td>\n",
              "      <td>-1.175733</td>\n",
              "      <td>0.409893</td>\n",
              "      <td>-1.205464</td>\n",
              "      <td>0.806299</td>\n",
              "      <td>...</td>\n",
              "      <td>1.252256</td>\n",
              "      <td>-0.987440</td>\n",
              "      <td>1.133334</td>\n",
              "      <td>0.409893</td>\n",
              "      <td>-1.165823</td>\n",
              "      <td>-0.373010</td>\n",
              "      <td>0.618006</td>\n",
              "      <td>1.272077</td>\n",
              "      <td>-1.215374</td>\n",
              "      <td>0.479264</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3480</th>\n",
              "      <td>1.130936</td>\n",
              "      <td>0.258055</td>\n",
              "      <td>1.058196</td>\n",
              "      <td>1.821966</td>\n",
              "      <td>-0.578455</td>\n",
              "      <td>1.058196</td>\n",
              "      <td>-0.833045</td>\n",
              "      <td>0.124699</td>\n",
              "      <td>-1.148252</td>\n",
              "      <td>0.718742</td>\n",
              "      <td>...</td>\n",
              "      <td>1.821966</td>\n",
              "      <td>-0.663318</td>\n",
              "      <td>-0.032905</td>\n",
              "      <td>-1.002772</td>\n",
              "      <td>-0.978525</td>\n",
              "      <td>-0.784552</td>\n",
              "      <td>0.173192</td>\n",
              "      <td>1.143059</td>\n",
              "      <td>-1.039142</td>\n",
              "      <td>0.306549</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1795</th>\n",
              "      <td>-0.840447</td>\n",
              "      <td>-0.472406</td>\n",
              "      <td>0.516034</td>\n",
              "      <td>1.109274</td>\n",
              "      <td>0.582020</td>\n",
              "      <td>0.591840</td>\n",
              "      <td>0.238144</td>\n",
              "      <td>-0.422780</td>\n",
              "      <td>0.613405</td>\n",
              "      <td>0.637375</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.252584</td>\n",
              "      <td>-2.301808</td>\n",
              "      <td>-0.442274</td>\n",
              "      <td>0.861663</td>\n",
              "      <td>-0.560699</td>\n",
              "      <td>0.540608</td>\n",
              "      <td>0.142927</td>\n",
              "      <td>1.275490</td>\n",
              "      <td>1.071340</td>\n",
              "      <td>0.876267</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3335</th>\n",
              "      <td>0.474419</td>\n",
              "      <td>-0.113313</td>\n",
              "      <td>0.488412</td>\n",
              "      <td>1.733844</td>\n",
              "      <td>0.572374</td>\n",
              "      <td>-0.379192</td>\n",
              "      <td>-1.596637</td>\n",
              "      <td>-0.868969</td>\n",
              "      <td>0.530393</td>\n",
              "      <td>-0.183281</td>\n",
              "      <td>...</td>\n",
              "      <td>1.789819</td>\n",
              "      <td>0.166559</td>\n",
              "      <td>1.188093</td>\n",
              "      <td>0.782278</td>\n",
              "      <td>0.698316</td>\n",
              "      <td>-1.750567</td>\n",
              "      <td>-0.924943</td>\n",
              "      <td>0.530393</td>\n",
              "      <td>-0.799001</td>\n",
              "      <td>-0.561109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1099</th>\n",
              "      <td>-0.421378</td>\n",
              "      <td>1.462126</td>\n",
              "      <td>-1.275895</td>\n",
              "      <td>1.158129</td>\n",
              "      <td>1.327889</td>\n",
              "      <td>-0.358845</td>\n",
              "      <td>-1.410703</td>\n",
              "      <td>0.303408</td>\n",
              "      <td>-0.398474</td>\n",
              "      <td>0.507667</td>\n",
              "      <td>...</td>\n",
              "      <td>1.076916</td>\n",
              "      <td>0.351943</td>\n",
              "      <td>0.819817</td>\n",
              "      <td>0.718917</td>\n",
              "      <td>1.136913</td>\n",
              "      <td>0.337254</td>\n",
              "      <td>-0.586579</td>\n",
              "      <td>1.510014</td>\n",
              "      <td>-1.026841</td>\n",
              "      <td>0.395185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2514</th>\n",
              "      <td>0.072249</td>\n",
              "      <td>-1.201610</td>\n",
              "      <td>0.790880</td>\n",
              "      <td>0.218083</td>\n",
              "      <td>-0.422327</td>\n",
              "      <td>0.145970</td>\n",
              "      <td>0.901358</td>\n",
              "      <td>-0.466246</td>\n",
              "      <td>0.487091</td>\n",
              "      <td>1.264977</td>\n",
              "      <td>...</td>\n",
              "      <td>0.970406</td>\n",
              "      <td>-0.451735</td>\n",
              "      <td>0.985949</td>\n",
              "      <td>1.541963</td>\n",
              "      <td>-0.225305</td>\n",
              "      <td>-2.385345</td>\n",
              "      <td>0.196546</td>\n",
              "      <td>0.335510</td>\n",
              "      <td>-1.832958</td>\n",
              "      <td>0.166655</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3606</th>\n",
              "      <td>1.352592</td>\n",
              "      <td>0.331141</td>\n",
              "      <td>1.190654</td>\n",
              "      <td>1.190654</td>\n",
              "      <td>0.007266</td>\n",
              "      <td>1.066087</td>\n",
              "      <td>-0.976814</td>\n",
              "      <td>-0.017647</td>\n",
              "      <td>-1.126295</td>\n",
              "      <td>1.003804</td>\n",
              "      <td>...</td>\n",
              "      <td>1.277851</td>\n",
              "      <td>-1.475083</td>\n",
              "      <td>-0.117301</td>\n",
              "      <td>-0.914530</td>\n",
              "      <td>0.106920</td>\n",
              "      <td>0.206574</td>\n",
              "      <td>-0.030104</td>\n",
              "      <td>1.115914</td>\n",
              "      <td>-1.176121</td>\n",
              "      <td>0.380968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2575</th>\n",
              "      <td>0.220324</td>\n",
              "      <td>-0.109989</td>\n",
              "      <td>0.918214</td>\n",
              "      <td>-0.413464</td>\n",
              "      <td>-0.806526</td>\n",
              "      <td>-0.123946</td>\n",
              "      <td>-0.194320</td>\n",
              "      <td>-0.617532</td>\n",
              "      <td>-1.329466</td>\n",
              "      <td>-0.438792</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.127819</td>\n",
              "      <td>-0.011199</td>\n",
              "      <td>-0.411279</td>\n",
              "      <td>-0.506249</td>\n",
              "      <td>-0.837173</td>\n",
              "      <td>-0.742393</td>\n",
              "      <td>-0.291009</td>\n",
              "      <td>-0.410843</td>\n",
              "      <td>-1.572290</td>\n",
              "      <td>0.167870</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4200 rows × 1200 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8fca8e28-6e4e-4e4c-9542-ab0ebc9e4dcd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8fca8e28-6e4e-4e4c-9542-ab0ebc9e4dcd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8fca8e28-6e4e-4e4c-9542-ab0ebc9e4dcd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "kl203bjIdxEm",
        "outputId": "8f574b50-0333-40a3-a5af-066e27f14cf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           f_0       f_1       f_2       f_3       f_4       f_5       f_6  \\\n",
              "622   0.414507 -0.084732  0.817176  1.699438 -0.177796  2.197731 -0.946666   \n",
              "4709  0.846881 -0.038140  1.127840  1.085696  0.846881  0.299011 -0.473627   \n",
              "1471  0.603621 -0.854295 -0.790347 -0.576797  1.137031 -0.621563 -0.836415   \n",
              "4030  0.948981  0.537924  0.948981  0.948981  0.927901 -0.747949  0.885742   \n",
              "4100  0.342467  1.771953 -0.023621  0.481929 -0.075920  1.841684 -0.651201   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "1614 -0.477779 -2.327928 -0.173024  0.914004  0.698379  0.318776 -2.158623   \n",
              "1239  0.997471  0.229178 -0.140462  0.977226  1.013152  0.259783 -0.277012   \n",
              "5234  0.379699  0.630899  0.572930  0.263760  0.495637  0.708191  0.572930   \n",
              "1298 -0.800257 -0.680145  2.461833 -1.628303  0.460057 -0.123933 -1.444007   \n",
              "5204  0.371371  1.580607 -0.003321  0.388403 -1.587249  1.836079  0.166994   \n",
              "\n",
              "           f_7       f_8       f_9  ...    f_1190    f_1191    f_1192  \\\n",
              "622  -0.272134  0.220641  0.706877  ...  1.480261 -1.049922  0.140801   \n",
              "4709 -0.712442 -0.305051  0.945216  ...  1.071648 -1.780086  0.523778   \n",
              "1471 -0.664562  2.069877 -1.605179  ... -0.086227 -1.323784  0.511916   \n",
              "4030  0.169026  0.084706  0.948981  ...  0.917361 -1.232787 -0.252572   \n",
              "4100  0.063542  0.551660  0.970046  ...  0.516794  0.150706 -0.145651   \n",
              "...        ...       ...       ...  ...       ...       ...       ...   \n",
              "1614 -0.768339  2.310280 -0.988883  ... -0.282483 -0.540868  0.184609   \n",
              "1239  2.619211 -0.861281  0.218731  ...  1.179650  0.283766 -1.275039   \n",
              "5234 -1.475318  0.321730 -0.760364  ...  0.283083 -2.248242 -0.663748   \n",
              "1298  1.486262  1.302783 -0.234174  ... -0.418349  0.326167  0.574420   \n",
              "5204  0.422466 -1.365840  1.631701  ...  0.388403  1.086694  1.546544   \n",
              "\n",
              "        f_1193    f_1194    f_1195    f_1196    f_1197    f_1198    f_1199  \n",
              "622   0.806468  0.618929 -0.921879 -0.496920  1.165440  3.335078  1.348169  \n",
              "4709 -1.639607 -0.473627 -0.656250 -0.024092  1.127840 -0.656250  0.327107  \n",
              "1471  1.455155  0.518500 -0.299079  0.206391  1.487134 -1.037806 -0.833084  \n",
              "4030 -1.211707 -1.380346  0.485224  0.390364  0.906822 -1.454126  0.126866  \n",
              "4100 -0.999856 -0.197949  1.859117  0.603958  0.464496  0.080975  0.429630  \n",
              "...        ...       ...       ...       ...       ...       ...       ...  \n",
              "1614  0.353144  0.785386 -1.272865 -1.166833  1.807885 -0.993463  0.623806  \n",
              "1239  0.051749 -0.025880  2.117535  1.554742  0.547960  0.188821  0.070420  \n",
              "5234 -2.383504 -0.799010  1.287884  0.070529  0.418345  0.592253 -0.876302  \n",
              "1298  0.487766  0.725005 -1.273332 -0.844419  0.409891 -0.590461  0.465109  \n",
              "5204 -0.292856 -0.309888  1.257009 -0.207699  0.422466  0.201057  1.103725  \n",
              "\n",
              "[1050 rows x 1200 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a4b73862-625e-4fd1-bd53-e7f940e320bb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>f_0</th>\n",
              "      <th>f_1</th>\n",
              "      <th>f_2</th>\n",
              "      <th>f_3</th>\n",
              "      <th>f_4</th>\n",
              "      <th>f_5</th>\n",
              "      <th>f_6</th>\n",
              "      <th>f_7</th>\n",
              "      <th>f_8</th>\n",
              "      <th>f_9</th>\n",
              "      <th>...</th>\n",
              "      <th>f_1190</th>\n",
              "      <th>f_1191</th>\n",
              "      <th>f_1192</th>\n",
              "      <th>f_1193</th>\n",
              "      <th>f_1194</th>\n",
              "      <th>f_1195</th>\n",
              "      <th>f_1196</th>\n",
              "      <th>f_1197</th>\n",
              "      <th>f_1198</th>\n",
              "      <th>f_1199</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>622</th>\n",
              "      <td>0.414507</td>\n",
              "      <td>-0.084732</td>\n",
              "      <td>0.817176</td>\n",
              "      <td>1.699438</td>\n",
              "      <td>-0.177796</td>\n",
              "      <td>2.197731</td>\n",
              "      <td>-0.946666</td>\n",
              "      <td>-0.272134</td>\n",
              "      <td>0.220641</td>\n",
              "      <td>0.706877</td>\n",
              "      <td>...</td>\n",
              "      <td>1.480261</td>\n",
              "      <td>-1.049922</td>\n",
              "      <td>0.140801</td>\n",
              "      <td>0.806468</td>\n",
              "      <td>0.618929</td>\n",
              "      <td>-0.921879</td>\n",
              "      <td>-0.496920</td>\n",
              "      <td>1.165440</td>\n",
              "      <td>3.335078</td>\n",
              "      <td>1.348169</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4709</th>\n",
              "      <td>0.846881</td>\n",
              "      <td>-0.038140</td>\n",
              "      <td>1.127840</td>\n",
              "      <td>1.085696</td>\n",
              "      <td>0.846881</td>\n",
              "      <td>0.299011</td>\n",
              "      <td>-0.473627</td>\n",
              "      <td>-0.712442</td>\n",
              "      <td>-0.305051</td>\n",
              "      <td>0.945216</td>\n",
              "      <td>...</td>\n",
              "      <td>1.071648</td>\n",
              "      <td>-1.780086</td>\n",
              "      <td>0.523778</td>\n",
              "      <td>-1.639607</td>\n",
              "      <td>-0.473627</td>\n",
              "      <td>-0.656250</td>\n",
              "      <td>-0.024092</td>\n",
              "      <td>1.127840</td>\n",
              "      <td>-0.656250</td>\n",
              "      <td>0.327107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1471</th>\n",
              "      <td>0.603621</td>\n",
              "      <td>-0.854295</td>\n",
              "      <td>-0.790347</td>\n",
              "      <td>-0.576797</td>\n",
              "      <td>1.137031</td>\n",
              "      <td>-0.621563</td>\n",
              "      <td>-0.836415</td>\n",
              "      <td>-0.664562</td>\n",
              "      <td>2.069877</td>\n",
              "      <td>-1.605179</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.086227</td>\n",
              "      <td>-1.323784</td>\n",
              "      <td>0.511916</td>\n",
              "      <td>1.455155</td>\n",
              "      <td>0.518500</td>\n",
              "      <td>-0.299079</td>\n",
              "      <td>0.206391</td>\n",
              "      <td>1.487134</td>\n",
              "      <td>-1.037806</td>\n",
              "      <td>-0.833084</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4030</th>\n",
              "      <td>0.948981</td>\n",
              "      <td>0.537924</td>\n",
              "      <td>0.948981</td>\n",
              "      <td>0.948981</td>\n",
              "      <td>0.927901</td>\n",
              "      <td>-0.747949</td>\n",
              "      <td>0.885742</td>\n",
              "      <td>0.169026</td>\n",
              "      <td>0.084706</td>\n",
              "      <td>0.948981</td>\n",
              "      <td>...</td>\n",
              "      <td>0.917361</td>\n",
              "      <td>-1.232787</td>\n",
              "      <td>-0.252572</td>\n",
              "      <td>-1.211707</td>\n",
              "      <td>-1.380346</td>\n",
              "      <td>0.485224</td>\n",
              "      <td>0.390364</td>\n",
              "      <td>0.906822</td>\n",
              "      <td>-1.454126</td>\n",
              "      <td>0.126866</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4100</th>\n",
              "      <td>0.342467</td>\n",
              "      <td>1.771953</td>\n",
              "      <td>-0.023621</td>\n",
              "      <td>0.481929</td>\n",
              "      <td>-0.075920</td>\n",
              "      <td>1.841684</td>\n",
              "      <td>-0.651201</td>\n",
              "      <td>0.063542</td>\n",
              "      <td>0.551660</td>\n",
              "      <td>0.970046</td>\n",
              "      <td>...</td>\n",
              "      <td>0.516794</td>\n",
              "      <td>0.150706</td>\n",
              "      <td>-0.145651</td>\n",
              "      <td>-0.999856</td>\n",
              "      <td>-0.197949</td>\n",
              "      <td>1.859117</td>\n",
              "      <td>0.603958</td>\n",
              "      <td>0.464496</td>\n",
              "      <td>0.080975</td>\n",
              "      <td>0.429630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1614</th>\n",
              "      <td>-0.477779</td>\n",
              "      <td>-2.327928</td>\n",
              "      <td>-0.173024</td>\n",
              "      <td>0.914004</td>\n",
              "      <td>0.698379</td>\n",
              "      <td>0.318776</td>\n",
              "      <td>-2.158623</td>\n",
              "      <td>-0.768339</td>\n",
              "      <td>2.310280</td>\n",
              "      <td>-0.988883</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.282483</td>\n",
              "      <td>-0.540868</td>\n",
              "      <td>0.184609</td>\n",
              "      <td>0.353144</td>\n",
              "      <td>0.785386</td>\n",
              "      <td>-1.272865</td>\n",
              "      <td>-1.166833</td>\n",
              "      <td>1.807885</td>\n",
              "      <td>-0.993463</td>\n",
              "      <td>0.623806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1239</th>\n",
              "      <td>0.997471</td>\n",
              "      <td>0.229178</td>\n",
              "      <td>-0.140462</td>\n",
              "      <td>0.977226</td>\n",
              "      <td>1.013152</td>\n",
              "      <td>0.259783</td>\n",
              "      <td>-0.277012</td>\n",
              "      <td>2.619211</td>\n",
              "      <td>-0.861281</td>\n",
              "      <td>0.218731</td>\n",
              "      <td>...</td>\n",
              "      <td>1.179650</td>\n",
              "      <td>0.283766</td>\n",
              "      <td>-1.275039</td>\n",
              "      <td>0.051749</td>\n",
              "      <td>-0.025880</td>\n",
              "      <td>2.117535</td>\n",
              "      <td>1.554742</td>\n",
              "      <td>0.547960</td>\n",
              "      <td>0.188821</td>\n",
              "      <td>0.070420</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5234</th>\n",
              "      <td>0.379699</td>\n",
              "      <td>0.630899</td>\n",
              "      <td>0.572930</td>\n",
              "      <td>0.263760</td>\n",
              "      <td>0.495637</td>\n",
              "      <td>0.708191</td>\n",
              "      <td>0.572930</td>\n",
              "      <td>-1.475318</td>\n",
              "      <td>0.321730</td>\n",
              "      <td>-0.760364</td>\n",
              "      <td>...</td>\n",
              "      <td>0.283083</td>\n",
              "      <td>-2.248242</td>\n",
              "      <td>-0.663748</td>\n",
              "      <td>-2.383504</td>\n",
              "      <td>-0.799010</td>\n",
              "      <td>1.287884</td>\n",
              "      <td>0.070529</td>\n",
              "      <td>0.418345</td>\n",
              "      <td>0.592253</td>\n",
              "      <td>-0.876302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1298</th>\n",
              "      <td>-0.800257</td>\n",
              "      <td>-0.680145</td>\n",
              "      <td>2.461833</td>\n",
              "      <td>-1.628303</td>\n",
              "      <td>0.460057</td>\n",
              "      <td>-0.123933</td>\n",
              "      <td>-1.444007</td>\n",
              "      <td>1.486262</td>\n",
              "      <td>1.302783</td>\n",
              "      <td>-0.234174</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.418349</td>\n",
              "      <td>0.326167</td>\n",
              "      <td>0.574420</td>\n",
              "      <td>0.487766</td>\n",
              "      <td>0.725005</td>\n",
              "      <td>-1.273332</td>\n",
              "      <td>-0.844419</td>\n",
              "      <td>0.409891</td>\n",
              "      <td>-0.590461</td>\n",
              "      <td>0.465109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5204</th>\n",
              "      <td>0.371371</td>\n",
              "      <td>1.580607</td>\n",
              "      <td>-0.003321</td>\n",
              "      <td>0.388403</td>\n",
              "      <td>-1.587249</td>\n",
              "      <td>1.836079</td>\n",
              "      <td>0.166994</td>\n",
              "      <td>0.422466</td>\n",
              "      <td>-1.365840</td>\n",
              "      <td>1.631701</td>\n",
              "      <td>...</td>\n",
              "      <td>0.388403</td>\n",
              "      <td>1.086694</td>\n",
              "      <td>1.546544</td>\n",
              "      <td>-0.292856</td>\n",
              "      <td>-0.309888</td>\n",
              "      <td>1.257009</td>\n",
              "      <td>-0.207699</td>\n",
              "      <td>0.422466</td>\n",
              "      <td>0.201057</td>\n",
              "      <td>1.103725</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1050 rows × 1200 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a4b73862-625e-4fd1-bd53-e7f940e320bb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a4b73862-625e-4fd1-bd53-e7f940e320bb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a4b73862-625e-4fd1-bd53-e7f940e320bb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-MNvY3cd0K-",
        "outputId": "ec834cce-943b-4042-b8df-e97070b1513a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       0\n",
              "1       1\n",
              "2       1\n",
              "3       0\n",
              "4       0\n",
              "       ..\n",
              "5245    0\n",
              "5246    0\n",
              "5247    1\n",
              "5248    1\n",
              "5249    1\n",
              "Name: labels, Length: 5250, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Using Logistic Regression"
      ],
      "metadata": {
        "id": "9mLsqftUybZU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# training using regression\n",
        "model_LG = LinearRegression()\n",
        "model_LG.fit(X_train, y_train)\n",
        "y_predlinear = model_LG.predict(X_test)\n",
        "# print(y_predlinear)\n",
        "y_predlinear_new = []\n",
        "for target in y_predlinear:\n",
        "  y_predlinear_new.append(round(target))\n",
        "# print(y_predlinear_new)\n",
        "# y_predlinear = round(y_predlinear)\n",
        "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_predlinear_new))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aA0oFh-ad2bm",
        "outputId": "eef80693-64a0-4d4f-a789-b8bc63f7638a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7628571428571429\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training using Gradient Boosting"
      ],
      "metadata": {
        "id": "XJRD3ludzBFc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "clf = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1,\n",
        "    max_depth=3, random_state=20)\n",
        "clf.fit(X_train, y_train)\n",
        "y_predgboost = clf.predict(X_test)\n",
        "y_predgboost_new = []\n",
        "for target in y_predgboost:\n",
        "  y_predgboost_new.append(round(target))\n",
        "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_predgboost_new))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-AOfdy6ylAv",
        "outputId": "15ab9095-ae0b-4e4e-f35e-01fdb9897163"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8542857142857143\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training using Deep Neural Network"
      ],
      "metadata": {
        "id": "L5hO7kGNz4sD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.iloc[:, 1:].values\n",
        "y = df.iloc[:, 0].values\n",
        "\n",
        "# Reshape the features to image-like format (assuming each neural layer is an image)\n",
        "X = X.reshape(X.shape[0], 20, 20, 3)\n",
        "y = to_categorical(y)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syXbR2nO0DPC",
        "outputId": "6126d348-e28e-4452-f49b-0b334740d7fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4200, 20, 20, 3)\n",
            "(4200, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Activation, Dropout\n",
        "from keras.utils import to_categorical, np_utils\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import load_model\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'valid',\n",
        "                 activation ='relu', input_shape = (20,20,3)))\n",
        "print(\"Input: \", model.input_shape)\n",
        "print(\"Output: \", model.output_shape)\n",
        "\n",
        "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'valid',\n",
        "                 activation ='relu'))\n",
        "print(\"Input: \", model.input_shape)\n",
        "print(\"Output: \", model.output_shape)\n",
        "\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Dropout(0.25))\n",
        "print(\"Input: \", model.input_shape)\n",
        "print(\"Output: \", model.output_shape)\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation = \"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(2, activation = \"softmax\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxhP5bDkuP2k",
        "outputId": "4f6ac90d-b8b5-47e3-abd2-581b46ce4136"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:  (None, 20, 20, 3)\n",
            "Output:  (None, 16, 16, 32)\n",
            "Input:  (None, 20, 20, 3)\n",
            "Output:  (None, 12, 12, 32)\n",
            "Input:  (None, 20, 20, 3)\n",
            "Output:  (None, 6, 6, 32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = RMSprop(lr=0.0005, rho=0.9, epsilon=1e-08, decay=0.0)\n",
        "model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "sTHCR23Nu0Ri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = EarlyStopping(monitor='val_acc',\n",
        "                              min_delta=0,\n",
        "                              patience=2,\n",
        "                              verbose=0, mode='auto')"
      ],
      "metadata": {
        "id": "cF6TAZ0xu3bp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, batch_size = 100, epochs = 30,\n",
        "          validation_data = (X_test, y_test), verbose = 2, callbacks=[early_stopping])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9JMW5EXu7xa",
        "outputId": "04b4154f-3a0d-4f09-d6ca-a1574a4bb055"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42/42 - 1s - loss: 0.4910 - accuracy: 0.7633 - val_loss: 0.3698 - val_accuracy: 0.8486 - 1s/epoch - 27ms/step\n",
            "Epoch 2/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42/42 - 0s - loss: 0.3744 - accuracy: 0.8188 - val_loss: 0.3429 - val_accuracy: 0.8619 - 218ms/epoch - 5ms/step\n",
            "Epoch 3/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42/42 - 0s - loss: 0.3287 - accuracy: 0.8474 - val_loss: 0.3328 - val_accuracy: 0.8552 - 210ms/epoch - 5ms/step\n",
            "Epoch 4/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42/42 - 0s - loss: 0.2888 - accuracy: 0.8710 - val_loss: 0.3238 - val_accuracy: 0.8629 - 205ms/epoch - 5ms/step\n",
            "Epoch 5/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42/42 - 0s - loss: 0.2390 - accuracy: 0.8948 - val_loss: 0.3317 - val_accuracy: 0.8619 - 192ms/epoch - 5ms/step\n",
            "Epoch 6/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42/42 - 0s - loss: 0.2027 - accuracy: 0.9126 - val_loss: 0.3430 - val_accuracy: 0.8619 - 219ms/epoch - 5ms/step\n",
            "Epoch 7/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42/42 - 0s - loss: 0.1685 - accuracy: 0.9360 - val_loss: 0.3836 - val_accuracy: 0.8600 - 180ms/epoch - 4ms/step\n",
            "Epoch 8/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42/42 - 0s - loss: 0.1391 - accuracy: 0.9510 - val_loss: 0.3494 - val_accuracy: 0.8505 - 196ms/epoch - 5ms/step\n",
            "Epoch 9/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42/42 - 0s - loss: 0.1062 - accuracy: 0.9652 - val_loss: 0.3912 - val_accuracy: 0.8533 - 211ms/epoch - 5ms/step\n",
            "Epoch 10/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42/42 - 0s - loss: 0.0755 - accuracy: 0.9764 - val_loss: 0.4346 - val_accuracy: 0.8505 - 183ms/epoch - 4ms/step\n",
            "Epoch 11/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42/42 - 0s - loss: 0.0735 - accuracy: 0.9767 - val_loss: 0.4310 - val_accuracy: 0.8419 - 218ms/epoch - 5ms/step\n",
            "Epoch 12/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42/42 - 0s - loss: 0.0598 - accuracy: 0.9798 - val_loss: 0.4601 - val_accuracy: 0.8448 - 178ms/epoch - 4ms/step\n",
            "Epoch 13/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42/42 - 0s - loss: 0.0429 - accuracy: 0.9871 - val_loss: 0.4705 - val_accuracy: 0.8238 - 212ms/epoch - 5ms/step\n",
            "Epoch 14/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42/42 - 0s - loss: 0.0437 - accuracy: 0.9852 - val_loss: 0.5102 - val_accuracy: 0.8486 - 186ms/epoch - 4ms/step\n",
            "Epoch 15/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42/42 - 0s - loss: 0.0354 - accuracy: 0.9886 - val_loss: 0.5141 - val_accuracy: 0.8505 - 211ms/epoch - 5ms/step\n",
            "Epoch 16/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42/42 - 0s - loss: 0.0390 - accuracy: 0.9848 - val_loss: 0.5248 - val_accuracy: 0.8457 - 190ms/epoch - 5ms/step\n",
            "Epoch 17/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42/42 - 0s - loss: 0.0321 - accuracy: 0.9900 - val_loss: 0.5889 - val_accuracy: 0.8495 - 217ms/epoch - 5ms/step\n",
            "Epoch 18/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42/42 - 0s - loss: 0.0268 - accuracy: 0.9905 - val_loss: 0.6303 - val_accuracy: 0.8505 - 182ms/epoch - 4ms/step\n",
            "Epoch 19/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42/42 - 0s - loss: 0.0279 - accuracy: 0.9893 - val_loss: 0.5853 - val_accuracy: 0.8486 - 192ms/epoch - 5ms/step\n",
            "Epoch 20/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42/42 - 0s - loss: 0.0208 - accuracy: 0.9929 - val_loss: 0.6524 - val_accuracy: 0.8438 - 191ms/epoch - 5ms/step\n",
            "Epoch 21/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42/42 - 0s - loss: 0.0214 - accuracy: 0.9926 - val_loss: 0.6548 - val_accuracy: 0.8495 - 188ms/epoch - 4ms/step\n",
            "Epoch 22/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42/42 - 0s - loss: 0.0187 - accuracy: 0.9921 - val_loss: 0.7131 - val_accuracy: 0.8371 - 192ms/epoch - 5ms/step\n",
            "Epoch 23/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42/42 - 0s - loss: 0.0211 - accuracy: 0.9929 - val_loss: 0.6716 - val_accuracy: 0.8457 - 197ms/epoch - 5ms/step\n",
            "Epoch 24/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42/42 - 0s - loss: 0.0203 - accuracy: 0.9924 - val_loss: 0.7667 - val_accuracy: 0.8419 - 201ms/epoch - 5ms/step\n",
            "Epoch 25/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42/42 - 0s - loss: 0.0157 - accuracy: 0.9943 - val_loss: 0.7648 - val_accuracy: 0.8476 - 192ms/epoch - 5ms/step\n",
            "Epoch 26/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42/42 - 0s - loss: 0.0194 - accuracy: 0.9929 - val_loss: 0.8123 - val_accuracy: 0.8486 - 218ms/epoch - 5ms/step\n",
            "Epoch 27/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42/42 - 0s - loss: 0.0121 - accuracy: 0.9964 - val_loss: 0.7861 - val_accuracy: 0.8410 - 185ms/epoch - 4ms/step\n",
            "Epoch 28/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42/42 - 0s - loss: 0.0173 - accuracy: 0.9938 - val_loss: 0.9313 - val_accuracy: 0.8514 - 191ms/epoch - 5ms/step\n",
            "Epoch 29/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42/42 - 0s - loss: 0.0135 - accuracy: 0.9945 - val_loss: 0.8141 - val_accuracy: 0.8381 - 223ms/epoch - 5ms/step\n",
            "Epoch 30/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42/42 - 0s - loss: 0.0166 - accuracy: 0.9938 - val_loss: 0.7633 - val_accuracy: 0.8429 - 192ms/epoch - 5ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "y_test = np.argmax(y_test, axis=1)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "print(\"F1 Score:\", f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvHNFW4nw9_i",
        "outputId": "c4450757-53c3-4ac8-945d-12e87f43de84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7633 - accuracy: 0.8429\n",
            "Test Loss: 0.763306736946106\n",
            "Test Accuracy: 0.8428571224212646\n",
            "33/33 [==============================] - 0s 2ms/step\n",
            "F1 Score: 0.6680080482897384\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing with test data"
      ],
      "metadata": {
        "id": "CdIiHqXP4S94"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data=pd.read_csv('/content/drive/MyDrive/train.csv')\n",
        "X = train_data.iloc[:, 1:].values\n",
        "y = train_data.iloc[:, 0].values\n",
        "X = X.reshape(X.shape[0], 20, 20, 3)\n",
        "\n",
        "\n",
        "# Convert the target variable to categorical format\n",
        "y = to_categorical(y)\n",
        "# print(X_train.shape)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "snbnf2vC1w6K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'valid',\n",
        "                 activation ='relu', input_shape = (20,20,3)))\n",
        "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'valid',\n",
        "                 activation ='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation = \"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(2, activation = \"softmax\"))\n",
        "optimizer = RMSprop(lr=0.0005, rho=0.9, epsilon=1e-08, decay=0.0)\n",
        "model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "early_stopping = EarlyStopping(monitor='val_acc', min_delta=0, patience=2, verbose=0, mode='auto')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0L_UuPej118O",
        "outputId": "70866f94-2595-40e4-b137-996f9410f558"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/optimizers/legacy/rmsprop.py:143: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X, y, batch_size = 100, epochs = 30,\n",
        "          validation_data = (X_test, y_test), verbose = 2, callbacks=[early_stopping])\n",
        "\n",
        "#Load test data\n",
        "test_data = pd.read_csv('/content/drive/MyDrive/test.csv')\n",
        "\n",
        "# Seperating useful features and excluding heading of the test data\n",
        "X_test = test_data.iloc[:, 1:].values\n",
        "X_test = X_test.reshape(X_test.shape[0], 20, 20, 3)\n",
        "\n",
        "\n",
        "predictions = model.predict(X_test)\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "#Creating a solution file which predicts from the test file\n",
        "result_df = pd.DataFrame({'id': test_data['id'], 'Prediction': predicted_labels})\n",
        "\n",
        "# Save results into a file in drive\n",
        "result_df.to_csv('/content/drive/MyDrive/predictions.csv', index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cf2ra-H_16Uv",
        "outputId": "3e4b2554-79a2-48ce-f3ea-0538aad0e9e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53/53 - 1s - loss: 0.5074 - accuracy: 0.7590 - val_loss: 0.3666 - val_accuracy: 0.8276 - 1s/epoch - 20ms/step\n",
            "Epoch 2/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53/53 - 0s - loss: 0.3726 - accuracy: 0.8251 - val_loss: 0.2948 - val_accuracy: 0.8790 - 258ms/epoch - 5ms/step\n",
            "Epoch 3/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53/53 - 0s - loss: 0.3255 - accuracy: 0.8543 - val_loss: 0.2866 - val_accuracy: 0.8571 - 283ms/epoch - 5ms/step\n",
            "Epoch 4/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53/53 - 0s - loss: 0.2880 - accuracy: 0.8672 - val_loss: 0.2146 - val_accuracy: 0.9390 - 297ms/epoch - 6ms/step\n",
            "Epoch 5/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53/53 - 0s - loss: 0.2399 - accuracy: 0.8924 - val_loss: 0.1651 - val_accuracy: 0.9181 - 350ms/epoch - 7ms/step\n",
            "Epoch 6/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53/53 - 0s - loss: 0.1995 - accuracy: 0.9154 - val_loss: 0.1302 - val_accuracy: 0.9781 - 389ms/epoch - 7ms/step\n",
            "Epoch 7/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53/53 - 0s - loss: 0.1743 - accuracy: 0.9307 - val_loss: 0.0939 - val_accuracy: 0.9829 - 317ms/epoch - 6ms/step\n",
            "Epoch 8/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53/53 - 0s - loss: 0.1439 - accuracy: 0.9415 - val_loss: 0.0617 - val_accuracy: 0.9914 - 343ms/epoch - 6ms/step\n",
            "Epoch 9/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53/53 - 0s - loss: 0.1145 - accuracy: 0.9585 - val_loss: 0.0510 - val_accuracy: 0.9971 - 330ms/epoch - 6ms/step\n",
            "Epoch 10/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53/53 - 0s - loss: 0.0852 - accuracy: 0.9710 - val_loss: 0.0315 - val_accuracy: 0.9990 - 332ms/epoch - 6ms/step\n",
            "Epoch 11/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53/53 - 0s - loss: 0.0819 - accuracy: 0.9697 - val_loss: 0.0291 - val_accuracy: 0.9971 - 340ms/epoch - 6ms/step\n",
            "Epoch 12/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53/53 - 0s - loss: 0.0664 - accuracy: 0.9775 - val_loss: 0.0152 - val_accuracy: 1.0000 - 326ms/epoch - 6ms/step\n",
            "Epoch 13/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53/53 - 0s - loss: 0.0503 - accuracy: 0.9819 - val_loss: 0.0119 - val_accuracy: 1.0000 - 338ms/epoch - 6ms/step\n",
            "Epoch 14/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53/53 - 0s - loss: 0.0449 - accuracy: 0.9855 - val_loss: 0.0107 - val_accuracy: 1.0000 - 362ms/epoch - 7ms/step\n",
            "Epoch 15/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53/53 - 0s - loss: 0.0435 - accuracy: 0.9865 - val_loss: 0.0079 - val_accuracy: 1.0000 - 255ms/epoch - 5ms/step\n",
            "Epoch 16/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53/53 - 0s - loss: 0.0425 - accuracy: 0.9840 - val_loss: 0.0169 - val_accuracy: 0.9990 - 269ms/epoch - 5ms/step\n",
            "Epoch 17/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53/53 - 0s - loss: 0.0346 - accuracy: 0.9870 - val_loss: 0.0049 - val_accuracy: 1.0000 - 269ms/epoch - 5ms/step\n",
            "Epoch 18/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53/53 - 0s - loss: 0.0326 - accuracy: 0.9895 - val_loss: 0.0051 - val_accuracy: 0.9990 - 236ms/epoch - 4ms/step\n",
            "Epoch 19/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53/53 - 0s - loss: 0.0264 - accuracy: 0.9907 - val_loss: 0.0021 - val_accuracy: 1.0000 - 234ms/epoch - 4ms/step\n",
            "Epoch 20/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53/53 - 0s - loss: 0.0277 - accuracy: 0.9905 - val_loss: 0.0027 - val_accuracy: 1.0000 - 292ms/epoch - 6ms/step\n",
            "Epoch 21/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53/53 - 0s - loss: 0.0311 - accuracy: 0.9882 - val_loss: 0.0029 - val_accuracy: 1.0000 - 224ms/epoch - 4ms/step\n",
            "Epoch 22/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53/53 - 0s - loss: 0.0232 - accuracy: 0.9914 - val_loss: 0.0019 - val_accuracy: 1.0000 - 230ms/epoch - 4ms/step\n",
            "Epoch 23/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53/53 - 0s - loss: 0.0262 - accuracy: 0.9905 - val_loss: 0.0021 - val_accuracy: 1.0000 - 235ms/epoch - 4ms/step\n",
            "Epoch 24/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53/53 - 0s - loss: 0.0212 - accuracy: 0.9924 - val_loss: 0.0030 - val_accuracy: 1.0000 - 275ms/epoch - 5ms/step\n",
            "Epoch 25/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53/53 - 0s - loss: 0.0209 - accuracy: 0.9916 - val_loss: 0.0011 - val_accuracy: 1.0000 - 240ms/epoch - 5ms/step\n",
            "Epoch 26/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53/53 - 0s - loss: 0.0197 - accuracy: 0.9926 - val_loss: 8.0794e-04 - val_accuracy: 1.0000 - 227ms/epoch - 4ms/step\n",
            "Epoch 27/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53/53 - 0s - loss: 0.0206 - accuracy: 0.9924 - val_loss: 0.0026 - val_accuracy: 1.0000 - 235ms/epoch - 4ms/step\n",
            "Epoch 28/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53/53 - 0s - loss: 0.0187 - accuracy: 0.9933 - val_loss: 0.0011 - val_accuracy: 1.0000 - 223ms/epoch - 4ms/step\n",
            "Epoch 29/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53/53 - 0s - loss: 0.0233 - accuracy: 0.9922 - val_loss: 9.8690e-04 - val_accuracy: 1.0000 - 231ms/epoch - 4ms/step\n",
            "Epoch 30/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53/53 - 0s - loss: 0.0217 - accuracy: 0.9924 - val_loss: 7.6253e-04 - val_accuracy: 1.0000 - 264ms/epoch - 5ms/step\n",
            "71/71 [==============================] - 0s 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using Vision Transformer"
      ],
      "metadata": {
        "id": "TE2lw1cs47Sk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inp = torch.from_numpy(X.values.reshape(len(X),3,20,20).astype(float))\n",
        "inp = torch.clamp(inp,0,1)\n",
        "inp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKk25tf3GX6W",
        "outputId": "59e182d4-eb17-428b-a8c7-d22df0c849fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[0.0000e+00, 9.7845e-01, 0.0000e+00,  ..., 4.5184e-02,\n",
              "           0.0000e+00, 7.0296e-01],\n",
              "          [0.0000e+00, 5.5401e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           1.0000e+00, 0.0000e+00],\n",
              "          [0.0000e+00, 1.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           8.3506e-01, 0.0000e+00],\n",
              "          ...,\n",
              "          [3.5884e-01, 0.0000e+00, 2.1953e-01,  ..., 2.9834e-01,\n",
              "           3.8864e-01, 1.7029e-01],\n",
              "          [8.2437e-01, 0.0000e+00, 5.4134e-01,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 7.8418e-01],\n",
              "          [4.8284e-01, 1.0000e+00, 3.8534e-01,  ..., 5.2226e-01,\n",
              "           0.0000e+00, 3.5099e-02]],\n",
              "\n",
              "         [[0.0000e+00, 1.0000e+00, 0.0000e+00,  ..., 7.4908e-01,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [9.6579e-01, 2.5935e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           1.0000e+00, 0.0000e+00],\n",
              "          [1.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
              "           1.0825e-01, 1.0000e+00],\n",
              "          ...,\n",
              "          [1.3879e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           1.0000e+00, 0.0000e+00],\n",
              "          [3.6090e-01, 9.8250e-01, 0.0000e+00,  ..., 1.0000e+00,\n",
              "           1.0000e+00, 0.0000e+00],\n",
              "          [0.0000e+00, 5.2106e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           1.0000e+00, 0.0000e+00]],\n",
              "\n",
              "         [[6.4230e-01, 0.0000e+00, 0.0000e+00,  ..., 7.2454e-01,\n",
              "           0.0000e+00, 2.6545e-01],\n",
              "          [9.2356e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           1.0000e+00, 0.0000e+00],\n",
              "          [4.5812e-01, 3.0362e-01, 0.0000e+00,  ..., 1.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          ...,\n",
              "          [0.0000e+00, 0.0000e+00, 1.4858e-01,  ..., 3.7191e-01,\n",
              "           0.0000e+00, 1.0000e+00],\n",
              "          [0.0000e+00, 1.0000e+00, 4.9966e-01,  ..., 7.4401e-01,\n",
              "           9.0800e-01, 0.0000e+00],\n",
              "          [0.0000e+00, 5.5010e-01, 4.6254e-01,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 5.5800e-01]]],\n",
              "\n",
              "\n",
              "        [[[0.0000e+00, 2.9481e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           1.8365e-01, 2.1598e-01],\n",
              "          [1.2473e-01, 8.8043e-01, 6.3155e-01,  ..., 1.0000e+00,\n",
              "           9.7884e-01, 3.3160e-01],\n",
              "          [0.0000e+00, 4.4263e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           1.0000e+00, 0.0000e+00],\n",
              "          ...,\n",
              "          [0.0000e+00, 1.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 4.7644e-01],\n",
              "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 4.3395e-01,\n",
              "           7.1138e-03, 1.0000e+00],\n",
              "          [1.5474e-01, 0.0000e+00, 0.0000e+00,  ..., 7.9551e-01,\n",
              "           0.0000e+00, 0.0000e+00]],\n",
              "\n",
              "         [[0.0000e+00, 9.2972e-01, 2.6606e-01,  ..., 5.2380e-01,\n",
              "           0.0000e+00, 2.1264e-01],\n",
              "          [1.0000e+00, 8.9600e-01, 0.0000e+00,  ..., 6.7959e-02,\n",
              "           3.5122e-01, 6.6440e-02],\n",
              "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           4.9262e-02, 1.0000e+00],\n",
              "          ...,\n",
              "          [0.0000e+00, 8.0660e-01, 0.0000e+00,  ..., 1.0000e+00,\n",
              "           4.6245e-02, 7.1387e-01],\n",
              "          [0.0000e+00, 9.4436e-02, 0.0000e+00,  ..., 1.0835e-01,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [2.0439e-01, 0.0000e+00, 6.7677e-01,  ..., 2.0627e-01,\n",
              "           0.0000e+00, 6.9124e-01]],\n",
              "\n",
              "         [[0.0000e+00, 1.0000e+00, 7.9855e-01,  ..., 3.8507e-01,\n",
              "           1.0000e+00, 1.0000e+00],\n",
              "          [0.0000e+00, 0.0000e+00, 6.2148e-01,  ..., 9.1671e-01,\n",
              "           2.8743e-01, 0.0000e+00],\n",
              "          [1.2162e-01, 0.0000e+00, 7.9450e-01,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 1.0000e+00],\n",
              "          ...,\n",
              "          [6.8690e-02, 3.6873e-01, 0.0000e+00,  ..., 4.5124e-01,\n",
              "           0.0000e+00, 4.8044e-01],\n",
              "          [0.0000e+00, 7.3034e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [0.0000e+00, 3.2274e-03, 4.5534e-01,  ..., 5.8296e-01,\n",
              "           2.5267e-01, 1.0000e+00]]],\n",
              "\n",
              "\n",
              "        [[[1.1325e-01, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
              "           3.7042e-01, 0.0000e+00],\n",
              "          [1.1470e-01, 0.0000e+00, 8.1075e-01,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 1.0000e+00],\n",
              "          [0.0000e+00, 0.0000e+00, 3.2358e-01,  ..., 3.1542e-01,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          ...,\n",
              "          [0.0000e+00, 1.2400e-01, 2.3621e-01,  ..., 1.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [1.0000e+00, 0.0000e+00, 1.0000e+00,  ..., 0.0000e+00,\n",
              "           8.1140e-01, 0.0000e+00],\n",
              "          [6.8745e-01, 0.0000e+00, 3.6316e-01,  ..., 1.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00]],\n",
              "\n",
              "         [[3.3343e-01, 1.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
              "           1.0000e+00, 1.5485e-01],\n",
              "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 4.9716e-01,\n",
              "           0.0000e+00, 1.0000e+00],\n",
              "          [0.0000e+00, 5.2011e-01, 1.0000e+00,  ..., 0.0000e+00,\n",
              "           1.0000e+00, 3.9723e-01],\n",
              "          ...,\n",
              "          [7.5814e-01, 1.0000e+00, 9.2188e-01,  ..., 6.5955e-01,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [0.0000e+00, 3.3720e-01, 3.1387e-01,  ..., 7.9011e-01,\n",
              "           9.5849e-01, 3.6410e-01],\n",
              "          [0.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00]],\n",
              "\n",
              "         [[1.0000e+00, 0.0000e+00, 2.3062e-01,  ..., 6.1762e-01,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [1.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [4.2382e-01, 6.9925e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          ...,\n",
              "          [2.3811e-01, 0.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
              "           7.4144e-03, 1.0000e+00],\n",
              "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
              "           4.2771e-01, 0.0000e+00],\n",
              "          [0.0000e+00, 4.6707e-01, 1.0000e+00,  ..., 2.4337e-01,\n",
              "           1.7008e-01, 1.0000e+00]]],\n",
              "\n",
              "\n",
              "        ...,\n",
              "\n",
              "\n",
              "        [[[0.0000e+00, 1.0000e+00, 1.2514e-02,  ..., 1.0000e+00,\n",
              "           5.2331e-01, 1.0000e+00],\n",
              "          [0.0000e+00, 0.0000e+00, 1.9640e-01,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [1.0000e+00, 1.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
              "           1.0000e+00, 0.0000e+00],\n",
              "          ...,\n",
              "          [0.0000e+00, 1.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [0.0000e+00, 1.0000e+00, 3.2946e-02,  ..., 0.0000e+00,\n",
              "           5.3378e-02, 9.3194e-01],\n",
              "          [0.0000e+00, 1.0000e+00, 7.8892e-01,  ..., 0.0000e+00,\n",
              "           2.3726e-01, 0.0000e+00]],\n",
              "\n",
              "         [[0.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 2.3726e-01,\n",
              "           9.5237e-01, 1.0000e+00],\n",
              "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [0.0000e+00, 1.9640e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           1.0000e+00, 1.1467e-01],\n",
              "          ...,\n",
              "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           9.5237e-01, 0.0000e+00],\n",
              "          [1.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           1.3510e-01, 0.0000e+00],\n",
              "          [5.3378e-02, 1.1467e-01, 0.0000e+00,  ..., 7.2762e-01,\n",
              "           0.0000e+00, 5.3378e-02]],\n",
              "\n",
              "         [[0.0000e+00, 6.8676e-01, 1.7597e-01,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 1.0000e+00],\n",
              "          [0.0000e+00, 3.8028e-01, 0.0000e+00,  ..., 6.8676e-01,\n",
              "           0.0000e+00, 1.0000e+00],\n",
              "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           9.4241e-02, 0.0000e+00],\n",
              "          ...,\n",
              "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 6.6633e-01,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
              "           1.0000e+00, 0.0000e+00],\n",
              "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           1.3510e-01, 1.0000e+00]]],\n",
              "\n",
              "\n",
              "        [[[0.0000e+00, 1.0000e+00, 4.9609e-02,  ..., 1.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [0.0000e+00, 1.6619e-02, 0.0000e+00,  ..., 1.4858e-01,\n",
              "           4.9609e-02, 0.0000e+00],\n",
              "          [0.0000e+00, 1.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
              "           1.0000e+00, 1.1559e-01],\n",
              "          ...,\n",
              "          [0.0000e+00, 9.9095e-02, 0.0000e+00,  ..., 1.6619e-02,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [1.9807e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           8.9087e-01, 1.0000e+00],\n",
              "          [0.0000e+00, 0.0000e+00, 1.0000e+00,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00]],\n",
              "\n",
              "         [[0.0000e+00, 8.7437e-01, 1.0000e+00,  ..., 0.0000e+00,\n",
              "           1.0000e+00, 1.0000e+00],\n",
              "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 8.2600e-02,\n",
              "           1.0000e+00, 9.9095e-02],\n",
              "          [1.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
              "           4.2900e-01, 0.0000e+00],\n",
              "          ...,\n",
              "          [0.0000e+00, 1.2371e-04, 0.0000e+00,  ..., 1.0000e+00,\n",
              "           1.0000e+00, 0.0000e+00],\n",
              "          [5.2797e-01, 0.0000e+00, 1.1559e-01,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00]],\n",
              "\n",
              "         [[0.0000e+00, 6.9292e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [1.0000e+00, 1.0000e+00, 5.4447e-01,  ..., 6.9292e-01,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 3.3114e-02,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          ...,\n",
              "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 7.9189e-01,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [0.0000e+00, 0.0000e+00, 1.9807e-01,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 3.3114e-02]]],\n",
              "\n",
              "\n",
              "        [[[0.0000e+00, 2.6701e-01, 0.0000e+00,  ..., 1.0000e+00,\n",
              "           9.8697e-01, 2.4218e-01],\n",
              "          [0.0000e+00, 0.0000e+00, 2.6701e-01,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [9.1249e-01, 1.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
              "           0.0000e+00, 9.3223e-02],\n",
              "          ...,\n",
              "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [6.8397e-02, 9.1249e-01, 4.1597e-01,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 1.0000e+00],\n",
              "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
              "           1.0000e+00, 0.0000e+00]],\n",
              "\n",
              "         [[0.0000e+00, 6.1458e-01, 1.0000e+00,  ..., 1.6770e-01,\n",
              "           0.0000e+00, 1.0000e+00],\n",
              "          [7.1388e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [0.0000e+00, 6.6423e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          ...,\n",
              "          [1.1805e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [1.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
              "           4.9045e-01, 8.6284e-01],\n",
              "          [1.6770e-01, 1.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
              "           0.0000e+00, 1.6770e-01]],\n",
              "\n",
              "         [[0.0000e+00, 1.0000e+00, 0.0000e+00,  ..., 1.9253e-01,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [0.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 5.1527e-01],\n",
              "          ...,\n",
              "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 7.8836e-01],\n",
              "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 9.3732e-01,\n",
              "           1.0000e+00, 0.0000e+00],\n",
              "          [1.0000e+00, 0.0000e+00, 6.8397e-02,  ..., 0.0000e+00,\n",
              "           6.6423e-01, 1.0000e+00]]]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from torch import nn\n",
        "from torch.nn import Module\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import TensorDataset ,DataLoader\n",
        "from tqdm import tqdm\n",
        "class VisionTransformer(nn.Module):\n",
        "    def __init__(self, classes, img_size, patch_size, dim):\n",
        "        super(VisionTransformer, self).__init__()\n",
        "        self.patch_size = patch_size\n",
        "        patches = (img_size / patch_size) ** 2\n",
        "        patch_dim = 3 * (patch_size ** 2)\n",
        "        self.patch_embedding = nn.Conv2d(3, dim, kernel_size=patch_size, stride=patch_size)\n",
        "        self.pos_encoding = nn.Parameter(torch.zeros(1, int(patches), dim))\n",
        "        self.transformer = nn.TransformerEncoder(nn.TransformerEncoderLayer(d_model=dim, nhead=8), num_layers=6)\n",
        "        self.fc = nn.Linear(dim, classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, channels, height, width = x.shape\n",
        "        x = self.patch_embedding(x)\n",
        "        x = x.flatten(2).permute(0, 2, 1)\n",
        "        seq_len = x.shape[1]\n",
        "        pos_encoding = self.pos_encoding.expand(batch_size, -1, -1)\n",
        "        x = torch.cat([pos_encoding, x], dim=1)\n",
        "        x = self.transformer(x)\n",
        "        x = x.mean(dim=1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "classes = 2\n",
        "img_size = 20\n",
        "patch_size = 5\n",
        "dim = 128\n",
        "batch_size = 64\n",
        "num_epochs=2\n",
        "\n",
        "train_dataset = TensorDataset(inp, torch.from_numpy(np.array(y)))\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "vit = VisionTransformer(classes, img_size, patch_size, dim)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(vit.parameters(), lr=0.0001 )\n",
        "\n",
        "loss_df = []\n",
        "def train(model, train_loader, criterion, optimizer, num_epochs):\n",
        "    model.train()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        epoch_loss = 0.0\n",
        "        progress_bar = tqdm(train_loader, desc=f'epoch {epoch + 1}', unit='batch', ncols=80)\n",
        "\n",
        "        for images, labels in progress_bar:\n",
        "            outputs = model(images.float())\n",
        "            loss = criterion(outputs, labels)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            progress_bar.set_postfix({'Loss': loss.item()})\n",
        "\n",
        "        epoch_loss /= len(train_loader)\n",
        "        loss_df.append(epoch_loss)\n",
        "        print(f'average_loss: {epoch_loss}')\n",
        "\n",
        "    print('Training finished.')\n",
        "\n",
        "\n",
        "train(vit, train_loader, criterion, optimizer,num_epochs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbGCjapBEAdO",
        "outputId": "c5b2bdd2-8bb5-4200-e953-5c0673ca62ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 1: 100%|███████████████████| 83/83 [01:40<00:00,  1.21s/batch, Loss=0.768]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average_loss: 0.5408171253750124\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 2: 100%|███████████████████| 83/83 [01:36<00:00,  1.16s/batch, Loss=0.722]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average_loss: 0.4069327686924532\n",
            "Training finished.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot( np.arange(len(loss_df)),np.array(loss_df))"
      ],
      "metadata": {
        "id": "22MbhzzJSXE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mp3y7uNWJ7sq",
        "outputId": "3cad9fef-999c-44f3-c437-d5bfdc80a892"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VisionTransformer(\n",
              "  (patch_embedding): Conv2d(3, 128, kernel_size=(5, 5), stride=(5, 5))\n",
              "  (transformer): TransformerEncoder(\n",
              "    (layers): ModuleList(\n",
              "      (0-5): 6 x TransformerEncoderLayer(\n",
              "        (self_attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
              "        )\n",
              "        (linear1): Linear(in_features=128, out_features=2048, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (linear2): Linear(in_features=2048, out_features=128, bias=True)\n",
              "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout1): Dropout(p=0.1, inplace=False)\n",
              "        (dropout2): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (fc): Linear(in_features=128, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_inp = torch.from_numpy(X_test.values.reshape(len(X_test),3,20,20).astype(float))\n",
        "test_inp = torch.clamp(inp,0,1)\n",
        "test_inp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YU9b4e--J_WS",
        "outputId": "4a77b717-93d0-454c-ff55-df41a8338e33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[0.0000e+00, 9.7845e-01, 0.0000e+00,  ..., 4.5184e-02,\n",
              "           0.0000e+00, 7.0296e-01],\n",
              "          [0.0000e+00, 5.5401e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           1.0000e+00, 0.0000e+00],\n",
              "          [0.0000e+00, 1.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           8.3506e-01, 0.0000e+00],\n",
              "          ...,\n",
              "          [3.5884e-01, 0.0000e+00, 2.1953e-01,  ..., 2.9834e-01,\n",
              "           3.8864e-01, 1.7029e-01],\n",
              "          [8.2437e-01, 0.0000e+00, 5.4134e-01,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 7.8418e-01],\n",
              "          [4.8284e-01, 1.0000e+00, 3.8534e-01,  ..., 5.2226e-01,\n",
              "           0.0000e+00, 3.5099e-02]],\n",
              "\n",
              "         [[0.0000e+00, 1.0000e+00, 0.0000e+00,  ..., 7.4908e-01,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [9.6579e-01, 2.5935e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           1.0000e+00, 0.0000e+00],\n",
              "          [1.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
              "           1.0825e-01, 1.0000e+00],\n",
              "          ...,\n",
              "          [1.3879e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           1.0000e+00, 0.0000e+00],\n",
              "          [3.6090e-01, 9.8250e-01, 0.0000e+00,  ..., 1.0000e+00,\n",
              "           1.0000e+00, 0.0000e+00],\n",
              "          [0.0000e+00, 5.2106e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           1.0000e+00, 0.0000e+00]],\n",
              "\n",
              "         [[6.4230e-01, 0.0000e+00, 0.0000e+00,  ..., 7.2454e-01,\n",
              "           0.0000e+00, 2.6545e-01],\n",
              "          [9.2356e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           1.0000e+00, 0.0000e+00],\n",
              "          [4.5812e-01, 3.0362e-01, 0.0000e+00,  ..., 1.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          ...,\n",
              "          [0.0000e+00, 0.0000e+00, 1.4858e-01,  ..., 3.7191e-01,\n",
              "           0.0000e+00, 1.0000e+00],\n",
              "          [0.0000e+00, 1.0000e+00, 4.9966e-01,  ..., 7.4401e-01,\n",
              "           9.0800e-01, 0.0000e+00],\n",
              "          [0.0000e+00, 5.5010e-01, 4.6254e-01,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 5.5800e-01]]],\n",
              "\n",
              "\n",
              "        [[[0.0000e+00, 2.9481e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           1.8365e-01, 2.1598e-01],\n",
              "          [1.2473e-01, 8.8043e-01, 6.3155e-01,  ..., 1.0000e+00,\n",
              "           9.7884e-01, 3.3160e-01],\n",
              "          [0.0000e+00, 4.4263e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           1.0000e+00, 0.0000e+00],\n",
              "          ...,\n",
              "          [0.0000e+00, 1.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 4.7644e-01],\n",
              "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 4.3395e-01,\n",
              "           7.1138e-03, 1.0000e+00],\n",
              "          [1.5474e-01, 0.0000e+00, 0.0000e+00,  ..., 7.9551e-01,\n",
              "           0.0000e+00, 0.0000e+00]],\n",
              "\n",
              "         [[0.0000e+00, 9.2972e-01, 2.6606e-01,  ..., 5.2380e-01,\n",
              "           0.0000e+00, 2.1264e-01],\n",
              "          [1.0000e+00, 8.9600e-01, 0.0000e+00,  ..., 6.7959e-02,\n",
              "           3.5122e-01, 6.6440e-02],\n",
              "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           4.9262e-02, 1.0000e+00],\n",
              "          ...,\n",
              "          [0.0000e+00, 8.0660e-01, 0.0000e+00,  ..., 1.0000e+00,\n",
              "           4.6245e-02, 7.1387e-01],\n",
              "          [0.0000e+00, 9.4436e-02, 0.0000e+00,  ..., 1.0835e-01,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [2.0439e-01, 0.0000e+00, 6.7677e-01,  ..., 2.0627e-01,\n",
              "           0.0000e+00, 6.9124e-01]],\n",
              "\n",
              "         [[0.0000e+00, 1.0000e+00, 7.9855e-01,  ..., 3.8507e-01,\n",
              "           1.0000e+00, 1.0000e+00],\n",
              "          [0.0000e+00, 0.0000e+00, 6.2148e-01,  ..., 9.1671e-01,\n",
              "           2.8743e-01, 0.0000e+00],\n",
              "          [1.2162e-01, 0.0000e+00, 7.9450e-01,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 1.0000e+00],\n",
              "          ...,\n",
              "          [6.8690e-02, 3.6873e-01, 0.0000e+00,  ..., 4.5124e-01,\n",
              "           0.0000e+00, 4.8044e-01],\n",
              "          [0.0000e+00, 7.3034e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [0.0000e+00, 3.2274e-03, 4.5534e-01,  ..., 5.8296e-01,\n",
              "           2.5267e-01, 1.0000e+00]]],\n",
              "\n",
              "\n",
              "        [[[1.1325e-01, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
              "           3.7042e-01, 0.0000e+00],\n",
              "          [1.1470e-01, 0.0000e+00, 8.1075e-01,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 1.0000e+00],\n",
              "          [0.0000e+00, 0.0000e+00, 3.2358e-01,  ..., 3.1542e-01,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          ...,\n",
              "          [0.0000e+00, 1.2400e-01, 2.3621e-01,  ..., 1.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [1.0000e+00, 0.0000e+00, 1.0000e+00,  ..., 0.0000e+00,\n",
              "           8.1140e-01, 0.0000e+00],\n",
              "          [6.8745e-01, 0.0000e+00, 3.6316e-01,  ..., 1.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00]],\n",
              "\n",
              "         [[3.3343e-01, 1.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
              "           1.0000e+00, 1.5485e-01],\n",
              "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 4.9716e-01,\n",
              "           0.0000e+00, 1.0000e+00],\n",
              "          [0.0000e+00, 5.2011e-01, 1.0000e+00,  ..., 0.0000e+00,\n",
              "           1.0000e+00, 3.9723e-01],\n",
              "          ...,\n",
              "          [7.5814e-01, 1.0000e+00, 9.2188e-01,  ..., 6.5955e-01,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [0.0000e+00, 3.3720e-01, 3.1387e-01,  ..., 7.9011e-01,\n",
              "           9.5849e-01, 3.6410e-01],\n",
              "          [0.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00]],\n",
              "\n",
              "         [[1.0000e+00, 0.0000e+00, 2.3062e-01,  ..., 6.1762e-01,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [1.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [4.2382e-01, 6.9925e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          ...,\n",
              "          [2.3811e-01, 0.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
              "           7.4144e-03, 1.0000e+00],\n",
              "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
              "           4.2771e-01, 0.0000e+00],\n",
              "          [0.0000e+00, 4.6707e-01, 1.0000e+00,  ..., 2.4337e-01,\n",
              "           1.7008e-01, 1.0000e+00]]],\n",
              "\n",
              "\n",
              "        ...,\n",
              "\n",
              "\n",
              "        [[[0.0000e+00, 1.0000e+00, 1.2514e-02,  ..., 1.0000e+00,\n",
              "           5.2331e-01, 1.0000e+00],\n",
              "          [0.0000e+00, 0.0000e+00, 1.9640e-01,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [1.0000e+00, 1.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
              "           1.0000e+00, 0.0000e+00],\n",
              "          ...,\n",
              "          [0.0000e+00, 1.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [0.0000e+00, 1.0000e+00, 3.2946e-02,  ..., 0.0000e+00,\n",
              "           5.3378e-02, 9.3194e-01],\n",
              "          [0.0000e+00, 1.0000e+00, 7.8892e-01,  ..., 0.0000e+00,\n",
              "           2.3726e-01, 0.0000e+00]],\n",
              "\n",
              "         [[0.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 2.3726e-01,\n",
              "           9.5237e-01, 1.0000e+00],\n",
              "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [0.0000e+00, 1.9640e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           1.0000e+00, 1.1467e-01],\n",
              "          ...,\n",
              "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           9.5237e-01, 0.0000e+00],\n",
              "          [1.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           1.3510e-01, 0.0000e+00],\n",
              "          [5.3378e-02, 1.1467e-01, 0.0000e+00,  ..., 7.2762e-01,\n",
              "           0.0000e+00, 5.3378e-02]],\n",
              "\n",
              "         [[0.0000e+00, 6.8676e-01, 1.7597e-01,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 1.0000e+00],\n",
              "          [0.0000e+00, 3.8028e-01, 0.0000e+00,  ..., 6.8676e-01,\n",
              "           0.0000e+00, 1.0000e+00],\n",
              "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           9.4241e-02, 0.0000e+00],\n",
              "          ...,\n",
              "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 6.6633e-01,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
              "           1.0000e+00, 0.0000e+00],\n",
              "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           1.3510e-01, 1.0000e+00]]],\n",
              "\n",
              "\n",
              "        [[[0.0000e+00, 1.0000e+00, 4.9609e-02,  ..., 1.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [0.0000e+00, 1.6619e-02, 0.0000e+00,  ..., 1.4858e-01,\n",
              "           4.9609e-02, 0.0000e+00],\n",
              "          [0.0000e+00, 1.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
              "           1.0000e+00, 1.1559e-01],\n",
              "          ...,\n",
              "          [0.0000e+00, 9.9095e-02, 0.0000e+00,  ..., 1.6619e-02,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [1.9807e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           8.9087e-01, 1.0000e+00],\n",
              "          [0.0000e+00, 0.0000e+00, 1.0000e+00,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00]],\n",
              "\n",
              "         [[0.0000e+00, 8.7437e-01, 1.0000e+00,  ..., 0.0000e+00,\n",
              "           1.0000e+00, 1.0000e+00],\n",
              "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 8.2600e-02,\n",
              "           1.0000e+00, 9.9095e-02],\n",
              "          [1.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
              "           4.2900e-01, 0.0000e+00],\n",
              "          ...,\n",
              "          [0.0000e+00, 1.2371e-04, 0.0000e+00,  ..., 1.0000e+00,\n",
              "           1.0000e+00, 0.0000e+00],\n",
              "          [5.2797e-01, 0.0000e+00, 1.1559e-01,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00]],\n",
              "\n",
              "         [[0.0000e+00, 6.9292e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [1.0000e+00, 1.0000e+00, 5.4447e-01,  ..., 6.9292e-01,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 3.3114e-02,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          ...,\n",
              "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 7.9189e-01,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [0.0000e+00, 0.0000e+00, 1.9807e-01,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 3.3114e-02]]],\n",
              "\n",
              "\n",
              "        [[[0.0000e+00, 2.6701e-01, 0.0000e+00,  ..., 1.0000e+00,\n",
              "           9.8697e-01, 2.4218e-01],\n",
              "          [0.0000e+00, 0.0000e+00, 2.6701e-01,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [9.1249e-01, 1.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
              "           0.0000e+00, 9.3223e-02],\n",
              "          ...,\n",
              "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [6.8397e-02, 9.1249e-01, 4.1597e-01,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 1.0000e+00],\n",
              "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
              "           1.0000e+00, 0.0000e+00]],\n",
              "\n",
              "         [[0.0000e+00, 6.1458e-01, 1.0000e+00,  ..., 1.6770e-01,\n",
              "           0.0000e+00, 1.0000e+00],\n",
              "          [7.1388e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [0.0000e+00, 6.6423e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          ...,\n",
              "          [1.1805e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [1.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
              "           4.9045e-01, 8.6284e-01],\n",
              "          [1.6770e-01, 1.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
              "           0.0000e+00, 1.6770e-01]],\n",
              "\n",
              "         [[0.0000e+00, 1.0000e+00, 0.0000e+00,  ..., 1.9253e-01,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [0.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 5.1527e-01],\n",
              "          ...,\n",
              "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 7.8836e-01],\n",
              "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 9.3732e-01,\n",
              "           1.0000e+00, 0.0000e+00],\n",
              "          [1.0000e+00, 0.0000e+00, 6.8397e-02,  ..., 0.0000e+00,\n",
              "           6.6423e-01, 1.0000e+00]]]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = torch.argmax(vit(torch.from_numpy(X_test.values.reshape(len(X_test),3,20,20)).float()),axis=1)"
      ],
      "metadata": {
        "id": "bpjg9hWMKKsu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('accuracy score : ' , accuracy_score(y_pred,y_test))\n",
        "print('f1 score : ', f1_score(y_pred,y_test))"
      ],
      "metadata": {
        "id": "6gLLf5m3KP-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I kind of stuck here. Not able to calculate the accuracy for the transformer model"
      ],
      "metadata": {
        "id": "ffMpwF6e5J7q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import tensorflow as tf\n",
        "# from tensorflow import keras\n",
        "# from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "O6vtpsKXpG0r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Assuming x_train, y_train, x_test, y_test are already preprocessed and tokenized\n",
        "# # Create tf.data.Dataset objects for training and testing data\n",
        "# train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
        "# test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
        "# batch_size = 32\n",
        "# # Shuffle and batch the training data\n",
        "# train_dataset = train_dataset.shuffle(len(X_train)).batch(batch_size)\n",
        "\n",
        "# # Batch the testing data\n",
        "# test_dataset = test_dataset.batch(batch_size)"
      ],
      "metadata": {
        "id": "Gb0cePPBqEUO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Calculate max sequence length for input data\n",
        "# max_sequence_length_input = max(len(sequence) for sequence in X_train)\n",
        "\n",
        "# # Determine the overall max sequence length\n",
        "# max_sequence_length = max_sequence_length_input\n",
        "\n",
        "# # Calculate input vocabulary size\n",
        "# input_vocab = set(token for sequence in X_train for token in sequence)\n",
        "# input_vocab_size = len(input_vocab)\n",
        "\n",
        "# # Calculate target vocabulary size\n",
        "# target_vocab = set(token for sequence in X_train for token in sequence)\n",
        "# target_vocab_size = len(target_vocab)\n",
        "\n",
        "# def transformer_model():\n",
        "#     # Input layers\n",
        "#     inputs = layers.Input(shape=(max_sequence_length,))\n",
        "#     targets = layers.Input(shape=(max_sequence_length,))\n",
        "\n",
        "#     # Embedding layers\n",
        "#     input_embedding = layers.Embedding(input_vocab_size, d_model)(inputs)\n",
        "#     target_embedding = layers.Embedding(target_vocab_size, d_model)(targets)\n",
        "\n",
        "#     # Transformer layers\n",
        "#     encoder_output = encoder_layer(input_embedding)\n",
        "#     decoder_output = decoder_layer(target_embedding, encoder_output)\n",
        "\n",
        "#     # Output layer\n",
        "#     outputs = layers.Dense(target_vocab_size, activation='softmax')(decoder_output)\n",
        "\n",
        "#     # Build the model\n",
        "#     model = keras.Model(inputs=[inputs, targets], outputs=outputs)\n",
        "#     return model"
      ],
      "metadata": {
        "id": "HQAunI8QeLKJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Define hyperparameters\n",
        "# d_model = 128  # Dimensionality of the model\n",
        "# num_heads = 4  # Number of attention heads\n",
        "# ff_dim = 256  # Dimension\n",
        "# def encoder_layer(embedding):\n",
        "#     # Multi-head attention\n",
        "#     attention = layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model)(embedding, embedding)\n",
        "#     attention = layers.Dropout(0.1)(attention)\n",
        "#     attention = layers.LayerNormalization(epsilon=1e-6)(embedding + attention)\n",
        "\n",
        "#     # Feed-forward network\n",
        "#     outputs = layers.Dense(units=ff_dim, activation='relu')(attention)\n",
        "#     outputs = layers.Dense(units=d_model)(outputs)\n",
        "#     outputs = layers.Dropout(0.1)(outputs)\n",
        "#     outputs = layers.LayerNormalization(epsilon=1e-6)(attention + outputs)\n",
        "\n",
        "#     return outputs\n",
        "\n",
        "# def decoder_layer(embedding, encoder_output):\n",
        "#     # Masked multi-head attention (self-attention)\n",
        "#     attention = layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model)(embedding, embedding)\n",
        "#     attention = layers.Dropout(0.1)(attention)\n",
        "#     attention = layers.LayerNormalization(epsilon=1e-6)(embedding + attention)\n",
        "\n",
        "#     # Multi-head attention (encoder-decoder attention)\n",
        "#     attention = layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model)(attention, encoder_output)\n",
        "#     attention = layers.Dropout(0.1)(attention)\n",
        "#     attention = layers.LayerNormalization(epsilon=1e-6)(attention + embedding)\n",
        "\n",
        "#     # Feed-forward network\n",
        "#     outputs = layers.Dense(units=ff_dim, activation='relu')(attention)\n",
        "#     outputs = layers.Dense(units=d_model)(outputs)\n",
        "#     outputs = layers.Dropout(0.1)(outputs)\n",
        "#     outputs = layers.LayerNormalization(epsilon=1e-6)(attention + outputs)\n",
        "\n",
        "#     return outputs"
      ],
      "metadata": {
        "id": "cXv3KMAxrhpY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = transformer_model()\n",
        "# model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "4Yl34AVBsDJs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# epochs = 10\n",
        "# model.fit(X_train, y_train, epochs=epochs)"
      ],
      "metadata": {
        "id": "Qw5DmCsyv5ko"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}